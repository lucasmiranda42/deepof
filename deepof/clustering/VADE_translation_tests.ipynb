{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d41506e",
   "metadata": {},
   "source": [
    "# Recurrent block Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c137f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Bidirectional, GRU, LayerNormalization, Masking\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    LayerNormalization,\n",
    "    TimeDistributed,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb64eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentBlockPT(nn.Module):\n",
    "    # __init__ remains correct.\n",
    "    def __init__(self, input_features: int, latent_dim: int, bidirectional_merge: str = \"concat\"):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        if bidirectional_merge != \"concat\":\n",
    "            warnings.warn(\"Bidirectional merge mode defaulting to 'concat'.\")\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_features, out_channels=2 * latent_dim, kernel_size=5, padding=\"same\", bias=False)\n",
    "        self.gru1 = nn.GRU(input_size=2 * latent_dim, hidden_size=2 * latent_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.norm1 = nn.LayerNorm(4 * latent_dim, eps=1e-3)\n",
    "        self.gru2 = nn.GRU(input_size=4 * latent_dim, hidden_size=latent_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.norm2 = nn.LayerNorm(2 * latent_dim, eps=1e-3)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, T, N, _ = x.shape\n",
    "        \n",
    "        # Stage 1: Convolution\n",
    "        conv_in = x.reshape(B * T, N, -1).permute(0, 2, 1) # B*T as TF TimeDistributed analogon\n",
    "        conv_out = F.relu(self.conv1d(conv_in))\n",
    "        gru1_in = conv_out.permute(0, 2, 1) # Shape: (B*T, N, F_conv)\n",
    "        \n",
    "        # --- Prepare for packing ---\n",
    "        # Calculate mask from convolution output (TF GRU layer with masking analogon)\n",
    "        mask = (torch.abs(gru1_in).sum(dim=-1) > 0) # Shape: (B*T, N)\n",
    "        lengths = mask.sum(dim=1).cpu()\n",
    "        valid_indices = torch.where(lengths > 0)[0]\n",
    "        \n",
    "        # --- Stage 2: First GRU with packing ---\n",
    "        gru1_out_full = torch.zeros(B * T, N, 4 * self.latent_dim, device=x.device, dtype=x.dtype) # allocate data\n",
    "        if len(valid_indices) > 0:\n",
    "            valid_lengths = lengths[valid_indices]\n",
    "            # Apply GRU whilst ignoring masked data\n",
    "            packed_input = pack_padded_sequence(\n",
    "                gru1_in[valid_indices], valid_lengths, batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            packed_output, _ = self.gru1(packed_input)\n",
    "            unpacked_output, _ = pad_packed_sequence(\n",
    "                packed_output, batch_first=True, total_length=N\n",
    "            )\n",
    "            gru1_out_full[valid_indices] = unpacked_output\n",
    "\n",
    "        # Stage 3: First LayerNorm\n",
    "        norm1_in = gru1_out_full.reshape(B, T, N, -1)\n",
    "        norm1_out = self.norm1(norm1_in)\n",
    "\n",
    "        # --- Stage 4: Second GRU with packing ---\n",
    "        gru2_in = norm1_out.reshape(B * T, N, -1)\n",
    "        gru2_h_n_full = torch.zeros(2, B * T, self.latent_dim, device=x.device, dtype=x.dtype)\n",
    "        if len(valid_indices) > 0:\n",
    "            valid_lengths = lengths[valid_indices] # Use the same lengths\n",
    "            packed_input_2 = pack_padded_sequence(\n",
    "                gru2_in[valid_indices], valid_lengths, batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, h_n_2 = self.gru2(packed_input_2)\n",
    "            gru2_h_n_full[:, valid_indices, :] = h_n_2\n",
    "        gru2_final_state = gru2_h_n_full.permute(1, 0, 2).reshape(B * T, -1)\n",
    "\n",
    "        # Stage 5: Second LayerNorm\n",
    "        norm2_out = self.norm2(gru2_final_state)\n",
    "        \n",
    "        final_output = norm2_out.reshape(B, T, -1)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d022d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recurrent_block(\n",
    "    x: tf.Tensor, latent_dim: int, gru_unroll: bool, bidirectional_merge: str\n",
    "):\n",
    "    \"\"\"Build a recurrent embedding block, using a 1D convolution followed by two bidirectional GRU layers.\n",
    "\n",
    "    Args:\n",
    "        x (tf.Tensor): Input tensor.\n",
    "        latent_dim (int): Number of dimensions of the output tensor.\n",
    "        gru_unroll (bool): whether to unroll the GRU layers. Defaults to False.\n",
    "        bidirectional_merge (str): how to merge the forward and backward GRU layers. Defaults to \"concat\".\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.models.Model object with the specified architecture.\n",
    "\n",
    "    \"\"\"\n",
    "    encoder = TimeDistributed(\n",
    "        tf.keras.layers.Conv1D(\n",
    "            filters=2 * latent_dim,\n",
    "            kernel_size=5,\n",
    "            strides=1,  # Increased strides yield shorter sequences\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=he_uniform(),\n",
    "            use_bias=False,\n",
    "        )\n",
    "    )(x)\n",
    "    encoder = tf.keras.layers.Masking(mask_value=0.0)(encoder)\n",
    "    encoder = TimeDistributed(\n",
    "        Bidirectional(\n",
    "            GRU(\n",
    "                2 * latent_dim,\n",
    "                activation=\"tanh\",\n",
    "                recurrent_activation=\"sigmoid\",\n",
    "                return_sequences=True,\n",
    "                unroll=gru_unroll,\n",
    "                use_bias=True,\n",
    "            ),\n",
    "            merge_mode=bidirectional_merge,\n",
    "        )\n",
    "    )(encoder)\n",
    "    encoder = LayerNormalization()(encoder)\n",
    "    encoder = TimeDistributed(\n",
    "        Bidirectional(\n",
    "            GRU(\n",
    "                latent_dim,\n",
    "                activation=\"tanh\",\n",
    "                recurrent_activation=\"sigmoid\",\n",
    "                return_sequences=False,\n",
    "                unroll=gru_unroll,\n",
    "                use_bias=True,\n",
    "            ),\n",
    "            merge_mode=bidirectional_merge,\n",
    "        )\n",
    "    )(encoder)\n",
    "    encoder = LayerNormalization()(encoder)\n",
    "    \n",
    "\n",
    "    return tf.keras.models.Model(x, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3224b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_recurrent_block_weights(tf_model, pt_model):\n",
    "    \"\"\"Transfers weights for the full recurrent block with GRU gate permutation.\"\"\"\n",
    "    conv_td, _, gru1_td, norm1, gru2_td, norm2 = tf_model.layers[1:]\n",
    "\n",
    "\n",
    "    def permute_gru_weights(keras_weights):\n",
    "        W_ih, W_hh, B = keras_weights\n",
    "        W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "        W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "        W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "        W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "        B_ih, B_hh = B\n",
    "        B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "        B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "        B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "        B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "        return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_td.layer.get_weights()[0]).permute(2, 1, 0)\n",
    "    \n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(gru1_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1); pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    \n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(gru1_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1); pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm1.get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm1.get_weights()[1])\n",
    "\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(gru2_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2); pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    \n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(gru2_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2); pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    \n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm2.get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm2.get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae0d189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_final_forward_pass_with_masking (__main__.TestRecurrentBlockTranslation)\n",
      "Test the full block with the pack_padded_sequence masking method. ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.421s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow execution time: 0.07317900657653809\n",
      "Pytorch execution time: 0.024010419845581055\n",
      "✅ Full `RecurrentBlockPT` translation test PASSED!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestRecurrentBlockTranslation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up the full models and transfer weights.\"\"\"\n",
    "        tf.keras.backend.clear_session()\n",
    "        self.latent_dim = 8\n",
    "        self.input_shape = (10, 6, 3) # (T, N, F)\n",
    "        \n",
    "        self.tf_model = get_recurrent_block(\n",
    "            tf.keras.Input(shape=self.input_shape), self.latent_dim, False, \"concat\"\n",
    "        )\n",
    "        self.pt_model = RecurrentBlockPT(self.input_shape[-1], self.latent_dim)\n",
    "        self.pt_model.eval()\n",
    "\n",
    "        transfer_recurrent_block_weights(self.tf_model, self.pt_model)\n",
    "        \n",
    "        # Create test data WITH MASKING\n",
    "        self.np_input = np.random.rand(4, *self.input_shape).astype(np.float32)\n",
    "        # Mask the last two \"nodes\" for the first sample in the batch\n",
    "        self.np_input[0, :, :, :] = 0.0\n",
    "\n",
    "    def test_final_forward_pass_with_masking(self):\n",
    "        \"\"\"Test the full block with the pack_padded_sequence masking method.\"\"\"\n",
    "        tf_start=time.time()\n",
    "        tf_output = self.tf_model(self.np_input, training=False)\n",
    "        tf_end=time.time()\n",
    "        tf_output_np = tf_output.numpy()\n",
    "        \n",
    "\n",
    "        pt_input_tensor = torch.from_numpy(self.np_input)\n",
    "        with torch.no_grad():\n",
    "            pt_start = time.time()\n",
    "            pt_output = self.pt_model(pt_input_tensor)\n",
    "            pt_end=time.time()\n",
    "        pt_output_np = pt_output.cpu().numpy()\n",
    "        print(\"Tensorflow execution time: \" + str(tf_end-tf_start))\n",
    "        print(\"Pytorch execution time: \" + str(pt_end-pt_start))\n",
    "\n",
    "        np.testing.assert_allclose(tf_output_np, pt_output_np, rtol=1e-5, atol=1e-5)\n",
    "        print(\"✅ Full `RecurrentBlockPT` translation test PASSED!\")\n",
    "        \n",
    "#To run in Jupyter:\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestRecurrentBlockTranslation)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75eadde",
   "metadata": {},
   "source": [
    "# ProbabilisticDecoder Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6046e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import layers as tfpl\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow_probability.python.bijectors import scale as tfb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Distribution, TransformedDistribution\n",
    "from torch.distributions.transforms import AffineTransform\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a8e56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilisticDecoder(tf.keras.layers.Layer):\n",
    "    \"\"\"Map the reconstruction output of a given decoder to a multivariate normal distribution.\"\"\"\n",
    "\n",
    "    def __init__(self, output_data_shape, **kwargs):\n",
    "        \"\"\"Initialize the probabilistic decoder.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.time_distributer = tf.keras.layers.Dense(\n",
    "            tfpl.IndependentNormal.params_size(output_data_shape) // 2\n",
    "        )\n",
    "        self.probabilistic_decoding = tfpl.DistributionLambda(\n",
    "            make_distribution_fn=lambda decoded: tfd.Masked(\n",
    "                tfd.Independent(\n",
    "                    tfd.Normal(\n",
    "                        loc=decoded[0], scale=tf.ones_like(decoded[0]),\n",
    "                        validate_args=False, allow_nan_stats=False,\n",
    "                    ),\n",
    "                    reinterpreted_batch_ndims=1,\n",
    "                ),\n",
    "                validity_mask=decoded[1],\n",
    "            ),\n",
    "            convert_to_tensor_fn=\"mean\",\n",
    "        )\n",
    "        self.scaled_probabilistic_decoding = tfpl.DistributionLambda(\n",
    "            make_distribution_fn=lambda decoded: tfd.Masked(\n",
    "                tfd.TransformedDistribution(\n",
    "                    decoded[0], # base distribution\n",
    "                    tfb.Scale(tf.cast(tf.expand_dims(decoded[1], axis=2), tf.float32)), # bijector\n",
    "                    name=\"vae_reconstruction\",\n",
    "                ),\n",
    "                validity_mask=decoded[1],\n",
    "            ),\n",
    "            convert_to_tensor_fn=\"mean\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        hidden, validity_mask = inputs\n",
    "        loc_params = tf.keras.layers.TimeDistributed(self.time_distributer)(hidden)\n",
    "        prob_decoded = self.probabilistic_decoding([loc_params, validity_mask])\n",
    "        scaled_prob_decoded = self.scaled_probabilistic_decoding(\n",
    "            [prob_decoded, validity_mask]\n",
    "        )\n",
    "        return scaled_prob_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bf4048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: Create a subclass that knows how to compute the mean for an Affine transform.\n",
    "class AffineTransformedDistribution(TransformedDistribution):\n",
    "    \"\"\"\n",
    "    A specific TransformedDistribution for Affine transforms that implements .mean.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_distribution, transform):\n",
    "        super().__init__(base_distribution, transform)\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        \"\"\"\n",
    "        Computes the mean of the transformed distribution.\n",
    "        E[loc + scale * X] = loc + scale * E[X]\n",
    "        \"\"\"\n",
    "        # The transform itself is callable and applies the affine transformation.\n",
    "        return self.transforms[0](self.base_dist.mean)\n",
    "\n",
    "class ProbabilisticDecoderPT(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch translation of the ProbabilisticDecoder, including scaling transform.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim: int, data_dim: int):\n",
    "        super().__init__()\n",
    "        self.loc_projection = nn.Linear(in_features=hidden_dim, out_features=data_dim)\n",
    "\n",
    "    def forward(self, hidden: torch.Tensor, validity_mask: torch.Tensor) -> AffineTransformedDistribution:\n",
    "        B, T, D = hidden.shape\n",
    "        # Reconstruct mean locations\n",
    "        loc_params = self.loc_projection(hidden.view(B * T, -1)).view(B, T, -1)\n",
    "\n",
    "        # Define Gaussian distributions with means (init: var=1)\n",
    "        scale_params = torch.ones_like(loc_params)\n",
    "        base_dist = torch.distributions.Normal(loc=loc_params, scale=scale_params)\n",
    "\n",
    "        # Multivariate Gaussian distributions for feature vector\n",
    "        independent_dist = torch.distributions.Independent(base_dist, 1)\n",
    "        \n",
    "        # Define transform to map masked values to 0 (y = 0 + 0 * x) and unmasked-values to themselves (y = 0 + 1.0 * x)\n",
    "        scale_transform = validity_mask.unsqueeze(-1).to(hidden.dtype)\n",
    "        transform = AffineTransform(loc=0, scale=scale_transform)\n",
    "        \n",
    "        # Returns a custom class instead of the generic one as \"mean\" functionality otherwise would be missing.\n",
    "        final_dist = AffineTransformedDistribution(independent_dist, transform)\n",
    "        return final_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "895ba3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_probabilistic_decoder_weights(tf_model, pt_model):\n",
    "    dense_layer = tf_model.time_distributer\n",
    "    W, b = dense_layer.get_weights()\n",
    "    pt_model.loc_projection.weight.data = torch.from_numpy(W.T)\n",
    "    pt_model.loc_projection.bias.data = torch.from_numpy(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95a69952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_final_forward_pass (__main__.TestProbabilisticDecoderFinal)\n",
      "Tests that the .mean() of the final transformed distributions are identical. ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Weights transferred successfully for final test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.426s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow execution time: 0.049201250076293945\n",
      "Pytorch execution time: 0.3155639171600342\n",
      "\n",
      "✅ `ProbabilisticDecoderPT` FINAL translation test PASSED!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestProbabilisticDecoderFinal(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        tf.keras.backend.clear_session()\n",
    "        self.batch_size, self.time_steps, self.hidden_dim, self.data_dim = 4, 10, 32, 5\n",
    "\n",
    "        # Create TF model\n",
    "        self.tf_model = ProbabilisticDecoder(output_data_shape=(self.data_dim,))\n",
    "        \n",
    "        # Create PyTorch model\n",
    "        self.pt_model = ProbabilisticDecoderPT(hidden_dim=self.hidden_dim, data_dim=self.data_dim)\n",
    "        self.pt_model.eval()\n",
    "\n",
    "        # --- THE FIX: Zero out the input tensor based on the mask ---\n",
    "        np_hidden_original = np.random.rand(self.batch_size, self.time_steps, self.hidden_dim).astype(np.float32)\n",
    "        \n",
    "        # Create a float mask (1.0/0.0)\n",
    "        self.np_float_mask = np.ones((self.batch_size, self.time_steps), dtype=np.float32)\n",
    "        self.np_float_mask[0, -1] = 0.0 # Mask last step of first item\n",
    "        self.np_float_mask[1, 5:] = 0.0 # Mask multiple steps of second item\n",
    "\n",
    "        # Apply the mask to the input data itself before feeding it to the models\n",
    "        self.np_hidden_masked = np_hidden_original * self.np_float_mask[:, :, np.newaxis]\n",
    "\n",
    "        # TF needs a boolean mask for tfd.Masked\n",
    "        self.np_bool_mask = self.np_float_mask.astype(bool)\n",
    "\n",
    "        # Build the TF model by calling it once with the masked input\n",
    "        self.tf_model([tf.constant(self.np_hidden_masked), tf.constant(self.np_bool_mask)])\n",
    "        \n",
    "        # Transfer weights\n",
    "        transfer_probabilistic_decoder_weights(self.tf_model, self.pt_model)\n",
    "        print(\"✅ Weights transferred successfully for final test.\")\n",
    "\n",
    "    def test_final_forward_pass(self):\n",
    "        \"\"\"Tests that the .mean() of the final transformed distributions are identical.\"\"\"\n",
    "        # --- TensorFlow ---\n",
    "        # Pass the zeroed-out hidden data and the boolean mask\n",
    "        tf_start=time.time()\n",
    "        tf_dist = self.tf_model([self.np_hidden_masked, self.np_bool_mask])\n",
    "        tf_mean_np = tf_dist.mean().numpy()\n",
    "        tf_end=time.time()\n",
    "\n",
    "\n",
    "        # --- PyTorch ---\n",
    "        pt_hidden_tensor = torch.from_numpy(self.np_hidden_masked)\n",
    "        pt_mask_tensor = torch.from_numpy(self.np_float_mask)\n",
    "        with torch.no_grad():\n",
    "            pt_start=time.time()\n",
    "            pt_dist = self.pt_model(pt_hidden_tensor, pt_mask_tensor)\n",
    "        pt_mean_np = pt_dist.mean.cpu().numpy()\n",
    "        pt_end=time.time()\n",
    "\n",
    "        # --- Verification ---\n",
    "        np.testing.assert_allclose(tf_mean_np, pt_mean_np, rtol=1e-6, atol=1e-6)\n",
    "        \n",
    "        # Check a masked-out part is zero\n",
    "        self.assertTrue(np.all(pt_mean_np[0, -1, :] == 0.0))\n",
    "        # Check an un-masked part is not zero\n",
    "        self.assertFalse(np.all(pt_mean_np[0, 0, :] == 0.0))\n",
    "\n",
    "        print(\"Tensorflow execution time: \" + str(tf_end-tf_start))\n",
    "        print(\"Pytorch execution time: \" + str(pt_end-pt_start))\n",
    "        \n",
    "        print(\"\\n✅ `ProbabilisticDecoderPT` FINAL translation test PASSED!\")\n",
    "\n",
    "# To run in Jupyter or a script:\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestProbabilisticDecoderFinal)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250a323",
   "metadata": {},
   "source": [
    "# Recurrent Decoder Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27becafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tcn\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from spektral.layers import CensNetConv\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    LayerNormalization,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import time\n",
    "import deepof.model_utils\n",
    "import deepof.clustering.model_utils_new\n",
    "from deepof.clustering.censNetConv_pt import CensNetConvPT\n",
    "import deepof.utils\n",
    "from deepof.data_loading import get_dt\n",
    "import warnings\n",
    "from deepof.clustering.model_utils_new import ProbabilisticDecoderPT\n",
    "from torch.distributions import Distribution, TransformedDistribution\n",
    "from torch.distributions.transforms import AffineTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "478bf738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recurrent_decoder(\n",
    "    input_shape: tuple,\n",
    "    latent_dim: int,\n",
    "    gru_unroll: bool = False,\n",
    "    bidirectional_merge: str = \"concat\",\n",
    "):\n",
    "    \"\"\"Return a recurrent neural decoder.\n",
    "\n",
    "    Builds a deep neural network capable of decoding the structured latent space generated by one of the compatible\n",
    "    classes into a sequence of motion tracking instances, either reconstructing the original\n",
    "    input, or generating new data from given clusters.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): shape of the input data\n",
    "        latent_dim (int): dimensionality of the latent space\n",
    "        gru_unroll (bool): whether to unroll the GRU layers. Defaults to False.\n",
    "        bidirectional_merge (str): how to merge the forward and backward GRU layers. Defaults to \"concat\".\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: a keras model that can be trained to decode the latent space into a series of motion tracking\n",
    "        sequences.\n",
    "\n",
    "    \"\"\"\n",
    "    # Define and instantiate generator\n",
    "    g = Input(shape=latent_dim)  # Decoder input, shaped as the latent space\n",
    "    x = Input(shape=input_shape)  # Encoder input, used to generate an output mask\n",
    "    validity_mask = tf.math.logical_not(tf.reduce_all(x == 0.0, axis=2))\n",
    "\n",
    "    generator = RepeatVector(input_shape[0])(g)\n",
    "    generator = Bidirectional(\n",
    "        GRU(\n",
    "            latent_dim,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            return_sequences=True,\n",
    "            unroll=gru_unroll,\n",
    "            use_bias=True,\n",
    "        ),\n",
    "        merge_mode=bidirectional_merge,\n",
    "    )(generator, mask=validity_mask)\n",
    "    generator = LayerNormalization()(generator)\n",
    "    generator = Bidirectional(\n",
    "        GRU(\n",
    "            2 * latent_dim,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            return_sequences=True,\n",
    "            unroll=gru_unroll,\n",
    "            use_bias=True,\n",
    "        ),\n",
    "        merge_mode=bidirectional_merge,\n",
    "    )(generator)\n",
    "    generator = LayerNormalization()(generator)\n",
    "    generator = tf.keras.layers.Conv1D(\n",
    "        filters=2 * latent_dim,\n",
    "        kernel_size=5,\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=he_uniform(),\n",
    "        use_bias=False,\n",
    "    )(generator)\n",
    "    generator = LayerNormalization()(generator)\n",
    "\n",
    "    x_decoded = deepof.model_utils.ProbabilisticDecoder(input_shape)(\n",
    "        [generator, validity_mask]\n",
    "    )\n",
    "\n",
    "    return Model([g, x], x_decoded, name=\"recurrent_decoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2f31c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentDecoderPT(nn.Module):\n",
    "    \"\"\"\n",
    "    A full PyTorch implementation of the recurrent decoder.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_shape: tuple, latent_dim: int, bidirectional_merge: str = \"concat\"):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_shape = output_shape\n",
    "        if bidirectional_merge != \"concat\":\n",
    "            warnings.warn(\"Bidirectional merge mode is fixed to 'concat' to correspond with original TensorFlow implementation.\")\n",
    "\n",
    "        # First Bi-GRU layer\n",
    "        self.gru1 = nn.GRU(\n",
    "            input_size=latent_dim,\n",
    "            hidden_size=latent_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(2 * latent_dim, eps=1e-3)\n",
    "\n",
    "        # Second Bi-GRU layer\n",
    "        self.gru2 = nn.GRU(\n",
    "            input_size=2 * latent_dim, # Input from first Bi-GRU\n",
    "            hidden_size=2 * latent_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(4 * latent_dim, eps=1e-3) # Output of second Bi-GRU is 2 * (2*latent_dim)\n",
    "\n",
    "        # Convolutional Layer\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=4 * latent_dim, # Input from second norm layer\n",
    "            out_channels=2 * latent_dim,\n",
    "            kernel_size=5,\n",
    "            padding=\"same\",\n",
    "            bias=False\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(2 * latent_dim, eps=1e-3) # Output of Conv1D\n",
    "\n",
    "        # Probabilistic Layer \n",
    "        self.prob_decoder = ProbabilisticDecoderPT(\n",
    "            hidden_dim=2 * latent_dim, # Input from third norm layer\n",
    "            data_dim=output_shape[1]\n",
    "        )\n",
    "\n",
    "    def forward(self, g: torch.Tensor, x: torch.Tensor) -> TransformedDistribution:\n",
    "        B, T, _ = x.shape\n",
    "\n",
    "        # 1. Create the validity mask and sequence lengths from input 'x'\n",
    "        validity_mask = ~torch.all(x == 0.0, dim=2)\n",
    "        lengths = validity_mask.sum(dim=1).cpu().to(torch.int64)\n",
    "        valid_indices = torch.where(lengths > 0)[0]\n",
    "\n",
    "        # 2. Emulate RepeatVector\n",
    "        generator = g.unsqueeze(1).expand(-1, T, -1)\n",
    "\n",
    "        # 3. First Bi-GRU with masking\n",
    "        gru1_out_full = torch.zeros(B, T, 2 * self.latent_dim, device=g.device, dtype=g.dtype)\n",
    "        if len(valid_indices) > 0:\n",
    "            # Apply GRU whilst ignoring masked data\n",
    "            packed_input_1 = pack_padded_sequence(\n",
    "                generator[valid_indices], lengths[valid_indices], batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            packed_output_1, _ = self.gru1(packed_input_1)\n",
    "            unpacked_output_1, _ = pad_packed_sequence(\n",
    "                packed_output_1, batch_first=True, total_length=T\n",
    "            )\n",
    "            gru1_out_full[valid_indices] = unpacked_output_1\n",
    "        norm1_out = self.norm1(gru1_out_full)\n",
    "\n",
    "        # 4. Second Bi-GRU with masking (reusing the same mask/lengths)\n",
    "        gru2_out_full = torch.zeros(B, T, 4 * self.latent_dim, device=g.device, dtype=g.dtype)\n",
    "        if len(valid_indices) > 0:\n",
    "            packed_input_2 = pack_padded_sequence(\n",
    "                norm1_out[valid_indices], lengths[valid_indices], batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            packed_output_2, _ = self.gru2(packed_input_2)\n",
    "            unpacked_output_2, _ = pad_packed_sequence(\n",
    "                packed_output_2, batch_first=True, total_length=T\n",
    "            )\n",
    "            gru2_out_full[valid_indices] = unpacked_output_2\n",
    "        norm2_out = self.norm2(gru2_out_full)\n",
    "\n",
    "        # 5. Convolution Block\n",
    "        # Conv1d expects (B, C, T), so we permute\n",
    "        conv_in = norm2_out.permute(0, 2, 1)\n",
    "        conv_out = F.relu(self.conv1d(conv_in))\n",
    "        # Permute back to (B, T, C) for LayerNorm\n",
    "        norm3_in = conv_out.permute(0, 2, 1)\n",
    "        norm3_out = self.norm3(norm3_in)\n",
    "\n",
    "        # 6. Final Probabilistic Decoder\n",
    "        final_dist = self.prob_decoder(norm3_out, validity_mask)\n",
    "\n",
    "        return final_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f44e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function from the provided example to handle gate order differences\n",
    "def permute_gru_weights(keras_weights):\n",
    "    \"\"\"Permutes GRU weights from Keras (z, r, n) to PyTorch (r, z, n) format.\"\"\"\n",
    "    W_ih, W_hh, B = keras_weights\n",
    "    # Keras gate order: z, r, n (update, reset, new/candidate)\n",
    "    W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "    W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "\n",
    "    # PyTorch gate order: r, z, n (reset, update, new/candidate)\n",
    "    W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "    W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "\n",
    "    # Keras has two bias vectors (input-hidden and recurrent), which are concatenated in B\n",
    "    B_ih, B_hh = B\n",
    "    B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "    B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "\n",
    "    B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "    B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "\n",
    "    return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "    \n",
    "def transfer_recurrent_decoder_weights(tf_model, pt_model):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full recurrent decoder model.\n",
    "    \"\"\"\n",
    "    # Find layers by type to avoid index issues\n",
    "    bidi_layers = [l for l in tf_model.layers if isinstance(l, Bidirectional)]\n",
    "    norm_layers = [l for l in tf_model.layers if isinstance(l, LayerNormalization)]\n",
    "    conv_layers = [l for l in tf_model.layers if isinstance(l, tf.keras.layers.Conv1D)]\n",
    "    prob_dec_layer = next(l for l in tf_model.layers if isinstance(l, deepof.model_utils.ProbabilisticDecoder))\n",
    "\n",
    "    # --- GRU 1 and Norm 1 ---\n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(bidi_layers[0].forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1)\n",
    "    pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(bidi_layers[0].backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1)\n",
    "    pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm_layers[0].get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm_layers[0].get_weights()[1])\n",
    "\n",
    "    # --- GRU 2 and Norm 2 ---\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(bidi_layers[1].forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2)\n",
    "    pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(bidi_layers[1].backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2)\n",
    "    pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm_layers[1].get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm_layers[1].get_weights()[1])\n",
    "\n",
    "    # --- Conv1D and Norm 3 ---\n",
    "    # TF Conv1D weights: (kernel_w, kernel_h, in_c, out_c) -> (5, 1, 4*ld, 2*ld)\n",
    "    # PT Conv1d weights: (out_c, in_c, kernel_w)\n",
    "    conv_weights_tf = conv_layers[0].get_weights()[0]\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_weights_tf).squeeze(1).permute(2, 1, 0)\n",
    "    pt_model.norm3.weight.data = torch.from_numpy(norm_layers[2].get_weights()[0]); pt_model.norm3.bias.data = torch.from_numpy(norm_layers[2].get_weights()[1])\n",
    "\n",
    "    # --- Probabilistic Decoder ---\n",
    "    # TF Dense weights: (in_features, out_features)\n",
    "    # PT Linear weights: (out_features, in_features)\n",
    "    prob_dec_weights, prob_dec_bias = prob_dec_layer.time_distributer.get_weights()\n",
    "    pt_model.prob_decoder.loc_projection.weight.data = torch.from_numpy(prob_dec_weights.T)\n",
    "    pt_model.prob_decoder.loc_projection.bias.data = torch.from_numpy(prob_dec_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e2439d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_full_forward_pass_with_masking (__main__.TestRecurrentDecoderTranslation)\n",
      "Test the full decoder translation against the original TF model. ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.500s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow execution time: 0.11349749565124512\n",
      "Pytorch execution time: 0.0\n",
      "✅ Full `RecurrentDecoderPT` translation test PASSED!\n"
     ]
    }
   ],
   "source": [
    "class TestRecurrentDecoderTranslation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up the full models and transfer weights.\"\"\"\n",
    "        tf.keras.backend.clear_session()\n",
    "        # Make epsilon consistent between TF and PT LayerNorm\n",
    "        tf.keras.backend.set_epsilon(1e-3)\n",
    "\n",
    "        self.latent_dim = 16\n",
    "        self.input_shape = (15, 8)  # (T, Features)\n",
    "        self.batch_size = 4\n",
    "\n",
    "        # Instantiate the original full TensorFlow model\n",
    "        self.tf_model = get_recurrent_decoder(\n",
    "            input_shape=self.input_shape,\n",
    "            latent_dim=self.latent_dim,\n",
    "            bidirectional_merge=\"concat\"\n",
    "        )\n",
    "\n",
    "        # Instantiate the full PyTorch model\n",
    "        self.pt_model = RecurrentDecoderPT(\n",
    "            output_shape=self.input_shape,\n",
    "            latent_dim=self.latent_dim\n",
    "        )\n",
    "        self.pt_model.eval()\n",
    "\n",
    "        # Transfer all weights\n",
    "        transfer_recurrent_decoder_weights(self.tf_model, self.pt_model)\n",
    "\n",
    "        # Create test data WITH MASKING\n",
    "        self.np_latent_input = np.random.rand(self.batch_size, self.latent_dim).astype(np.float32)\n",
    "        self.np_sequence_input = np.random.rand(self.batch_size, *self.input_shape).astype(np.float32)\n",
    "        # Mask some steps for sample 0\n",
    "        self.np_sequence_input[0, -3:, :] = 0.0\n",
    "        # Mask all steps for sample 1\n",
    "        self.np_sequence_input[1, :, :] = 0.0\n",
    "\n",
    "    def test_full_forward_pass_with_masking(self):\n",
    "        \"\"\"Test the full decoder translation against the original TF model.\"\"\"\n",
    "        # TensorFlow execution\n",
    "        tf_start = time.time()\n",
    "        tf_output_dist = self.tf_model([self.np_latent_input, self.np_sequence_input], training=False)\n",
    "        # CORRECTED LINE: Call .mean() on the distribution object first\n",
    "        tf_output_np = tf_output_dist.mean().numpy()\n",
    "        tf_end = time.time()\n",
    "\n",
    "\n",
    "        # PyTorch execution\n",
    "        pt_latent_tensor = torch.from_numpy(self.np_latent_input)\n",
    "        pt_sequence_tensor = torch.from_numpy(self.np_sequence_input)\n",
    "        with torch.no_grad():\n",
    "            pt_start = time.time()\n",
    "            pt_dist = self.pt_model(pt_latent_tensor, pt_sequence_tensor)\n",
    "            # Use the .mean property to get the tensor output\n",
    "            pt_output = pt_dist.mean\n",
    "        pt_output_np = pt_output.cpu().numpy()\n",
    "        pt_end = time.time()\n",
    "\n",
    "        print(\"Tensorflow execution time: \" + str(tf_end-tf_start))\n",
    "        print(\"Pytorch execution time: \" + str(pt_end-pt_start))\n",
    "\n",
    "        # Compare the final tensor outputs\n",
    "        np.testing.assert_allclose(tf_output_np, pt_output_np, rtol=1e-5, atol=1e-4)\n",
    "        print(\"✅ Full `RecurrentDecoderPT` translation test PASSED!\")\n",
    "\n",
    "# To run in a Python script or Jupyter notebook:\n",
    "if __name__ == '__main__':\n",
    "    # Add deepof and other necessary imports from the original problem description\n",
    "    # Then run the test suite\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    suite = unittest.TestLoader().loadTestsFromTestCase(TestRecurrentDecoderTranslation)\n",
    "    runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a263a9d1",
   "metadata": {},
   "source": [
    "# Recurrent Encoder Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9744cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tcn\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from spektral.layers import CensNetConv\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    LayerNormalization,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import time\n",
    "import deepof.model_utils\n",
    "import deepof.clustering.model_utils_new\n",
    "from deepof.clustering.censNetConv_pt import CensNetConvPT\n",
    "import deepof.utils\n",
    "from deepof.data_loading import get_dt\n",
    "import warnings\n",
    "from deepof.clustering.model_utils_new import ProbabilisticDecoderPT, RecurrentBlockPT\n",
    "from torch.distributions import Distribution, TransformedDistribution\n",
    "from torch.distributions.transforms import AffineTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9f456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recurrent_encoder(\n",
    "    input_shape: tuple,\n",
    "    edge_feature_shape: tuple,\n",
    "    adjacency_matrix: np.ndarray,\n",
    "    latent_dim: int,\n",
    "    use_gnn: bool = True,\n",
    "    gru_unroll: bool = False,\n",
    "    bidirectional_merge: str = \"concat\",\n",
    "    interaction_regularization: float = 0.0,\n",
    "):\n",
    "    \"\"\"Return a deep recurrent neural encoder.\n",
    "\n",
    "     Builds a neural network capable of encoding the motion tracking instances into a vector ready to be fed to\n",
    "    one of the provided structured latent spaces.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): shape of the node features for the input data. Should be time x nodes x features.\n",
    "        edge_feature_shape (tuple): shape of the adjacency matrix to use in the graph attention layers. Should be time x edges x features.\n",
    "        adjacency_matrix (np.ndarray): adjacency matrix for the mice connectivity graph. Shape should be nodes x nodes.\n",
    "        latent_dim (int): dimension of the latent space.\n",
    "        use_gnn (bool): If True, the encoder uses a graph representation of the input, with coordinates and speeds as node attributes, and distances as edge attributes. If False, a regular 3D tensor is used as input.\n",
    "        gru_unroll (bool): whether to unroll the GRU layers. Defaults to False.\n",
    "        bidirectional_merge (str): how to merge the forward and backward GRU layers. Defaults to \"concat\".\n",
    "        interaction_regularization (float): Regularization parameter for the interaction features.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: a keras model that can be trained to encode motion tracking instances into a vector.\n",
    "\n",
    "    \"\"\"\n",
    "    # Define feature and adjacency inputs\n",
    "    x = Input(shape=input_shape)\n",
    "    a = Input(shape=edge_feature_shape)\n",
    "\n",
    "    if use_gnn:\n",
    "        x_reshaped = tf.transpose(\n",
    "            tf.reshape(\n",
    "                tf.transpose(x),\n",
    "                [\n",
    "                    -1,\n",
    "                    adjacency_matrix.shape[-1],\n",
    "                    x.shape[1],\n",
    "                    input_shape[-1] // adjacency_matrix.shape[-1],\n",
    "                ][::-1],\n",
    "            )\n",
    "        )\n",
    "        a_reshaped = tf.transpose(\n",
    "            tf.reshape(\n",
    "                tf.transpose(a),\n",
    "                [\n",
    "                    -1,\n",
    "                    edge_feature_shape[-1],\n",
    "                    a.shape[1],\n",
    "                    1,\n",
    "                ][::-1],\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    else:\n",
    "        x_flat = tf.reshape(x, [-1, input_shape[0], input_shape[1] * input_shape[2]])\n",
    "        x_reshaped = tf.expand_dims(x_flat, axis=1)\n",
    "\n",
    "    # Instantiate temporal RNN block\n",
    "    encoder = deepof.clustering.model_utils_new.get_recurrent_block(\n",
    "        x_reshaped, latent_dim, gru_unroll, bidirectional_merge\n",
    "    )(x_reshaped)\n",
    "\n",
    "\n",
    "    # Instantiate spatial graph block\n",
    "    if use_gnn:\n",
    "\n",
    "        # Embed edge features too\n",
    "        a_encoder = deepof.clustering.model_utils_new.get_recurrent_block(\n",
    "            a_reshaped, latent_dim, gru_unroll, bidirectional_merge\n",
    "        )(a_reshaped)\n",
    "    \n",
    "        spatial_block = CensNetConv(\n",
    "            node_channels=latent_dim,\n",
    "            edge_channels=latent_dim,\n",
    "            activation=\"relu\",\n",
    "            node_regularizer=tf.keras.regularizers.l1(interaction_regularization),\n",
    "        )\n",
    "\n",
    "        # Process adjacency matrix\n",
    "        laplacian, edge_laplacian, incidence = spatial_block.preprocess(\n",
    "            adjacency_matrix\n",
    "        )\n",
    "\n",
    "        # Get and concatenate node and edge embeddings\n",
    "        x_nodes, x_edges = spatial_block(\n",
    "            [encoder, (laplacian, edge_laplacian, incidence), a_encoder], mask=None\n",
    "        )\n",
    "        \n",
    "\n",
    "        x_nodes = tf.reshape(\n",
    "            x_nodes,\n",
    "            [-1, adjacency_matrix.shape[-1] * latent_dim],\n",
    "        )\n",
    "\n",
    "        x_edges = tf.reshape(\n",
    "            x_edges,\n",
    "            [-1, edge_feature_shape[-1] * latent_dim],\n",
    "        )\n",
    "\n",
    "        encoder = tf.concat([x_nodes, x_edges], axis=-1)\n",
    "\n",
    "    else:\n",
    "        encoder = tf.squeeze(encoder, axis=1)\n",
    "\n",
    "    encoder_output = tf.keras.layers.Dense(latent_dim, kernel_initializer=\"he_uniform\")(\n",
    "        encoder\n",
    "    )\n",
    "    \n",
    "    return Model([x, a], encoder_output, name=\"recurrent_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f588403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentEncoderPT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: tuple,\n",
    "        edge_feature_shape: tuple,\n",
    "        adjacency_matrix: np.ndarray,\n",
    "        latent_dim: int,\n",
    "        use_gnn: bool = True,\n",
    "        interaction_regularization: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_gnn = use_gnn\n",
    "        self.num_nodes = adjacency_matrix.shape[0]\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        if self.use_gnn:\n",
    "            # Node path initialization \n",
    "            node_feat_per_animal = input_shape[-1] // self.num_nodes\n",
    "            self.node_recurrent_block = RecurrentBlockPT(\n",
    "                input_features=node_feat_per_animal, latent_dim=latent_dim\n",
    "            )\n",
    "\n",
    "            # Edge path initialization \n",
    "            self.edge_recurrent_block = RecurrentBlockPT(\n",
    "                input_features=1, latent_dim=latent_dim\n",
    "            )\n",
    "\n",
    "            self.spatial_gnn_block = CensNetConvPT(\n",
    "                node_channels=latent_dim,\n",
    "                edge_channels=latent_dim,\n",
    "            )\n",
    "            lap, edge_lap, inc = self.spatial_gnn_block.preprocess(torch.tensor(adjacency_matrix))\n",
    "            self.register_buffer(\"laplacian\", lap.float())\n",
    "            self.register_buffer(\"edge_laplacian\", edge_lap.float())\n",
    "            self.register_buffer(\"incidence\", inc.float())\n",
    "            \n",
    "            self.num_edges = edge_feature_shape[1]\n",
    "            final_dense_in = (self.num_nodes * latent_dim) + (self.num_edges * latent_dim)\n",
    "            self.final_dense = nn.Linear(final_dense_in, latent_dim)\n",
    "\n",
    "        else: # Non-GNN path \n",
    "            in_features = input_shape[1] * input_shape[2]\n",
    "            self.recurrent_block = RecurrentBlockPT(\n",
    "                input_features=in_features, latent_dim=latent_dim\n",
    "            )\n",
    "            self.final_dense = nn.Linear(latent_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, a: torch.Tensor) -> torch.Tensor:\n",
    "        B, T, N_nodes_total, F_nodes_total = x.shape\n",
    "        _, _, E_edges_total, F_edges_total = a.shape\n",
    "\n",
    "        if self.use_gnn:\n",
    "            # --- Attempt to replicate the exact TensorFlow reshape logic ---\n",
    "            \n",
    "            # 1. Node Path\n",
    "            F_per_node = F_nodes_total // self.num_nodes\n",
    "            x_t = x.permute(3, 2, 1, 0)\n",
    "            target_shape_x = (F_per_node, T, self.num_nodes, -1)\n",
    "            x_reshaped_t = x_t.reshape(target_shape_x)\n",
    "            x_reshaped = x_reshaped_t.permute(3, 2, 1, 0)\n",
    "            \n",
    "            # 2. Edge Path\n",
    "            a_t = a.permute(3, 2, 1, 0)\n",
    "            target_shape_a = (1, T, F_edges_total, -1)\n",
    "            a_reshaped_t = a_t.reshape(target_shape_a)\n",
    "            a_reshaped = a_reshaped_t.permute(3, 2, 1, 0)\n",
    "\n",
    "            # 3. Pass through Recurrent Blocks\n",
    "            node_output = self.node_recurrent_block(x_reshaped)           \n",
    "            edge_output = self.edge_recurrent_block(a_reshaped)\n",
    "            \n",
    "            # 4. GNN and Final Layers\n",
    "            adj_tuple = (self.laplacian, self.edge_laplacian, self.incidence)\n",
    "            x_nodes, x_edges = self.spatial_gnn_block(\n",
    "                [node_output, adj_tuple, edge_output]\n",
    "            )\n",
    "            x_nodes=F.relu(x_nodes)\n",
    "            x_edges=F.relu(x_edges)\n",
    "            \n",
    "            b_prime = x_nodes.shape[0]\n",
    "            x_nodes_flat = x_nodes.view(b_prime, -1)\n",
    "            x_edges_flat = x_edges.view(b_prime, -1)\n",
    "            encoder = torch.cat([x_nodes_flat, x_edges_flat], dim=-1)\n",
    "            \n",
    "\n",
    "        else: # Non-GNN path \n",
    "            x_reshaped = x.view(B, T, N_nodes_total * F_nodes_total).unsqueeze(1)\n",
    "            encoder = self.recurrent_block(x_reshaped).squeeze(1)\n",
    "\n",
    "        return self.final_dense(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ad0fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_recurrent_block_weights(tf_model, pt_model):\n",
    "    \"\"\"Transfers weights for the full recurrent block with GRU gate permutation.\"\"\"\n",
    "    conv_td, _, gru1_td, norm1, gru2_td, norm2 = tf_model.layers[1:]\n",
    "\n",
    "\n",
    "    def permute_gru_weights(keras_weights):\n",
    "        W_ih, W_hh, B = keras_weights\n",
    "        W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "        W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "        W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "        W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "        B_ih, B_hh = B\n",
    "        B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "        B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "        B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "        B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "        return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_td.layer.get_weights()[0]).permute(2, 1, 0)\n",
    "    \n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(gru1_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1); pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    \n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(gru1_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1); pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm1.get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm1.get_weights()[1])\n",
    "\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(gru2_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2); pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    \n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(gru2_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2); pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    \n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm2.get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm2.get_weights()[1])\n",
    "\n",
    "    \n",
    "def transfer_censnet_weights(tf_layer, pt_layer):\n",
    "    \"\"\"\n",
    "    Transfers all six weights from a Spektral CensNetConv layer to the\n",
    "    corresponding CensNetConvPT layer.\n",
    "    \"\"\"\n",
    "    # Get all weights from the TensorFlow layer. The order is determined by\n",
    "    # the layer's build order in Spektral's source code.\n",
    "    tf_weights = tf_layer.get_weights()\n",
    "\n",
    "    # Unpack all six weights.\n",
    "    # Order: kernel_node, bias_node, kernel_edge, bias_edge, projector_node, projector_edge\n",
    "    kn_tf, bn_tf, ke_tf, be_tf, pn_tf, pe_tf = tf_weights\n",
    "\n",
    "    # 1. & 2. Transfer Node Kernel and Bias\n",
    "    # Keras Dense kernel is (in_features, out_features)\n",
    "    pt_layer.node_kernel.data = torch.from_numpy(kn_tf)\n",
    "    pt_layer.edge_kernel.data = torch.from_numpy(bn_tf)\n",
    "\n",
    "    # 3. & 4. Transfer Edge Kernel and Bias\n",
    "    # Same transposition logic applies.\n",
    "    pt_layer.node_weights.data = torch.from_numpy(ke_tf)\n",
    "    pt_layer.edge_weights.data = torch.from_numpy(be_tf)\n",
    "\n",
    "    # 5. Transfer Node Projector Weights (P_n)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.node_bias.data = torch.from_numpy(pn_tf)\n",
    "\n",
    "    # 6. Transfer Edge Projector Weights (P_e)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.edge_bias.data = torch.from_numpy(pe_tf)\n",
    "    \n",
    "\n",
    "def transfer_recurrent_encoder_weights(tf_model, pt_model):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full recurrent encoder, finding layers\n",
    "    by their default names and types to avoid modifying original code.\n",
    "    \"\"\"\n",
    "    # The final dense layer is consistently the last one in the model's layer list.\n",
    "    final_dense_tf = tf_model.layers[-1]\n",
    "    final_dense_pt = pt_model.final_dense\n",
    "    w, b = final_dense_tf.get_weights()\n",
    "    final_dense_pt.weight.data = torch.from_numpy(w.T)\n",
    "    final_dense_pt.bias.data = torch.from_numpy(b)\n",
    "\n",
    "    if pt_model.use_gnn:\n",
    "        # Keras automatically names nested models 'model', 'model_1', etc., by order of creation.\n",
    "        # Node recurrent block is created first.\n",
    "        node_recurrent_model = tf_model.get_layer(\"model\")\n",
    "        # Edge recurrent block is created second.\n",
    "        edge_recurrent_model = tf_model.get_layer(\"model_1\")\n",
    "        # Find the CensNetConv layer by its class type.\n",
    "        gnn_layer = next(l for l in tf_model.layers if isinstance(l, CensNetConv))\n",
    "\n",
    "        transfer_recurrent_block_weights(node_recurrent_model, pt_model.node_recurrent_block)\n",
    "        transfer_recurrent_block_weights(edge_recurrent_model, pt_model.edge_recurrent_block)\n",
    "        transfer_censnet_weights(gnn_layer, pt_model.spatial_gnn_block)\n",
    "    else: # Not using GNN\n",
    "        # There is only one nested model, which Keras names 'model'.\n",
    "        recurrent_model = tf_model.get_layer(\"model\")\n",
    "        transfer_recurrent_block_weights(recurrent_model, pt_model.recurrent_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e744d26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward_pass_gnn (__main__.TestRecurrentEncoderTranslation)\n",
      "Test the GNN-enabled path of the encoder. ... The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 76\u001b[0m\n\u001b[0;32m     74\u001b[0m runner \u001b[38;5;241m=\u001b[39m unittest\u001b[38;5;241m.\u001b[39mTextTestRunner(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     75\u001b[0m suite \u001b[38;5;241m=\u001b[39m unittest\u001b[38;5;241m.\u001b[39mTestLoader()\u001b[38;5;241m.\u001b[39mloadTestsFromTestCase(TestRecurrentEncoderTranslation)\n\u001b[1;32m---> 76\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuite\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\unittest\\runner.py:184\u001b[0m, in \u001b[0;36mTextTestRunner.run\u001b[1;34m(self, test)\u001b[0m\n\u001b[0;32m    182\u001b[0m     startTestRun()\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     stopTestRun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstopTestRun\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\unittest\\suite.py:84\u001b[0m, in \u001b[0;36mBaseTestSuite.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\unittest\\suite.py:122\u001b[0m, in \u001b[0;36mTestSuite.run\u001b[1;34m(self, result, debug)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug:\n\u001b[1;32m--> 122\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     test\u001b[38;5;241m.\u001b[39mdebug()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\unittest\\case.py:650\u001b[0m, in \u001b[0;36mTestCase.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\unittest\\case.py:591\u001b[0m, in \u001b[0;36mTestCase.run\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    589\u001b[0m outcome\u001b[38;5;241m.\u001b[39mexpecting_failure \u001b[38;5;241m=\u001b[39m expecting_failure\n\u001b[0;32m    590\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m outcome\u001b[38;5;241m.\u001b[39mtestPartExecutor(\u001b[38;5;28mself\u001b[39m, isTest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 591\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callTestMethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestMethod\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m outcome\u001b[38;5;241m.\u001b[39mexpecting_failure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m outcome\u001b[38;5;241m.\u001b[39mtestPartExecutor(\u001b[38;5;28mself\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\unittest\\case.py:549\u001b[0m, in \u001b[0;36mTestCase._callTestMethod\u001b[1;34m(self, method)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_callTestMethod\u001b[39m(\u001b[38;5;28mself\u001b[39m, method):\n\u001b[1;32m--> 549\u001b[0m     \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 40\u001b[0m, in \u001b[0;36mTestRecurrentEncoderTranslation.test_forward_pass_gnn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     38\u001b[0m tf_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     39\u001b[0m tf_output \u001b[38;5;241m=\u001b[39m tf_model_gnn([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_np, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_np], training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 40\u001b[0m tf_end \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     41\u001b[0m pt_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "Cell \u001b[1;32mIn[6], line 40\u001b[0m, in \u001b[0;36mTestRecurrentEncoderTranslation.test_forward_pass_gnn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     38\u001b[0m tf_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     39\u001b[0m tf_output \u001b[38;5;241m=\u001b[39m tf_model_gnn([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_np, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma_np], training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 40\u001b[0m tf_end \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     41\u001b[0m pt_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:634\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1368\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1311\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:494\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Petron\\Desktop\\Python_Projects\\Deepof\\dof\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2188\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2185\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2187\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2188\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2190\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2193\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Petron\\Desktop\\Python_Projects\\Deepof\\dof\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2257\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2254\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[0;32m   2255\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[1;32m-> 2257\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2258\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m   2260\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class TestRecurrentEncoderTranslation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up parameters and create random data that matches model assumptions.\"\"\"\n",
    "        tf.keras.backend.clear_session()\n",
    "        self.latent_dim = 8\n",
    "        \n",
    "        # Inits\n",
    "        self.b, self.t, self.n, self.f = 2, 10, 3, 12  # Batch, Time, Nodes, Features\n",
    "        self.e, self.f_edge = 3, 3  # Edges, Edge Features\n",
    "\n",
    "        self.input_shape = (self.t, self.n, self.f)\n",
    "        self.edge_shape = (self.t, self.e, self.f_edge)\n",
    "        self.adj_matrix = np.ones((self.n, self.n)) - np.eye(self.n)\n",
    "\n",
    "        # Create random input data\n",
    "        self.x_np = np.random.rand(self.b, self.t, self.n, self.f).astype(np.float32)\n",
    "        self.a_np = np.random.rand(self.b, self.t, self.e, self.f_edge).astype(np.float32)\n",
    "        \n",
    "    def test_forward_pass_gnn(self):\n",
    "        \"\"\"Test the GNN-enabled path of the encoder.\"\"\"\n",
    "        # Build TF and PT models\n",
    "        tf_model_gnn = get_recurrent_encoder(\n",
    "            self.input_shape, self.edge_shape, self.adj_matrix, self.latent_dim, use_gnn=True\n",
    "        )\n",
    "        pt_model_gnn = RecurrentEncoderPT(\n",
    "            self.input_shape, self.edge_shape, self.adj_matrix, self.latent_dim, use_gnn=True\n",
    "        )\n",
    "        pt_model_gnn.eval()\n",
    "\n",
    "        # Run a single \"dummy\" forward pass on the PyTorch model.\n",
    "        with torch.no_grad():\n",
    "            pt_model_gnn(torch.from_numpy(self.x_np), torch.from_numpy(self.a_np))\n",
    "\n",
    "        # Now that the weights have been initialized, we can transfer the TF values into them.\n",
    "        transfer_recurrent_encoder_weights(tf_model_gnn, pt_model_gnn)\n",
    "\n",
    "        # Execute and compare the outputs\n",
    "        tf_start = time.time()\n",
    "        tf_output = tf_model_gnn([self.x_np, self.a_np], training=False).numpy()\n",
    "        tf_end = time.time()\n",
    "        pt_start = time.time()\n",
    "        with torch.no_grad():\n",
    "            pt_output = pt_model_gnn(torch.from_numpy(self.x_np), torch.from_numpy(self.a_np)).detach().numpy()\n",
    "        pt_end = time.time()\n",
    "\n",
    "        print(\"Tensorflow execution time: \" + str(tf_end-tf_start))\n",
    "        print(\"Pytorch execution time: \" + str(pt_end-pt_start))\n",
    "\n",
    "        np.testing.assert_allclose(tf_output, pt_output, rtol=1e-5, atol=1e-4)\n",
    "        print(\"✅ `RecurrentEncoderPT` (GNN path) translation test PASSED!\")\n",
    "\n",
    "    def test_forward_pass_no_gnn(self):\n",
    "        \"\"\"Test the non-GNN path of the encoder.\"\"\"\n",
    "        # Build TF and PT models\n",
    "        tf_model_no_gnn = get_recurrent_encoder(\n",
    "            self.input_shape, self.edge_shape, self.adj_matrix, self.latent_dim, use_gnn=False\n",
    "        )\n",
    "        pt_model_no_gnn = RecurrentEncoderPT(\n",
    "            self.input_shape, self.edge_shape, self.adj_matrix, self.latent_dim, use_gnn=False\n",
    "        )\n",
    "        pt_model_no_gnn.eval()\n",
    "\n",
    "        # Transfer weights\n",
    "        transfer_recurrent_encoder_weights(tf_model_no_gnn, pt_model_no_gnn)\n",
    "\n",
    "        # Execute and compare\n",
    "        tf_output = tf_model_no_gnn([self.x_np, self.a_np], training=False).numpy()\n",
    "        pt_output = pt_model_no_gnn(torch.from_numpy(self.x_np), torch.from_numpy(self.a_np)).detach().numpy()\n",
    "\n",
    "        np.testing.assert_allclose(tf_output, pt_output, rtol=1e-5, atol=1e-5)\n",
    "        print(\"✅ `RecurrentEncoderPT` (non-GNN path) translation test PASSED!\")\n",
    "\n",
    "# To run:\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestRecurrentEncoderTranslation)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be78f0",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28daa27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "import tensorflow_probability as tfp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from typing import List, Tuple, Dict\n",
    "import time\n",
    "import deepof.model_utils\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b0bb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import Layer # Assuming ClusterControl inherits from this\n",
    "from typing import List\n",
    "\n",
    "# These are placeholders for the external utilities used in the original model\n",
    "# to make the class definition self-contained and runnable.\n",
    "class ClusterControl(Layer):\n",
    "    \"\"\"Placeholder for the custom deepof.model_utils.ClusterControl layer.\"\"\"\n",
    "    def __init__(self, batch_size, n_components, encoding_dim, k, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, inputs: List[tf.Tensor]) -> tf.Tensor:\n",
    "        # The layer is pass-through for the latent vector\n",
    "        return inputs[0]\n",
    "\n",
    "def compute_kmeans_loss(latent_means: tf.Tensor, weight: float, batch_size: int) -> tf.Tensor:\n",
    "    \"\"\"Placeholder for the custom deepof.model_utils.compute_kmeans_loss function.\"\"\"\n",
    "    gram_matrix = (tf.transpose(latent_means) @ latent_means) / tf.cast(batch_size, tf.float32)\n",
    "    s = tf.linalg.svd(gram_matrix, compute_uv=False)\n",
    "    s = tf.sqrt(tf.maximum(s, 1e-9))\n",
    "    return weight * tf.reduce_mean(s)\n",
    "\n",
    "# TensorFlow Probability layers\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "class GaussianMixtureLatent(tf.keras.models.Model):\n",
    "    \"\"\"Gaussian Mixture probabilistic latent space model.\n",
    "\n",
    "    Used to represent the embedding of motion tracking data in a mixture of Gaussians\n",
    "    with a provided number of components, with means, covariances and weights.\n",
    "    Implementation based on VaDE (https://arxiv.org/abs/1611.05148)\n",
    "    and VaDE-SC (https://openreview.net/forum?id=RQ428ZptQfU).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: tuple,\n",
    "        n_components: int,\n",
    "        latent_dim: int,\n",
    "        batch_size: int,\n",
    "        kl_warmup: int = 5,\n",
    "        kl_annealing_mode: str = \"linear\",\n",
    "        mc_kl: int = 100,\n",
    "        mmd_warmup: int = 15,\n",
    "        mmd_annealing_mode: str = \"linear\",\n",
    "        kmeans_loss: float = 0.0,\n",
    "        reg_cluster_variance: bool = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Initialize the Gaussian Mixture Latent layer.\n",
    "\n",
    "        Args:\n",
    "            input_shape (tuple): shape of the input data\n",
    "            n_components (int): number of components in the Gaussian mixture.\n",
    "            latent_dim (int): dimensionality of the latent space.\n",
    "            batch_size (int): batch size for training.\n",
    "            kl_warmup (int): number of epochs to warm up the KL divergence.\n",
    "            kl_annealing_mode (str): mode to use for annealing the KL divergence. Must be one of \"linear\" and \"sigmoid\".\n",
    "            mc_kl (int): number of Monte Carlo samples to use for computing the KL divergence.\n",
    "            mmd_warmup (int): number of epochs to warm up the MMD.\n",
    "            mmd_annealing_mode (str): mode to use for annealing the MMD. Must be one of \"linear\" and \"sigmoid\".\n",
    "            kmeans_loss (float): weight of the Gram matrix regularization loss.\n",
    "            reg_cluster_variance (bool): whether to penalize uneven cluster variances in the latent space.\n",
    "            **kwargs: keyword arguments passed to the parent class\n",
    "\n",
    "        \"\"\"\n",
    "        super(GaussianMixtureLatent, self).__init__(**kwargs)\n",
    "        self.seq_shape = input_shape[0] \n",
    "        self.n_components = n_components\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.kl_warmup = kl_warmup\n",
    "        self.kl_annealing_mode = kl_annealing_mode\n",
    "        self.mc_kl = mc_kl\n",
    "        self.mmd_warmup = mmd_warmup\n",
    "        self.mmd_annealing_mode = mmd_annealing_mode\n",
    "        self.kmeans = kmeans_loss\n",
    "        self.optimizer = Nadam(learning_rate=1e-3, clipvalue=0.75)\n",
    "        self.reg_cluster_variance = reg_cluster_variance\n",
    "        self.pretrain = tf.Variable(0.0, name=\"pretrain\", trainable=False)\n",
    "\n",
    "        # Initialize GM parameters\n",
    "        self.c_mu = tf.Variable(\n",
    "            tf.initializers.GlorotNormal()(shape=[self.n_components, self.latent_dim]),\n",
    "            name=\"mu_c\",\n",
    "        )\n",
    "        self.log_c_sigma = tf.Variable(\n",
    "            tf.initializers.GlorotNormal()([self.n_components, self.latent_dim]),\n",
    "            name=\"log_sigma_c\",\n",
    "        )\n",
    "\n",
    "        # Initialize the Gaussian Mixture prior with the specified number of components\n",
    "        self.prior = tf.constant(tf.ones([self.n_components]) * (1 / self.n_components))\n",
    "\n",
    "        # Initialize layers\n",
    "        self.z_gauss_mean = Dense(\n",
    "            tfpl.IndependentNormal.params_size(self.latent_dim) // 2,\n",
    "            name=\"cluster_means\",\n",
    "            activation=\"linear\",\n",
    "            kernel_initializer=\"glorot_uniform\",\n",
    "            activity_regularizer=None,\n",
    "        )\n",
    "        self.z_gauss_var = Dense(\n",
    "            tfpl.IndependentNormal.params_size(self.latent_dim) // 2,\n",
    "            name=\"cluster_variances\",\n",
    "            activation=\"softplus\",\n",
    "            kernel_initializer=\"glorot_uniform\",\n",
    "            activity_regularizer=tf.keras.regularizers.l1(0.1),\n",
    "        )\n",
    "\n",
    "        self.cluster_control_layer = deepof.model_utils.ClusterControl(\n",
    "            batch_size=self.batch_size,\n",
    "            n_components=self.n_components,\n",
    "            encoding_dim=self.latent_dim,\n",
    "            k=self.n_components,\n",
    "        )\n",
    "\n",
    "        # control KL weight\n",
    "        self.kl_warm_up_iters = tf.cast(\n",
    "            self.kl_warmup * (self.seq_shape // self.batch_size), tf.int64\n",
    "        )\n",
    "        self._kl_weight = tf.Variable(\n",
    "            1.0, trainable=False, dtype=tf.float32, name=\"kl_weight\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training=False, epsilon=None, return_all_outputs_for_testing=False): # pragma: no cover\n",
    "        \"\"\"Compute the output of the layer.\"\"\"\n",
    "        z_gauss_mean = self.z_gauss_mean(inputs)\n",
    "        z_gauss_var = self.z_gauss_var(inputs)\n",
    "\n",
    "        if epsilon is not None:\n",
    "            # Use deterministic reparameterization for testing\n",
    "            z_sample = z_gauss_mean + tf.math.sqrt(tf.math.exp(z_gauss_var)) * epsilon\n",
    "        else:\n",
    "            # Original stochastic sampling for production\n",
    "            z_dist = tfd.MultivariateNormalDiag(\n",
    "                loc=z_gauss_mean, scale_diag=tf.math.sqrt(tf.math.exp(z_gauss_var))\n",
    "            )\n",
    "            z_sample = tf.squeeze(z_dist.sample())\n",
    "\n",
    "        # Compute embedding probabilities given each cluster\n",
    "        p_z_c = tf.stack(\n",
    "            [\n",
    "                tfd.MultivariateNormalDiag(\n",
    "                    loc=self.c_mu[i, :],\n",
    "                    scale_diag=tf.math.exp(self.log_c_sigma)[i, :],\n",
    "                ).log_prob((z_sample if training else z_gauss_mean))\n",
    "                + 1e-6\n",
    "                for i in range(self.n_components)\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "\n",
    "        # Update prior\n",
    "        prior = self.prior\n",
    "\n",
    "        # Compute cluster probabilitie given embedding\n",
    "        z_cat = tf.math.log(prior + 1e-6) + p_z_c\n",
    "        z_cat = tf.nn.log_softmax(z_cat, axis=-1)\n",
    "        z_cat = tf.math.exp(z_cat)\n",
    "\n",
    "        # Add clustering loss\n",
    "        loss_clustering = -tf.reduce_sum(\n",
    "            tf.multiply(z_cat, tf.math.softmax(p_z_c, axis=-1)), axis=-1\n",
    "        ) * (1.0 - tf.cast(self.pretrain, tf.float32))\n",
    "        loss_prior = -tf.math.reduce_sum(\n",
    "            tf.math.xlogy(z_cat, 1e-6 + prior), axis=-1\n",
    "        ) * (1.0 - tf.cast(self.pretrain, tf.float32))\n",
    "\n",
    "        #self.add_metric(loss_clustering, name=\"clustering_loss\", aggregation=\"mean\")\n",
    "        #self.add_metric(loss_prior, name=\"prior_loss\", aggregation=\"mean\")\n",
    "\n",
    "        # Update KL weight based on the current iteration\n",
    "        if self.kl_warm_up_iters > 0:\n",
    "            if self.kl_annealing_mode in [\"linear\", \"sigmoid\"]:\n",
    "                self._kl_weight = tf.cast(\n",
    "                    tf.keras.backend.min(\n",
    "                        [self.optimizer.iterations / self.kl_warm_up_iters, 1.0]\n",
    "                    ),\n",
    "                    tf.float32,\n",
    "                )\n",
    "                if self.kl_annealing_mode == \"sigmoid\":\n",
    "                    self._kl_weight = tf.math.sigmoid(\n",
    "                        (2 * self._kl_weight - 1)\n",
    "                        / (self._kl_weight - self._kl_weight**2)\n",
    "                    )\n",
    "            else:\n",
    "                raise NotImplementedError(\n",
    "                    \"annealing_mode must be one of 'linear' and 'sigmoid'\"\n",
    "                )\n",
    "        else:\n",
    "            self._kl_weight = tf.cast(1.0, tf.float32)\n",
    "\n",
    "        loss_variational_1 = -1 / 2 * tf.reduce_sum(z_gauss_var + 1, axis=-1)\n",
    "        loss_variational_2 = tf.math.reduce_sum(\n",
    "            tf.math.xlogy(z_cat, 1e-6 + z_cat), axis=-1\n",
    "        )\n",
    "        kl = loss_variational_1 + loss_variational_2 * (\n",
    "            1.0 - tf.cast(self.pretrain, tf.float32)\n",
    "        )\n",
    "        kl_batch = self._kl_weight * kl\n",
    "\n",
    "        #self.add_metric(self._kl_weight, aggregation=\"mean\", name=\"kl_weight\")\n",
    "        #self.add_metric(kl, aggregation=\"mean\", name=\"kl_divergence\")\n",
    "\n",
    "        #self.add_loss(tf.math.reduce_mean(loss_clustering))\n",
    "        #self.add_loss(tf.math.reduce_mean(loss_prior))\n",
    "        #self.add_loss(tf.math.reduce_mean(kl_batch))\n",
    "\n",
    "\n",
    "        # Calculate metrics for potential return\n",
    "        hard_groups = tf.math.argmax(z_cat, axis=1)\n",
    "        max_groups = tf.reduce_max(z_cat, axis=1)\n",
    "        n_populated = tf.cast(tf.shape(tf.unique(tf.reshape(hard_groups, [-1]))[0])[0], tf.float32)\n",
    "        confidence = tf.reduce_mean(max_groups)\n",
    "\n",
    "        z = z_sample if training else z_gauss_mean\n",
    "\n",
    "        if self.n_components > 1:\n",
    "            z = self.cluster_control_layer([z, z_cat])\n",
    "\n",
    "        k_loss = 0.0\n",
    "        if self.kmeans:\n",
    "            k_loss = deepof.model_utils.compute_kmeans_loss(z, weight=self.kmeans, batch_size=self.batch_size)\n",
    "            #self.add_loss(k_loss)\n",
    "            #self.add_metric(k_loss, name=\"kmeans_loss\")\n",
    "\n",
    "        # MODIFIED: Add a switch for the return value\n",
    "        if return_all_outputs_for_testing:\n",
    "            # In test mode, return all computed values for direct comparison\n",
    "            return z, z_cat, n_populated, confidence, k_loss\n",
    "        else:\n",
    "            # In production mode, use side effects (add_loss/add_metric) and return the original signature\n",
    "            loss_clustering = -tf.reduce_sum(tf.multiply(z_cat, tf.math.softmax(p_z_c, axis=-1)), axis=-1) * (1.0 - tf.cast(self.pretrain, tf.float32))\n",
    "            loss_prior = -tf.reduce_sum(tf.math.xlogy(z_cat, 1e-6 + self.prior), axis=-1) * (1.0 - tf.cast(self.pretrain, tf.float32))\n",
    "            self.add_metric(loss_clustering, name=\"clustering_loss\", aggregation=\"mean\")\n",
    "            self.add_metric(loss_prior, name=\"prior_loss\", aggregation=\"mean\")\n",
    "\n",
    "            self.add_metric(self._kl_weight, aggregation=\"mean\", name=\"kl_weight\")\n",
    "            self.add_metric(kl, aggregation=\"mean\", name=\"kl_divergence\")\n",
    "\n",
    "            self.add_loss(tf.math.reduce_mean(loss_clustering))\n",
    "            self.add_loss(tf.math.reduce_mean(loss_prior))\n",
    "            self.add_loss(tf.math.reduce_mean(kl_batch))\n",
    "\n",
    "            if self.kmeans:\n",
    "                self.add_loss(k_loss)\n",
    "                self.add_metric(k_loss, name=\"kmeans_loss\")\n",
    "\n",
    "            # ... all other add_loss and add_metric calls from the original ...\n",
    "            return z, z_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "034c7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "class ClusterControlPT(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates clustering metrics. This is a pass-through layer for the main\n",
    "    latent vector `z`, returning it unmodified alongside a dictionary of metrics.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(\n",
    "        self, z: torch.Tensor, z_cat: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Calculates metrics and passes the latent vector `z` through.\n",
    "\n",
    "        Args:\n",
    "            z: The latent vector (batch_size, latent_dim).\n",
    "            z_cat: Cluster probabilities (batch_size, n_components).\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing the unmodified `z` and a dictionary of metrics.\n",
    "        \"\"\"\n",
    "        confidence, hard_groups = torch.max(z_cat, dim=1)\n",
    "        \n",
    "        # Calculate the number of unique clusters populated in the batch\n",
    "        num_populated = torch.unique(hard_groups).numel()\n",
    "        \n",
    "        metrics = {\n",
    "            \"number_of_populated_clusters\": torch.tensor(\n",
    "                float(num_populated), device=z.device\n",
    "            ),\n",
    "            \"confidence_in_selected_cluster\": torch.mean(confidence),\n",
    "        }\n",
    "        \n",
    "        return z, metrics\n",
    "\n",
    "def compute_kmeans_loss_pt(latent_means: torch.Tensor, weight: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes a loss based on the singular values of the Gram matrix of the\n",
    "    latent vectors, encouraging orthogonality.\n",
    "\n",
    "    Args:\n",
    "        latent_means: The latent vectors from the model (batch_size, latent_dim).\n",
    "        weight: The weight to apply to this loss component.\n",
    "\n",
    "    Returns:\n",
    "        The calculated scalar loss tensor.\n",
    "    \"\"\"\n",
    "    batch_size = float(latent_means.shape[0])\n",
    "    gram_matrix = (latent_means.T @ latent_means) / batch_size\n",
    "    \n",
    "    # Compute singular values, which are the square roots of the eigenvalues for a symmetric matrix\n",
    "    singular_values = torch.linalg.svdvals(gram_matrix)\n",
    "    \n",
    "    # Clamp to avoid NaN gradients from sqrt(0)\n",
    "    penalization = torch.sqrt(torch.clamp(singular_values, min=1e-9))\n",
    "    \n",
    "    return weight * torch.mean(penalization)\n",
    "\n",
    "\n",
    "class GaussianMixtureLatentPT(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of the Gaussian Mixture probabilistic latent space model.\n",
    "    It embeds data into a latent space and models that space as a mixture of Gaussians.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        n_components: int,\n",
    "        latent_dim: int,\n",
    "        kmeans: float,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.n_components = n_components\n",
    "        self.latent_dim = latent_dim\n",
    "        self.kmeans_weight = kmeans\n",
    "\n",
    "        # --- Trainable Parameters for the GMM components ---\n",
    "        self.gmm_means = nn.Parameter(torch.empty(n_components, latent_dim))\n",
    "        self.gmm_log_vars = nn.Parameter(torch.empty(n_components, latent_dim))\n",
    "        nn.init.xavier_normal_(self.gmm_means)\n",
    "        nn.init.xavier_normal_(self.gmm_log_vars)\n",
    "\n",
    "        # --- Encoder Layers to produce the latent distribution ---\n",
    "        self.encoder_mean = nn.Linear(self.input_dim, self.latent_dim)\n",
    "        self.encoder_log_var = nn.Linear(self.input_dim, self.latent_dim)\n",
    "\n",
    "        # --- Non-trainable Buffers ---\n",
    "        self.register_buffer('prior', torch.ones(n_components) / n_components)\n",
    "        self.register_buffer('pretrain', torch.tensor(0.0))\n",
    "        \n",
    "        # --- Helper Layers ---\n",
    "        self.cluster_control = ClusterControlPT()\n",
    "\n",
    "    def _encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Encodes the input into mean and log-variance of the latent distribution.\"\"\"\n",
    "        z_mean = self.encoder_mean(x)\n",
    "        z_log_var = self.encoder_log_var(x) # Note: softplus is applied in the forward pass\n",
    "        return z_mean, z_log_var\n",
    "\n",
    "    def _reparameterize(\n",
    "        self, mean: torch.Tensor, var: torch.Tensor, epsilon: torch.Tensor = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs reparameterization.\n",
    "        MODIFIED to exactly replicate the original TF model's non-standard scale calculation.\n",
    "        \"\"\"\n",
    "        # Original TF logic: scale = sqrt(exp(variance))\n",
    "        # The 'var' input here is the direct output of the softplus activation.\n",
    "        scale = torch.sqrt(torch.exp(var))\n",
    "        \n",
    "        if epsilon is None:\n",
    "            epsilon = torch.randn_like(scale)\n",
    "        return mean + scale * epsilon\n",
    "\n",
    "    def _calculate_posterior(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Calculates the posterior probability p(c|z) for each sample.\"\"\"\n",
    "        # MODIFIED: The GMM parameters from TF are log-std-dev, not log-variance.\n",
    "        # So we just exponentiate them to get the scale.\n",
    "        gmm_scale = torch.exp(self.gmm_log_vars)\n",
    "\n",
    "        gmm_dist = Normal(\n",
    "            loc=self.gmm_means.unsqueeze(0),\n",
    "            scale=gmm_scale.unsqueeze(0)\n",
    "        )\n",
    "        log_p_z_given_c = gmm_dist.log_prob(z.unsqueeze(1)).sum(dim=-1)\n",
    "        \n",
    "        log_p_c_given_z = torch.log(self.prior + 1e-9) + log_p_z_given_c\n",
    "        \n",
    "        return F.softmax(log_p_c_given_z, dim=-1)\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, epsilon: torch.Tensor = None\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        z_mean, z_var_raw = self._encode(x)\n",
    "        z_var = F.softplus(z_var_raw) # Apply activation\n",
    "\n",
    "        # Pass z_var directly, not z_log_var\n",
    "        z_sample = self._reparameterize(z_mean, z_var, epsilon)\n",
    "        # ... rest of the method is the same ...\n",
    "        z_for_downstream = z_sample if self.training else z_mean\n",
    "        z_cat = self._calculate_posterior(z_for_downstream)\n",
    "        z_final, metrics = self.cluster_control(z_for_downstream, z_cat)\n",
    "        kmeans_loss = torch.tensor(0.0, device=x.device)\n",
    "        if self.kmeans_weight > 0:\n",
    "            kmeans_loss = compute_kmeans_loss_pt(z_final, weight=self.kmeans_weight)\n",
    "        return (z_final, z_cat, metrics[\"number_of_populated_clusters\"], metrics[\"confidence_in_selected_cluster\"], kmeans_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e57d957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_gmm_weights(tf_model, pt_model: GaussianMixtureLatentPT):\n",
    "    \"\"\"\n",
    "    Transfers weights from the final TF model to the refactored PT model,\n",
    "    using the updated attribute names.\n",
    "    \"\"\"\n",
    "    # --- Transfer GMM component parameters ---\n",
    "    # OLD: pt_model.c_mu\n",
    "    pt_model.gmm_means.data = torch.from_numpy(tf_model.c_mu.numpy())\n",
    "    # OLD: pt_model.log_c_sigma\n",
    "    pt_model.gmm_log_vars.data = torch.from_numpy(tf_model.log_c_sigma.numpy())\n",
    "\n",
    "    # --- Transfer Encoder layer parameters ---\n",
    "    tf_mean_weights = tf_model.z_gauss_mean.get_weights()\n",
    "    # OLD: pt_model.z_gauss_mean\n",
    "    pt_model.encoder_mean.weight.data = torch.from_numpy(tf_mean_weights[0].T)\n",
    "    pt_model.encoder_mean.bias.data = torch.from_numpy(tf_mean_weights[1])\n",
    "    \n",
    "    tf_var_weights = tf_model.z_gauss_var.get_weights()\n",
    "    # OLD: pt_model.z_gauss_var\n",
    "    pt_model.encoder_log_var.weight.data = torch.from_numpy(tf_var_weights[0].T)\n",
    "    pt_model.encoder_log_var.bias.data = torch.from_numpy(tf_var_weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "657aeb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_final_pass_eval_mode (__main__.TestGMMFinalSimplified) ... ok\n",
      "test_final_pass_train_mode (__main__.TestGMMFinalSimplified) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing final integration in EVALUATION mode ---\n",
      "Tensorflow execution time: 0.061212778091430664\n",
      "Pytorch execution time: 0.0057981014251708984\n",
      "Comparing all outputs...\n",
      "✅ Final integration in EVALUATION mode PASSED!\n",
      "\n",
      "--- Testing final integration in TRAINING mode ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.322s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow execution time: 0.04517531394958496\n",
      "Pytorch execution time: 0.0\n",
      "Comparing all outputs...\n",
      "✅ Final integration in TRAINING mode PASSED!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestGMMFinalSimplified(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.input_dim, self.latent_dim, self.n_components, self.batch_size = 64, 16, 5, 4\n",
    "        self.seq_shape = self.batch_size * 100\n",
    "        self.kmeans_weight = 0.1\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        # Instantiate the *actual* final TF model\n",
    "        self.tf_model = GaussianMixtureLatent(\n",
    "            input_shape=(self.seq_shape, self.input_dim),\n",
    "            n_components=self.n_components,\n",
    "            latent_dim=self.latent_dim,\n",
    "            batch_size=self.batch_size,\n",
    "            kmeans_loss=self.kmeans_weight\n",
    "        )\n",
    "        # Build the model using the test-mode signature\n",
    "        self.tf_model(\n",
    "            tf.zeros((1, self.input_dim)), \n",
    "            epsilon=tf.zeros((1, self.latent_dim)),\n",
    "            return_all_outputs_for_testing=True\n",
    "        )\n",
    "\n",
    "        # PyTorch model setup remains the same\n",
    "        self.pt_model = GaussianMixtureLatentPT(\n",
    "            input_dim=self.input_dim, n_components=self.n_components,\n",
    "            latent_dim=self.latent_dim, kmeans=self.kmeans_weight\n",
    "        )\n",
    "        \n",
    "        transfer_gmm_weights(self.tf_model, self.pt_model)\n",
    "        \n",
    "        self.np_input = np.random.rand(self.batch_size, self.input_dim).astype(np.float32)\n",
    "        seed = 42\n",
    "        np.random.seed(seed)\n",
    "        epsilon_np = np.random.randn(self.batch_size, self.latent_dim).astype(np.float32)\n",
    "        self.epsilon_tf = tf.convert_to_tensor(epsilon_np)\n",
    "        self.epsilon_pt = torch.from_numpy(epsilon_np)\n",
    "\n",
    "    def run_comparison_test(self, training_mode: bool):\n",
    "        mode_str = \"TRAINING\" if training_mode else \"EVALUATION\"\n",
    "        print(f\"\\n--- Testing final integration in {mode_str} mode ---\")\n",
    "        \n",
    "        self.pt_model.train(training_mode)\n",
    "\n",
    "        tf_start = time.time()\n",
    "        # Call the TF model with test flags enabled\n",
    "        tf_z, tf_z_cat, tf_n_pop, tf_conf, tf_kmeans = self.tf_model(\n",
    "            self.np_input, \n",
    "            training=training_mode, \n",
    "            epsilon=self.epsilon_tf, \n",
    "            return_all_outputs_for_testing=True\n",
    "        )\n",
    "        tf_end = time.time()\n",
    "        \n",
    "        pt_start = time.time()\n",
    "        # PyTorch call remains the same\n",
    "        with torch.no_grad():\n",
    "            pt_z, pt_z_cat, pt_n_pop, pt_conf, pt_kmeans = self.pt_model(\n",
    "                torch.from_numpy(self.np_input), epsilon=self.epsilon_pt\n",
    "            )\n",
    "        pt_end = time.time()\n",
    "        \n",
    "        print(\"Tensorflow execution time: \" + str(tf_end-tf_start))\n",
    "        print(\"Pytorch execution time: \" + str(pt_end-pt_start))\n",
    "        \n",
    "        print(\"Comparing all outputs...\")\n",
    "        np.testing.assert_allclose(tf_z.numpy(), pt_z.numpy(), rtol=1e-5, atol=1e-5)\n",
    "        np.testing.assert_allclose(tf_z_cat.numpy(), pt_z_cat.numpy(), rtol=1e-5, atol=1e-5)\n",
    "        np.testing.assert_allclose(tf_n_pop.numpy(), pt_n_pop.numpy(), rtol=1e-5, atol=1e-5)\n",
    "        np.testing.assert_allclose(tf_conf.numpy(), pt_conf.numpy(), rtol=1e-5, atol=1e-5)\n",
    "        np.testing.assert_allclose(tf_kmeans.numpy(), pt_kmeans.numpy(), rtol=1e-5, atol=1e-5)\n",
    "        print(f\"✅ Final integration in {mode_str} mode PASSED!\")\n",
    "\n",
    "    def test_final_pass_train_mode(self):\n",
    "        self.run_comparison_test(training_mode=True)\n",
    "    \n",
    "    def test_final_pass_eval_mode(self):\n",
    "        self.run_comparison_test(training_mode=False)\n",
    "\n",
    "\n",
    "# Run the test\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestGMMFinalSimplified)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e442e",
   "metadata": {},
   "source": [
    "# Get Vade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c2c93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "import tensorflow_probability as tfp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "import time\n",
    "import deepof.model_utils\n",
    "from deepof.model_utils import ClusterControl, compute_kmeans_loss, CensNetConv, ProbabilisticDecoder\n",
    "from deepof.models import get_recurrent_encoder, get_recurrent_decoder, GaussianMixtureLatent, get_TCN_encoder, get_TCN_decoder, get_transformer_encoder, get_transformer_decoder\n",
    "from deepof.clustering.models_new import RecurrentEncoderPT, RecurrentDecoderPT, GaussianMixtureLatentPT\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    LayerNormalization,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    ")\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9590d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vade(\n",
    "    input_shape: tuple,\n",
    "    edge_feature_shape: tuple,\n",
    "    adjacency_matrix: np.ndarray,\n",
    "    latent_dim: int,\n",
    "    use_gnn: bool,\n",
    "    n_components: int,\n",
    "    batch_size: int = 64,\n",
    "    kl_warmup: int = 15,\n",
    "    kl_annealing_mode: str = \"sigmoid\",\n",
    "    mc_kl: int = 100,\n",
    "    kmeans_loss: float = 1.0,\n",
    "    reg_cluster_variance: bool = False,\n",
    "    encoder_type: str = \"recurrent\",\n",
    "    interaction_regularization: float = 0.0,\n",
    "):\n",
    "    \"\"\"Build a Gaussian mixture variational autoencoder (VaDE) model, adapted to the DeepOF setting.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): shape of the input data.\n",
    "        edge_feature_shape (tuple): shape of the edge feature matrix used for graph representations.\n",
    "        adjacency_matrix (np.ndarray): adjacency matrix of the connectivity graph to use.\n",
    "        latent_dim (int): dimensionality of the latent space.\n",
    "        use_gnn (bool): If True, the encoder uses a graph representation of the input, with coordinates and speeds as node attributes, and distances as edge attributes. If False, a regular 3D tensor is used as input.\n",
    "        n_components (int): number of components in the Gaussian mixture.\n",
    "        batch_size (int): batch size for training.\n",
    "        kl_warmup (int): Number of iterations during which to warm up the KL divergence.\n",
    "        kl_annealing_mode (str): mode to use for annealing the KL divergence. Must be one of \"linear\" and \"sigmoid\".\n",
    "        mc_kl (int): number of Monte Carlo samples to use for computing the KL divergence.\n",
    "        kmeans_loss (float): weight of the Gram matrix loss as described in deepof.model_utils.compute_kmeans_loss.\n",
    "        reg_cluster_variance (bool): whether to penalize uneven cluster variances in the latent space.\n",
    "        encoder_type (str): type of encoder to use. Can be set to \"recurrent\" (default), \"TCN\", or \"transformer\".\n",
    "        interaction_regularization (float): weight of the interaction regularization term.\n",
    "\n",
    "    Returns:\n",
    "        encoder (tf.keras.Model): connected encoder of the VQ-VAE model. Outputs a vector of shape (latent_dim,).\n",
    "        decoder (tf.keras.Model): connected decoder of the VQ-VAE model.\n",
    "        grouper (tf.keras.Model): deep clustering branch of the VQ-VAE model. Outputs a vector of shape (n_components,) for each training instance, corresponding to the soft counts for each cluster.\n",
    "        vade (tf.keras.Model): complete VaDE model\n",
    "\n",
    "    \"\"\"\n",
    "    if encoder_type == \"recurrent\":\n",
    "        encoder = get_recurrent_encoder(\n",
    "            input_shape=input_shape[1:],\n",
    "            adjacency_matrix=adjacency_matrix,\n",
    "            edge_feature_shape=edge_feature_shape[1:],\n",
    "            latent_dim=latent_dim,\n",
    "            use_gnn=use_gnn,\n",
    "            interaction_regularization=interaction_regularization,\n",
    "        )\n",
    "        decoder = get_recurrent_decoder(\n",
    "            input_shape=input_shape[1:], latent_dim=latent_dim\n",
    "        )\n",
    "\n",
    "    elif encoder_type == \"TCN\":\n",
    "        encoder = get_TCN_encoder(\n",
    "            input_shape=input_shape[1:],\n",
    "            adjacency_matrix=adjacency_matrix,\n",
    "            edge_feature_shape=edge_feature_shape[1:],\n",
    "            latent_dim=latent_dim,\n",
    "            use_gnn=use_gnn,\n",
    "            interaction_regularization=interaction_regularization,\n",
    "        )\n",
    "        decoder = get_TCN_decoder(input_shape=input_shape[1:], latent_dim=latent_dim)\n",
    "\n",
    "    elif encoder_type == \"transformer\":\n",
    "        encoder = get_transformer_encoder(\n",
    "            input_shape[1:],\n",
    "            edge_feature_shape=edge_feature_shape[1:],\n",
    "            adjacency_matrix=adjacency_matrix,\n",
    "            latent_dim=latent_dim,\n",
    "            use_gnn=use_gnn,\n",
    "            interaction_regularization=interaction_regularization,\n",
    "        )\n",
    "        decoder = get_transformer_decoder(input_shape[1:], latent_dim=latent_dim)\n",
    "\n",
    "    latent_space = GaussianMixtureLatent(\n",
    "        input_shape=input_shape[0],\n",
    "        n_components=n_components,\n",
    "        latent_dim=latent_dim,\n",
    "        batch_size=batch_size,\n",
    "        kl_warmup=kl_warmup,\n",
    "        kl_annealing_mode=kl_annealing_mode,\n",
    "        mc_kl=mc_kl,\n",
    "        kmeans_loss=kmeans_loss,\n",
    "        reg_cluster_variance=reg_cluster_variance,\n",
    "        name=\"gaussian_mixture_latent\",\n",
    "    )\n",
    "\n",
    "    # Connect encoder and latent space\n",
    "    inputs = Input(input_shape[1:])\n",
    "    a = tf.keras.layers.Input(edge_feature_shape[1:], name=\"encoder_edge_features\")\n",
    "    encoder_outputs = encoder([inputs, a])\n",
    "    latent, categorical = latent_space(encoder_outputs)\n",
    "    embedding = tf.keras.Model([inputs, a], latent, name=\"encoder\")\n",
    "    grouper = tf.keras.Model([inputs, a], categorical, name=\"grouper\")\n",
    "\n",
    "    # Connect decoder\n",
    "    vade_outputs = decoder([embedding.outputs, inputs])\n",
    "\n",
    "    # Instantiate fully connected model\n",
    "    vade = tf.keras.Model(embedding.inputs, vade_outputs, name=\"VaDE\")\n",
    "\n",
    "    return embedding, decoder, grouper, vade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b985dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "# Assume the following translated blocks are imported and available:\n",
    "# from deepof.clustering.models_new import (\n",
    "#     RecurrentEncoderPT, RecurrentDecoderPT, GaussianMixtureLatentPT\n",
    "# )\n",
    "# And their corresponding TensorFlow versions and weight transfer functions are also available.\n",
    "\n",
    "class VaDEPT(nn.Module):\n",
    "    \"\"\"\n",
    "    A self-contained PyTorch implementation of the VaDE model.\n",
    "\n",
    "    This class encapsulates the entire VaDE architecture, including the encoder,\n",
    "    the Gaussian mixture latent space, and the decoder. It is instantiated with\n",
    "    all necessary configuration parameters, building its sub-modules internally.\n",
    "    This provides a clean, single-object interface for the model.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: tuple,\n",
    "        edge_feature_shape: tuple,\n",
    "        adjacency_matrix: np.ndarray,\n",
    "        latent_dim: int,\n",
    "        n_components: int,\n",
    "        use_gnn: bool = True,\n",
    "        kmeans_loss: float = 1.0,\n",
    "        interaction_regularization: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes and builds the VaDE model and its components.\n",
    "\n",
    "        Args:\n",
    "            input_shape (tuple): Shape of the input node features (Time, Nodes, Features_per_node).\n",
    "            edge_feature_shape (tuple): Shape of the edge features (Time, Edges, Features_per_edge).\n",
    "            adjacency_matrix (np.ndarray): Adjacency matrix of the connectivity graph.\n",
    "            latent_dim (int): Dimensionality of the latent space.\n",
    "            n_components (int): Number of components in the Gaussian mixture.\n",
    "            use_gnn (bool): If True, use the GNN-based encoder.\n",
    "            kmeans_loss (float): Weight of the k-means style loss in the latent space.\n",
    "            interaction_regularization (float): Regularization for GNN interaction features.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store key dimensions for internal use (e.g., reshaping in forward pass)\n",
    "        time_steps, n_nodes, n_features_per_node = input_shape\n",
    "        self.input_n_nodes = n_nodes\n",
    "        self.input_n_features_per_node = n_features_per_node\n",
    "\n",
    "        # 1. Instantiate Encoder\n",
    "        self.encoder = RecurrentEncoderPT(\n",
    "            input_shape=input_shape,\n",
    "            edge_feature_shape=edge_feature_shape,\n",
    "            adjacency_matrix=adjacency_matrix,\n",
    "            latent_dim=latent_dim,\n",
    "            use_gnn=use_gnn,\n",
    "            interaction_regularization=interaction_regularization,\n",
    "        )\n",
    "\n",
    "        # 2. Instantiate Latent Space\n",
    "        self.latent_space = GaussianMixtureLatentPT(\n",
    "            input_dim=latent_dim,\n",
    "            n_components=n_components,\n",
    "            latent_dim=latent_dim,\n",
    "            kmeans=kmeans_loss,\n",
    "        )\n",
    "\n",
    "        # 3. Instantiate Decoder\n",
    "        decoder_output_features = n_nodes * n_features_per_node\n",
    "        self.decoder = RecurrentDecoderPT(\n",
    "            output_shape=(time_steps, decoder_output_features),\n",
    "            latent_dim=latent_dim,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, a: torch.Tensor\n",
    "    ) -> Tuple[torch.distributions.Distribution, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Defines the full forward pass for the VaDE model (training and evaluation).\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input node features tensor (B, T, N, F_node).\n",
    "            a (torch.Tensor): Input edge features tensor (B, T, E, F_edge).\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing:\n",
    "            - reconstruction_dist (torch.distributions.Distribution): The output distribution from the decoder.\n",
    "            - latent (torch.Tensor): The sampled latent representation from the GMM space.\n",
    "            - categorical (torch.Tensor): The cluster probabilities (soft assignments).\n",
    "            - kmeans_loss (torch.Tensor): The k-means regularization loss from the latent space.\n",
    "        \"\"\"\n",
    "        # 1. Encode the input to get the pre-latent representation\n",
    "        encoder_output = self.encoder(x, a)\n",
    "        \n",
    "        # 2. Pass through GMM latent space\n",
    "        latent, categorical, _, _, kmeans_loss, gmm_params = self.latent_space(encoder_output)\n",
    "        \n",
    "        # 3. Decode the latent sample back to the original data space\n",
    "        # Reshape x to (B, T, N*F) for the decoder's masking logic\n",
    "        B, T, _, _ = x.shape\n",
    "        x_for_decoder = x.view(B, T, self.input_n_nodes * self.input_n_features_per_node)\n",
    "        \n",
    "        reconstruction_dist = self.decoder(latent, x_for_decoder)\n",
    "        \n",
    "        return reconstruction_dist, latent, categorical, kmeans_loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def embed(self, x: torch.Tensor, a: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Inference-only method to get the latent embedding. Equivalent to the 'embedding' Keras model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input node features tensor.\n",
    "            a (torch.Tensor): Input edge features tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The latent representation `z`.\n",
    "        \"\"\"\n",
    "        encoder_output = self.encoder(x, a)\n",
    "        latent, _, _, _, _, _ = self.latent_space(encoder_output)\n",
    "        return latent\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def group(self, x: torch.Tensor, a: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Inference-only method to get cluster probabilities. Equivalent to the 'grouper' Keras model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input node features tensor.\n",
    "            a (torch.Tensor): Input edge features tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The soft cluster assignments (categorical probabilities).\n",
    "        \"\"\"\n",
    "        encoder_output = self.encoder(x, a)\n",
    "        _, categorical, _, _, _, _ = self.latent_space(encoder_output)\n",
    "        return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ec8fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_recurrent_block_weights(tf_model, pt_model):\n",
    "    \"\"\"Transfers weights for the full recurrent block with GRU gate permutation.\"\"\"\n",
    "    conv_td, _, gru1_td, norm1, gru2_td, norm2 = tf_model.layers[1:]\n",
    "\n",
    "\n",
    "    def permute_gru_weights(keras_weights):\n",
    "        W_ih, W_hh, B = keras_weights\n",
    "        W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "        W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "        W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "        W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "        B_ih, B_hh = B\n",
    "        B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "        B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "        B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "        B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "        return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_td.layer.get_weights()[0]).permute(2, 1, 0)\n",
    "    \n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(gru1_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1); pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    \n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(gru1_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1); pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm1.get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm1.get_weights()[1])\n",
    "\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(gru2_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2); pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    \n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(gru2_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2); pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    \n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm2.get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm2.get_weights()[1])\n",
    "\n",
    "    \n",
    "def transfer_censnet_weights(tf_layer, pt_layer):\n",
    "    \"\"\"\n",
    "    Transfers all six weights from a Spektral CensNetConv layer to the\n",
    "    corresponding CensNetConvPT layer.\n",
    "    \"\"\"\n",
    "    # Get all weights from the TensorFlow layer. The order is determined by\n",
    "    # the layer's build order in Spektral's source code.\n",
    "    tf_weights = tf_layer.get_weights()\n",
    "\n",
    "    # Unpack all six weights.\n",
    "    # Order: kernel_node, bias_node, kernel_edge, bias_edge, projector_node, projector_edge\n",
    "    kn_tf, bn_tf, ke_tf, be_tf, pn_tf, pe_tf = tf_weights\n",
    "\n",
    "    # Build weights on first pass\n",
    "    if pt_layer.node_kernel is None:\n",
    "        # Move parameters to the same device as input tensors\n",
    "        pt_layer._build(kn_tf.T.shape, bn_tf.T.shape)\n",
    "        #pt_layer.to(kn_tf.device)\n",
    "\n",
    "    # 1. & 2. Transfer Node Kernel and Bias\n",
    "    # Keras Dense kernel is (in_features, out_features)\n",
    "    pt_layer.node_kernel.data = torch.from_numpy(kn_tf)\n",
    "    pt_layer.edge_kernel.data = torch.from_numpy(bn_tf)\n",
    "\n",
    "    # 3. & 4. Transfer Edge Kernel and Bias\n",
    "    # Same transposition logic applies.\n",
    "    pt_layer.node_weights.data = torch.from_numpy(ke_tf)\n",
    "    pt_layer.edge_weights.data = torch.from_numpy(be_tf)\n",
    "\n",
    "    # 5. Transfer Node Projector Weights (P_n)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.node_bias.data = torch.from_numpy(pn_tf)\n",
    "\n",
    "    # 6. Transfer Edge Projector Weights (P_e)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.edge_bias.data = torch.from_numpy(pe_tf)\n",
    "    \n",
    "\n",
    "def transfer_recurrent_encoder_weights(tf_model, pt_model):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full recurrent encoder, finding layers\n",
    "    by their default names and types to avoid modifying original code.\n",
    "    \"\"\"\n",
    "    # The final dense layer is consistently the last one in the model's layer list.\n",
    "    final_dense_tf = tf_model.layers[-1]\n",
    "    final_dense_pt = pt_model.final_dense\n",
    "    w, b = final_dense_tf.get_weights()\n",
    "    final_dense_pt.weight.data = torch.from_numpy(w.T)\n",
    "    final_dense_pt.bias.data = torch.from_numpy(b)\n",
    "\n",
    "    if pt_model.use_gnn:\n",
    "        # Keras automatically names nested models 'model', 'model_1', etc., by order of creation.\n",
    "        # Node recurrent block is created first.\n",
    "        node_recurrent_model = tf_model.get_layer(\"model\")\n",
    "        # Edge recurrent block is created second.\n",
    "        edge_recurrent_model = tf_model.get_layer(\"model_1\")\n",
    "        # Find the CensNetConv layer by its class type.\n",
    "        gnn_layer = next(l for l in tf_model.layers if isinstance(l, CensNetConv))\n",
    "\n",
    "        transfer_recurrent_block_weights(node_recurrent_model, pt_model.node_recurrent_block)\n",
    "        transfer_recurrent_block_weights(edge_recurrent_model, pt_model.edge_recurrent_block)\n",
    "        transfer_censnet_weights(gnn_layer, pt_model.spatial_gnn_block)\n",
    "    else: # Not using GNN\n",
    "        # There is only one nested model, which Keras names 'model'.\n",
    "        recurrent_model = tf_model.get_layer(\"model\")\n",
    "        transfer_recurrent_block_weights(recurrent_model, pt_model.recurrent_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "611f492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_gmm_weights(tf_model, pt_model: GaussianMixtureLatentPT):\n",
    "    \"\"\"\n",
    "    Transfers weights from the final TF model to the refactored PT model,\n",
    "    using the updated attribute names.\n",
    "    \"\"\"\n",
    "    # --- Transfer GMM component parameters ---\n",
    "    # OLD: pt_model.c_mu\n",
    "    pt_model.gmm_means.data = torch.from_numpy(tf_model.c_mu.numpy())\n",
    "    # OLD: pt_model.log_c_sigma\n",
    "    pt_model.gmm_log_vars.data = torch.from_numpy(tf_model.log_c_sigma.numpy())\n",
    "\n",
    "    # --- Transfer Encoder layer parameters ---\n",
    "    tf_mean_weights = tf_model.z_gauss_mean.get_weights()\n",
    "    # OLD: pt_model.z_gauss_mean\n",
    "    pt_model.encoder_mean.weight.data = torch.from_numpy(tf_mean_weights[0].T)\n",
    "    pt_model.encoder_mean.bias.data = torch.from_numpy(tf_mean_weights[1])\n",
    "    \n",
    "    tf_var_weights = tf_model.z_gauss_var.get_weights()\n",
    "    # OLD: pt_model.z_gauss_var\n",
    "    pt_model.encoder_log_var.weight.data = torch.from_numpy(tf_var_weights[0].T)\n",
    "    pt_model.encoder_log_var.bias.data = torch.from_numpy(tf_var_weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0084d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function from the provided example to handle gate order differences\n",
    "def permute_gru_weights(keras_weights):\n",
    "    \"\"\"Permutes GRU weights from Keras (z, r, n) to PyTorch (r, z, n) format.\"\"\"\n",
    "    W_ih, W_hh, B = keras_weights\n",
    "    # Keras gate order: z, r, n (update, reset, new/candidate)\n",
    "    W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "    W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "\n",
    "    # PyTorch gate order: r, z, n (reset, update, new/candidate)\n",
    "    W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "    W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "\n",
    "    # Keras has two bias vectors (input-hidden and recurrent), which are concatenated in B\n",
    "    B_ih, B_hh = B\n",
    "    B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "    B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "\n",
    "    B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "    B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "\n",
    "    return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "    \n",
    "def transfer_recurrent_decoder_weights(tf_model, pt_model):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full recurrent decoder model.\n",
    "    \"\"\"\n",
    "    # Find layers by type to avoid index issues\n",
    "    bidi_layers = [l for l in tf_model.layers if isinstance(l, Bidirectional)]\n",
    "    norm_layers = [l for l in tf_model.layers if isinstance(l, LayerNormalization)]\n",
    "    conv_layers = [l for l in tf_model.layers if isinstance(l, tf.keras.layers.Conv1D)]\n",
    "    prob_dec_layer = next(l for l in tf_model.layers if isinstance(l, deepof.model_utils.ProbabilisticDecoder))\n",
    "\n",
    "    # --- GRU 1 and Norm 1 ---\n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(bidi_layers[0].forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1)\n",
    "    pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(bidi_layers[0].backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1)\n",
    "    pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm_layers[0].get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm_layers[0].get_weights()[1])\n",
    "\n",
    "    # --- GRU 2 and Norm 2 ---\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(bidi_layers[1].forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2)\n",
    "    pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(bidi_layers[1].backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2)\n",
    "    pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm_layers[1].get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm_layers[1].get_weights()[1])\n",
    "\n",
    "    # --- Conv1D and Norm 3 ---\n",
    "    # TF Conv1D weights: (kernel_w, kernel_h, in_c, out_c) -> (5, 1, 4*ld, 2*ld)\n",
    "    # PT Conv1d weights: (out_c, in_c, kernel_w)\n",
    "    conv_weights_tf = conv_layers[0].get_weights()[0]\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_weights_tf).squeeze(1).permute(2, 1, 0)\n",
    "    pt_model.norm3.weight.data = torch.from_numpy(norm_layers[2].get_weights()[0]); pt_model.norm3.bias.data = torch.from_numpy(norm_layers[2].get_weights()[1])\n",
    "\n",
    "    # --- Probabilistic Decoder ---\n",
    "    # TF Dense weights: (in_features, out_features)\n",
    "    # PT Linear weights: (out_features, in_features)\n",
    "    prob_dec_weights, prob_dec_bias = prob_dec_layer.time_distributer.get_weights()\n",
    "    pt_model.prob_decoder.loc_projection.weight.data = torch.from_numpy(prob_dec_weights.T)\n",
    "    pt_model.prob_decoder.loc_projection.bias.data = torch.from_numpy(prob_dec_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41c88136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_full_model_and_parts (__main__.TestVaDETranslation)\n",
      "Test the forward pass and helper methods of the VaDEPT class. ... "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 160\u001b[0m\n\u001b[0;32m    158\u001b[0m runner \u001b[38;5;241m=\u001b[39m unittest\u001b[38;5;241m.\u001b[39mTextTestRunner(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    159\u001b[0m suite \u001b[38;5;241m=\u001b[39m unittest\u001b[38;5;241m.\u001b[39mTestLoader()\u001b[38;5;241m.\u001b[39mloadTestsFromTestCase(TestVaDETranslation)\n\u001b[1;32m--> 160\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuite\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\unittest\\runner.py:184\u001b[0m, in \u001b[0;36mTextTestRunner.run\u001b[1;34m(self, test)\u001b[0m\n\u001b[0;32m    182\u001b[0m     startTestRun()\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     stopTestRun \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstopTestRun\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\unittest\\suite.py:84\u001b[0m, in \u001b[0;36mBaseTestSuite.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\unittest\\suite.py:122\u001b[0m, in \u001b[0;36mTestSuite.run\u001b[1;34m(self, result, debug)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug:\n\u001b[1;32m--> 122\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     test\u001b[38;5;241m.\u001b[39mdebug()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\unittest\\case.py:650\u001b[0m, in \u001b[0;36mTestCase.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\unittest\\case.py:587\u001b[0m, in \u001b[0;36mTestCase.run\u001b[1;34m(self, result)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outcome \u001b[38;5;241m=\u001b[39m outcome\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m outcome\u001b[38;5;241m.\u001b[39mtestPartExecutor(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 587\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callSetUp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outcome\u001b[38;5;241m.\u001b[39msuccess:\n\u001b[0;32m    589\u001b[0m     outcome\u001b[38;5;241m.\u001b[39mexpecting_failure \u001b[38;5;241m=\u001b[39m expecting_failure\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\unittest\\case.py:546\u001b[0m, in \u001b[0;36mTestCase._callSetUp\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_callSetUp\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 546\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetUp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 73\u001b[0m, in \u001b[0;36mTestVaDETranslation.setUp\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_feature_shape_pt \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_edges, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_per_edge)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# --- 5. Instantiate Models ---\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_embedding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_decoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_grouper, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_vade \u001b[38;5;241m=\u001b[39m \u001b[43mget_vade\u001b[49m(\n\u001b[0;32m     74\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_shape_tf,\n\u001b[0;32m     75\u001b[0m     edge_feature_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_feature_shape_tf,\n\u001b[0;32m     76\u001b[0m     adjacency_matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj_matrix,\n\u001b[0;32m     77\u001b[0m     latent_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim,\n\u001b[0;32m     78\u001b[0m     use_gnn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_gnn,\n\u001b[0;32m     79\u001b[0m     n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components,\n\u001b[0;32m     80\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m     81\u001b[0m     kmeans_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkmeans_loss\n\u001b[0;32m     82\u001b[0m )\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt_vade \u001b[38;5;241m=\u001b[39m VaDEPT(\n\u001b[0;32m     85\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_shape_pt,\n\u001b[0;32m     86\u001b[0m     edge_feature_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_feature_shape_pt,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m     kmeans_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkmeans_loss\n\u001b[0;32m     92\u001b[0m )\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt_vade\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[1;32mIn[7], line 73\u001b[0m, in \u001b[0;36mTestVaDETranslation.setUp\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_feature_shape_pt \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_length, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_edges, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_per_edge)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# --- 5. Instantiate Models ---\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_embedding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_decoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_grouper, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_vade \u001b[38;5;241m=\u001b[39m \u001b[43mget_vade\u001b[49m(\n\u001b[0;32m     74\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_shape_tf,\n\u001b[0;32m     75\u001b[0m     edge_feature_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_feature_shape_tf,\n\u001b[0;32m     76\u001b[0m     adjacency_matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madj_matrix,\n\u001b[0;32m     77\u001b[0m     latent_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatent_dim,\n\u001b[0;32m     78\u001b[0m     use_gnn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_gnn,\n\u001b[0;32m     79\u001b[0m     n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components,\n\u001b[0;32m     80\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[0;32m     81\u001b[0m     kmeans_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkmeans_loss\n\u001b[0;32m     82\u001b[0m )\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt_vade \u001b[38;5;241m=\u001b[39m VaDEPT(\n\u001b[0;32m     85\u001b[0m     input_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_shape_pt,\n\u001b[0;32m     86\u001b[0m     edge_feature_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_feature_shape_pt,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     91\u001b[0m     kmeans_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkmeans_loss\n\u001b[0;32m     92\u001b[0m )\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt_vade\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1697\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:634\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1368\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:1311\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\\\pydevd_cython.pyx:494\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Petron\\Desktop\\Python_Projects\\Deepof\\dof\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2188\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2185\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2187\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2188\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_suspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2190\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2193\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Petron\\Desktop\\Python_Projects\\Deepof\\dof\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2257\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2254\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[0;32m   2255\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[1;32m-> 2257\u001b[0m         \u001b[43mnotify_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2258\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m   2260\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Imports and Mocks from the previous response are assumed to be present\n",
    "import unittest\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "import time\n",
    "import deepof.clustering.models_new\n",
    "# End of Mocks\n",
    "\n",
    "\n",
    "def transfer_vade_class_weights(tf_vade_model, tf_decoder_model, pt_vade_model: VaDEPT):\n",
    "    \"\"\"\n",
    "    Transfers weights from a full TensorFlow VaDE model to the self-contained PyTorch VaDEPT class.\n",
    "    \"\"\"\n",
    "    print(\"Transferring weights for all VaDE components...\")\n",
    "    \n",
    "    # 1. Get the inner Keras models/layers by name from the complete TF model\n",
    "    tf_encoder_inner = tf_vade_model.get_layer(\"recurrent_encoder\")\n",
    "    tf_latent_layer = tf_vade_model.get_layer(\"gaussian_mixture_latent\")\n",
    "    \n",
    "    # 2. Use the specialized weight transfer functions, passing the PT sub-modules\n",
    "    print(\"  -> Transferring Encoder weights...\")\n",
    "    transfer_recurrent_encoder_weights(tf_encoder_inner, pt_vade_model.encoder)\n",
    "    print(\"  -> Transferring GMM Latent weights...\")\n",
    "    transfer_gmm_weights(tf_latent_layer, pt_vade_model.latent_space)\n",
    "    print(\"  -> Transferring Decoder weights...\")\n",
    "    transfer_recurrent_decoder_weights(tf_decoder_model, pt_vade_model.decoder)\n",
    "    \n",
    "    print(\"Weight transfer complete.\")\n",
    "\n",
    "\n",
    "class TestVaDETranslation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up parameters, models, and data for testing.\"\"\"\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.keras.backend.set_epsilon(1e-3)\n",
    "\n",
    "        # --- 1. Define Fundamental Dimensions ---\n",
    "        self.batch_size = 128\n",
    "        self.window_length = 25\n",
    "        self.num_nodes = 11\n",
    "        # In your example, total features (n=33) / num_nodes (11) = 3\n",
    "        self.features_per_node = 33\n",
    "        self.num_edges = 11\n",
    "        self.features_per_edge = 111 # Assuming 1 feature per edge\n",
    "\n",
    "        # --- 2. Define Model Parameters ---\n",
    "        self.latent_dim = 6\n",
    "        self.n_components = 10\n",
    "        self.kmeans_loss = 1.0\n",
    "        self.use_gnn = False\n",
    "\n",
    "        # --- 3. Create Adjacency Matrix ---\n",
    "        m = np.zeros((self.num_nodes, self.num_nodes))\n",
    "        ui = np.triu_indices(self.num_nodes)\n",
    "        num_possible_edges = len(ui[0])\n",
    "        c = np.random.choice(num_possible_edges, min(self.num_edges, num_possible_edges), replace=False)\n",
    "        m[ui[0][c], ui[1][c]] = 1\n",
    "        m += m.T # Make symmetric\n",
    "        self.adj_matrix = m\n",
    "\n",
    "        # --- 4. Create Framework-Specific Shapes for Model Instantiation ---\n",
    "        \n",
    "        # TensorFlow expects (batch, time, total_features)\n",
    "        self.input_shape_tf = (self.batch_size, self.window_length, self.num_nodes * self.features_per_node)\n",
    "        self.edge_feature_shape_tf = (self.batch_size, self.window_length, self.num_edges * self.features_per_edge)\n",
    "        \n",
    "        # PyTorch VaDEPT expects (time, nodes, features_per_node) for a SINGLE sample\n",
    "        self.input_shape_pt = (self.window_length, self.num_nodes, self.features_per_node)\n",
    "        self.edge_feature_shape_pt = (self.window_length, self.num_edges, self.features_per_edge)\n",
    "\n",
    "        # --- 5. Instantiate Models ---\n",
    "        self.tf_embedding, self.tf_decoder, self.tf_grouper, self.tf_vade = get_vade(\n",
    "            input_shape=self.input_shape_tf,\n",
    "            edge_feature_shape=self.edge_feature_shape_tf,\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=self.use_gnn,\n",
    "            n_components=self.n_components,\n",
    "            batch_size=self.batch_size,\n",
    "            kmeans_loss=self.kmeans_loss\n",
    "        )\n",
    "        \n",
    "        self.pt_vade = VaDEPT(\n",
    "            input_shape=self.input_shape_pt,\n",
    "            edge_feature_shape=self.edge_feature_shape_pt,\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            n_components=self.n_components,\n",
    "            use_gnn=self.use_gnn,\n",
    "            kmeans_loss=self.kmeans_loss\n",
    "        )\n",
    "        self.pt_vade.eval()\n",
    "\n",
    "        # --- 6. Prepare Data Tensors for Each Framework ---\n",
    "        np.random.seed(42)\n",
    "        # The \"canonical\" data is 4D, as expected by the new PyTorch models\n",
    "        self.x_np_4d = np.random.rand(\n",
    "            self.batch_size, self.window_length, self.num_nodes, self.features_per_node\n",
    "        ).astype(np.float32)\n",
    "        self.a_np_4d = np.random.rand(\n",
    "            self.batch_size, self.window_length, self.num_edges, self.features_per_edge\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        # Create the 3D version for the legacy TensorFlow model by reshaping\n",
    "        self.x_np_tf = self.x_np_4d.reshape(self.input_shape_tf)\n",
    "        self.a_np_tf = self.a_np_4d.reshape(self.edge_feature_shape_tf)\n",
    "        \n",
    "        # --- 7. Transfer Weights ---\n",
    "        transfer_vade_class_weights(self.tf_vade, self.tf_decoder, self.pt_vade)\n",
    "\n",
    "    def test_full_model_and_parts(self):\n",
    "        \"\"\"Test the forward pass and helper methods of the VaDEPT class.\"\"\"\n",
    "        print(\"\\n--- Testing Self-Contained VaDEPT Class Translation ---\")\n",
    "        \n",
    "        # --- TensorFlow Execution (with its required 3D input) ---\n",
    "        tf_start = time.time()\n",
    "        tf_rec_dist = self.tf_vade([self.x_np_tf, self.a_np_tf], training=False)\n",
    "        tf_rec_mean = tf_rec_dist.mean().numpy()\n",
    "        tf_lat_out = self.tf_embedding([self.x_np_tf, self.a_np_tf], training=False).numpy()\n",
    "        tf_cat_out = self.tf_grouper([self.x_np_tf, self.a_np_tf], training=False).numpy()\n",
    "        tf_end = time.time()\n",
    "        \n",
    "        # --- PyTorch Execution (with its required 4D input) ---\n",
    "        x_pt = torch.from_numpy(self.x_np_4d)\n",
    "        a_pt = torch.from_numpy(self.a_np_4d)\n",
    "        \n",
    "        pt_start = time.time()\n",
    "        with torch.no_grad():\n",
    "            pt_rec_dist, _, _, _ = self.pt_vade(x_pt, a_pt)\n",
    "            pt_rec_mean = pt_rec_dist.mean.numpy() \n",
    "            pt_lat_out = self.pt_vade.embed(x_pt, a_pt).numpy()\n",
    "            pt_cat_out = self.pt_vade.group(x_pt, a_pt).numpy()\n",
    "        pt_end = time.time()\n",
    "\n",
    "        print(f\"TensorFlow execution time: {tf_end - tf_start:.6f}s\")\n",
    "        print(f\"PyTorch execution time: {pt_end - pt_start:.6f}s\")\n",
    "        \n",
    "        # --- Assertions ---\n",
    "        print(\"\\nComparing latent space embeddings (from .embed() vs 'embedding' model)...\")\n",
    "        # Both outputs should be (batch_size, latent_dim), so (128, 6)\n",
    "        np.testing.assert_allclose(tf_lat_out, pt_lat_out, rtol=1e-5, atol=1e-4)\n",
    "        print(\"✅ Latent embeddings match.\")\n",
    "\n",
    "        print(\"Comparing categorical probabilities (from .group() vs 'grouper' model)...\")\n",
    "        # Both outputs should be (batch_size, n_components), so (128, 10)\n",
    "        np.testing.assert_allclose(tf_cat_out, pt_cat_out, rtol=1e-5, atol=1e-5)\n",
    "        print(\"✅ Categorical probabilities match.\")\n",
    "        \n",
    "        print(\"Comparing final reconstruction means (from forward() vs 'vade' model)...\")\n",
    "        # Both outputs should be (batch_size, time_steps, total_features), so (128, 25, 33)\n",
    "        np.testing.assert_allclose(tf_rec_mean, pt_rec_mean, rtol=1e-5, atol=1e-4)\n",
    "        print(\"✅ Reconstructions match.\")\n",
    "\n",
    "        print(\"\\n✅ Self-contained VaDEPT class translation test PASSED!\")\n",
    "\n",
    "# To run the test\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestVaDETranslation)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3082a",
   "metadata": {},
   "source": [
    "# Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c33fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "import time\n",
    "import deepof.model_utils\n",
    "from spektral.layers import CensNetConv\n",
    "from deepof.model_utils import ClusterControl, compute_kmeans_loss, ProbabilisticDecoder\n",
    "import deepof.models\n",
    "from deepof.models import get_recurrent_encoder, get_recurrent_decoder, GaussianMixtureLatent, get_TCN_encoder, get_TCN_decoder, get_transformer_encoder, get_transformer_decoder\n",
    "from deepof.clustering.models_new import RecurrentEncoderPT, RecurrentDecoderPT, GaussianMixtureLatentPT\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    LayerNormalization,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    ")\n",
    "\n",
    "from deepof.data_loading import get_dt\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e67e0726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VaDE(tf.keras.models.Model):\n",
    "    \"\"\"Gaussian Mixture Variational Autoencoder for pose motif elucidation.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: tuple,\n",
    "        edge_feature_shape: tuple,\n",
    "        adjacency_matrix: np.ndarray = None,\n",
    "        latent_dim: int = 8,\n",
    "        use_gnn: bool = True,\n",
    "        n_components: int = 15,\n",
    "        batch_size: int = 64,\n",
    "        kl_annealing_mode: str = \"linear\",\n",
    "        kl_warmup_epochs: int = 15,\n",
    "        montecarlo_kl: int = 100,\n",
    "        kmeans_loss: float = 1.0,\n",
    "        reg_cat_clusters: float = 1.0,\n",
    "        reg_cluster_variance: bool = False,\n",
    "        encoder_type: str = \"recurrent\",\n",
    "        interaction_regularization: float = 0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Init a VaDE model.\n",
    "\n",
    "        Args:\n",
    "            input_shape (tuple): Shape of the input to the full model.\n",
    "            edge_feature_shape (tuple): shape of the edge feature matrix used for graph representations.\n",
    "            adjacency_matrix (np.ndarray): adjacency matrix of the connectivity graph to use.\n",
    "            batch_size (int): Batch size for training.\n",
    "            latent_dim (int): Dimensionality of the latent space.\n",
    "            use_gnn (bool): If True, the encoder uses a graph representation of the input, with coordinates and speeds as node attributes, and distances as edge attributes. If False, a regular 3D tensor is used as input.\n",
    "            kl_annealing_mode (str): Annealing mode for KL annealing. Can be one of 'linear' and 'sigmoid'.\n",
    "            kl_warmup_epochs (int): Number of epochs to warmup KL annealing.\n",
    "            montecarlo_kl (int): Number of Monte Carlo samples for KL divergence.\n",
    "            n_components (int): Number of mixture components in the latent space.\n",
    "            kmeans_loss (float): weight of the gram matrix regularization loss.\n",
    "            reg_cat_clusters (bool): whether to use the penalized uneven cluster membership in the latent space, by minimizing the KL divergence between cluster membership and a uniform categorical distribution.\n",
    "            reg_cluster_variance (bool): whether to penalize uneven cluster variances in the latent space.\n",
    "            encoder_type (str): type of encoder to use. Can be set to \"recurrent\" (default), \"TCN\", or \"transformer\".\n",
    "            interaction_regularization (float): Regularization parameter for the interaction features.\n",
    "            **kwargs: Additional keyword arguments.\n",
    "\n",
    "        \"\"\"\n",
    "        super(VaDE, self).__init__(**kwargs)\n",
    "        self.seq_shape = input_shape\n",
    "        self.edge_feature_shape = edge_feature_shape\n",
    "        self.adjacency_matrix = adjacency_matrix\n",
    "        self.batch_size = batch_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.use_gnn = use_gnn\n",
    "        self.kl_annealing_mode = kl_annealing_mode\n",
    "        self.kl_warmup = kl_warmup_epochs\n",
    "        self.mc_kl = montecarlo_kl\n",
    "        self.n_components = n_components\n",
    "        self.optimizer = Nadam(learning_rate=1e-3, clipvalue=0.75)\n",
    "        self.kmeans = kmeans_loss\n",
    "        self.reg_cat_clusters = reg_cat_clusters\n",
    "        self.reg_cluster_variance = reg_cluster_variance\n",
    "        self.encoder_type = encoder_type\n",
    "        self.interaction_regularization = interaction_regularization\n",
    "\n",
    "        # Define VaDE model\n",
    "        self.encoder, self.decoder, self.grouper, self.vade = deepof.models.get_vade(\n",
    "            input_shape=self.seq_shape,\n",
    "            edge_feature_shape=self.edge_feature_shape,\n",
    "            adjacency_matrix=self.adjacency_matrix,\n",
    "            n_components=self.n_components,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=use_gnn,\n",
    "            batch_size=self.batch_size,\n",
    "            kl_warmup=self.kl_warmup,\n",
    "            kl_annealing_mode=self.kl_annealing_mode,\n",
    "            mc_kl=self.mc_kl,\n",
    "            kmeans_loss=self.kmeans,\n",
    "            reg_cluster_variance=self.reg_cluster_variance,\n",
    "            encoder_type=self.encoder_type,\n",
    "            interaction_regularization=self.interaction_regularization,\n",
    "        )\n",
    "\n",
    "        # Propagate the optimizer to all relevant sub-models, to enable metric annealing\n",
    "        self.vade.optimizer = self.optimizer\n",
    "        self.vade.get_layer(\"gaussian_mixture_latent\").optimizer = self.optimizer\n",
    "\n",
    "        # Define metrics to track\n",
    "\n",
    "        # Track all loss function components\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.val_total_loss_tracker = tf.keras.metrics.Mean(name=\"val_total_loss\")\n",
    "\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.val_reconstruction_loss_tracker = tf.keras.metrics.Mean(\n",
    "            name=\"val_reconstruction_loss\"\n",
    "        )\n",
    "\n",
    "        if self.reg_cat_clusters:\n",
    "            self.cat_cluster_loss_tracker = tf.keras.metrics.Mean(\n",
    "                name=\"cat_cluster_loss\"\n",
    "            )\n",
    "            self.val_cat_cluster_loss_tracker = tf.keras.metrics.Mean(\n",
    "                name=\"val_cat_cluster_loss\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def metrics(self):  # pragma: no cover\n",
    "        \"\"\"Initializes tracked metrics of VaDE model.\"\"\"\n",
    "        metrics = [\n",
    "            self.total_loss_tracker,\n",
    "            self.val_total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.val_reconstruction_loss_tracker,\n",
    "        ]\n",
    "\n",
    "        if self.reg_cat_clusters:\n",
    "            metrics += [\n",
    "                self.cat_cluster_loss_tracker,\n",
    "                self.val_cat_cluster_loss_tracker,\n",
    "            ]\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    @property\n",
    "    def get_gmm_params(self):\n",
    "        \"\"\"Return the GMM parameters of the model.\"\"\"\n",
    "        # Get GMM parameters\n",
    "        return {\n",
    "            \"means\": self.grouper.get_layer(\"gaussian_mixture_latent\").c_mu,\n",
    "            \"sigmas\": tf.math.exp(\n",
    "                self.grouper.get_layer(\"gaussian_mixture_latent\").log_c_sigma\n",
    "            ),\n",
    "            \"weights\": tf.math.softmax(\n",
    "                self.grouper.get_layer(\"gaussian_mixture_latent\").prior\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def set_pretrain_mode(self, switch):\n",
    "        \"\"\"Set the pretrain mode of the model.\"\"\"\n",
    "        self.grouper.get_layer(\"gaussian_mixture_latent\").pretrain.assign(switch)\n",
    "\n",
    "    def pretrain(\n",
    "        self,\n",
    "        data,\n",
    "        embed_x,\n",
    "        embed_a,\n",
    "        epochs=10,\n",
    "        samples=10000,\n",
    "        gmm_initialize=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Run a GMM directed pretraining of the encoder, to minimize the likelihood of getting stuck in a local minimum.\"\"\"\n",
    "        # Turn on pretrain mode\n",
    "        self.set_pretrain_mode(1.0)\n",
    "\n",
    "        # pre-train\n",
    "        self.fit(\n",
    "            data,\n",
    "            epochs=epochs,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "        # Turn off pretrain mode\n",
    "        self.set_pretrain_mode(0.0)\n",
    "\n",
    "        if gmm_initialize:\n",
    "\n",
    "            with tf.device(\"CPU\"):\n",
    "                # Get embedding samples\n",
    "                em_x=get_dt(embed_x, 'embed_x')\n",
    "                em_a=get_dt(embed_a, 'embed_a')\n",
    "\n",
    "                emb_idx = np.random.choice(range(em_x.shape[0]), samples)\n",
    "\n",
    "                # map to latent\n",
    "                z = self.encoder([em_x[emb_idx], em_a[emb_idx]])\n",
    "                \n",
    "                del em_x\n",
    "                del em_a\n",
    "                del emb_idx\n",
    "\n",
    "                # fit GMM\n",
    "                gmm = deepof.models.GaussianMixture(\n",
    "                    n_components=self.n_components,\n",
    "                    covariance_type=\"diag\",\n",
    "                    reg_covar=1e-04,\n",
    "                    **kwargs,\n",
    "                ).fit(z)\n",
    "                # get GMM parameters\n",
    "                mu = gmm.means_\n",
    "                sigma2 = gmm.covariances_\n",
    "\n",
    "            # initialize mixture components\n",
    "            self.grouper.get_layer(\"gaussian_mixture_latent\").c_mu.assign(\n",
    "                tf.convert_to_tensor(value=mu, dtype=tf.float32)\n",
    "            )\n",
    "            self.grouper.get_layer(\"gaussian_mixture_latent\").log_c_sigma.assign(\n",
    "                tf.math.log(\n",
    "                    tf.math.sqrt(tf.convert_to_tensor(value=sigma2, dtype=tf.float32))\n",
    "                )\n",
    "            )\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\"Call the VaDE model.\"\"\"\n",
    "        return self.vade(inputs, **kwargs)\n",
    "\n",
    "    def train_step(self, data):  # pragma: no cover\n",
    "        \"\"\"Perform a training step.\"\"\"\n",
    "        # Unpack data, repacking labels into a generator\n",
    "        x, a, y = data\n",
    "        if not isinstance(y, tuple):\n",
    "            y = [y]\n",
    "        y = (labels for labels in y)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Get outputs from the full model\n",
    "            outputs = self.vade([x, a], training=True)\n",
    "\n",
    "            # Get rid of the attention scores that the transformer decoder outputs\n",
    "            if self.encoder_type == \"transformer\":\n",
    "                outputs = outputs[0]\n",
    "\n",
    "            if isinstance(outputs, list):\n",
    "                reconstructions = outputs[0]\n",
    "            else:\n",
    "                reconstructions = outputs\n",
    "\n",
    "            # Regularize embeddings\n",
    "            # groups = self.grouper(x, training=True)\n",
    "\n",
    "            # Compute losses\n",
    "            seq_inputs = next(y)\n",
    "            total_loss = sum(self.vade.losses)\n",
    "\n",
    "            # Add a regularization term to the soft_counts, to prevent the embedding layer from\n",
    "            # collapsing into a few clusters.\n",
    "            if self.reg_cat_clusters:\n",
    "\n",
    "                soft_counts = self.grouper([x, a], training=True)\n",
    "                soft_counts_regulrization = (\n",
    "                    self.reg_cat_clusters\n",
    "                    * deepof.model_utils.cluster_frequencies_regularizer(\n",
    "                        soft_counts=soft_counts, k=self.n_components\n",
    "                    )\n",
    "                )\n",
    "                total_loss += soft_counts_regulrization\n",
    "\n",
    "            # Compute reconstruction loss\n",
    "            reconstruction_loss = -tf.reduce_mean(reconstructions.log_prob(seq_inputs))\n",
    "            total_loss += reconstruction_loss\n",
    "\n",
    "        # Backpropagation\n",
    "        grads = tape.gradient(total_loss, self.vade.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.vade.trainable_variables))\n",
    "\n",
    "        # Track losses\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "\n",
    "        # Log results (coupled with TensorBoard)\n",
    "        log_dict = {\n",
    "            \"total_loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "        if self.reg_cat_clusters:\n",
    "            self.cat_cluster_loss_tracker.update_state(soft_counts_regulrization)\n",
    "            log_dict[\"cat_cluster_loss\"] = self.cat_cluster_loss_tracker.result()\n",
    "\n",
    "        # Log to TensorBoard, both explicitly and implicitly (within model) tracked metrics\n",
    "        return {**log_dict, **{met.name: met.result() for met in self.vade.metrics}}\n",
    "\n",
    "    # noinspection PyUnboundLocalVariable\n",
    "    @tf.function\n",
    "    def test_step(self, data):  # pragma: no cover\n",
    "        \"\"\"Performs a test step.\"\"\"\n",
    "        # Unpack data, repacking labels into a generator\n",
    "        x, a, y = data\n",
    "        if not isinstance(y, tuple):\n",
    "            y = [y]\n",
    "        y = (labels for labels in y)\n",
    "\n",
    "        # Get outputs from the full model\n",
    "        outputs = self.vade([x, a], training=False)\n",
    "\n",
    "        # Get rid of the attention scores that the transformer decoder outputs\n",
    "        if self.encoder_type == \"transformer\":\n",
    "            outputs = outputs[0]\n",
    "\n",
    "        if isinstance(outputs, list):\n",
    "            reconstructions = outputs[0]\n",
    "        else:\n",
    "            reconstructions = outputs\n",
    "\n",
    "        # Compute losses\n",
    "        seq_inputs = next(y)\n",
    "        total_loss = sum(self.vade.losses)\n",
    "\n",
    "        # Add a regularization term to the soft_counts, to prevent the embedding layer from\n",
    "        # collapsing into a few clusters.\n",
    "        if self.reg_cat_clusters:\n",
    "            soft_counts = self.grouper([x, a], training=False)\n",
    "            soft_counts_regulrization = (\n",
    "                self.reg_cat_clusters\n",
    "                * deepof.model_utils.cluster_frequencies_regularizer(\n",
    "                    soft_counts=soft_counts, k=self.n_components\n",
    "                )\n",
    "            )\n",
    "            total_loss += soft_counts_regulrization\n",
    "\n",
    "        # Compute reconstruction loss\n",
    "        reconstruction_loss = -tf.reduce_mean(reconstructions.log_prob(seq_inputs))\n",
    "        total_loss += reconstruction_loss\n",
    "\n",
    "        # Track losses\n",
    "        self.val_total_loss_tracker.update_state(total_loss)\n",
    "        self.val_reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "\n",
    "        # Log results (coupled with TensorBoard)\n",
    "        log_dict = {\n",
    "            \"total_loss\": self.val_total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.val_reconstruction_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "        if self.reg_cat_clusters:\n",
    "            self.val_cat_cluster_loss_tracker.update_state(soft_counts_regulrization)\n",
    "            log_dict[\"cat_cluster_loss\"] = self.val_cat_cluster_loss_tracker.result()\n",
    "\n",
    "        return {**log_dict, **{met.name: met.result() for met in self.vade.metrics}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b5b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VaDEPT(nn.Module):\n",
    "    \"\"\"\n",
    "    A self-contained PyTorch implementation of the VaDE model.\n",
    "\n",
    "    This class encapsulates the entire VaDE architecture, including the encoder,\n",
    "    the Gaussian mixture latent space, and the decoder. It is instantiated with\n",
    "    all necessary configuration parameters, building its sub-modules internally.\n",
    "    This provides a clean, single-object interface for the model.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: tuple,\n",
    "        edge_feature_shape: tuple,\n",
    "        adjacency_matrix: np.ndarray,\n",
    "        latent_dim: int,\n",
    "        n_components: int,\n",
    "        use_gnn: bool = True,\n",
    "        kmeans_loss: float = 1.0,\n",
    "        interaction_regularization: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes and builds the VaDE model and its components.\n",
    "\n",
    "        Args:\n",
    "            input_shape (tuple): Shape of the input node features (Time, Nodes, Features_per_node).\n",
    "            edge_feature_shape (tuple): Shape of the edge features (Time, Edges, Features_per_edge).\n",
    "            adjacency_matrix (np.ndarray): Adjacency matrix of the connectivity graph.\n",
    "            latent_dim (int): Dimensionality of the latent space.\n",
    "            n_components (int): Number of components in the Gaussian mixture.\n",
    "            use_gnn (bool): If True, use the GNN-based encoder.\n",
    "            kmeans_loss (float): Weight of the k-means style loss in the latent space.\n",
    "            interaction_regularization (float): Regularization for GNN interaction features.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store key dimensions for internal use (e.g., reshaping in forward pass)\n",
    "        time_steps, n_nodes, n_features_per_node = input_shape\n",
    "        self.input_n_nodes = n_nodes\n",
    "        self.input_n_features_per_node = n_features_per_node\n",
    "\n",
    "        # 1. Instantiate Encoder\n",
    "        self.encoder = RecurrentEncoderPT(\n",
    "            input_shape=input_shape,\n",
    "            edge_feature_shape=edge_feature_shape,\n",
    "            adjacency_matrix=adjacency_matrix,\n",
    "            latent_dim=latent_dim,\n",
    "            use_gnn=use_gnn,\n",
    "            interaction_regularization=interaction_regularization,\n",
    "        )\n",
    "\n",
    "        # 2. Instantiate Latent Space\n",
    "        self.latent_space = GaussianMixtureLatentPT(\n",
    "            input_dim=latent_dim,\n",
    "            n_components=n_components,\n",
    "            latent_dim=latent_dim,\n",
    "            kmeans=kmeans_loss,\n",
    "        )\n",
    "\n",
    "        # 3. Instantiate Decoder\n",
    "        decoder_output_features = n_nodes * n_features_per_node\n",
    "        self.decoder = RecurrentDecoderPT(\n",
    "            output_shape=(time_steps, decoder_output_features),\n",
    "            latent_dim=latent_dim,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, a: torch.Tensor\n",
    "    ) -> Tuple[torch.distributions.Distribution, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Defines the full forward pass for the VaDE model (training and evaluation).\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input node features tensor (B, T, N, F_node).\n",
    "            a (torch.Tensor): Input edge features tensor (B, T, E, F_edge).\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing:\n",
    "            - reconstruction_dist (torch.distributions.Distribution): The output distribution from the decoder.\n",
    "            - latent (torch.Tensor): The sampled latent representation from the GMM space.\n",
    "            - categorical (torch.Tensor): The cluster probabilities (soft assignments).\n",
    "            - kmeans_loss (torch.Tensor): The k-means regularization loss from the latent space.\n",
    "        \"\"\"\n",
    "        # 1. Encode the input to get the pre-latent representation\n",
    "        encoder_output = self.encoder(x, a)\n",
    "        \n",
    "        # 2. Pass through GMM latent space\n",
    "        latent, categorical, _, _, kmeans_loss, _ = self.latent_space(encoder_output)\n",
    "        \n",
    "        # 3. Decode the latent sample back to the original data space\n",
    "        # Reshape x to (B, T, N*F) for the decoder's masking logic\n",
    "        B, T, _, _ = x.shape\n",
    "        x_for_decoder = x.view(B, T, self.input_n_nodes * self.input_n_features_per_node)\n",
    "        \n",
    "        reconstruction_dist = self.decoder(latent, x_for_decoder)\n",
    "        \n",
    "        return reconstruction_dist, latent, categorical, kmeans_loss\n",
    "    \n",
    "\n",
    "    def get_gmm_params(self) -> dict:\n",
    "        \"\"\"Returns the GMM parameters from the latent space.\"\"\"\n",
    "        # This is the PyTorch equivalent of the TF property\n",
    "        with torch.no_grad():\n",
    "            means = self.latent_space.gmm_means\n",
    "            # The latent space stores log-variances, convert to std-dev\n",
    "            stds = torch.exp(0.5 * self.latent_space.gmm_log_vars)\n",
    "            # Prior is already softmaxed if needed, or just probabilities\n",
    "            weights = self.latent_space.prior\n",
    "        return {\"means\": means, \"stds\": stds, \"weights\": weights}\n",
    "\n",
    "\n",
    "    def set_pretrain_mode(self, pretrain_on: bool):\n",
    "        \"\"\"Sets the pretrain flag in the latent space.\"\"\"\n",
    "        # In TF it was a float (0.0/1.0), here a boolean is cleaner\n",
    "        self.latent_space.pretrain.fill_(1.0 if pretrain_on else 0.0)\n",
    "\n",
    "\n",
    "    def initialize_gmm_from_data(self, data_loader, n_samples=10000):\n",
    "        \"\"\"\n",
    "        Runs the autoencoder part of the model over the data to get embeddings,\n",
    "        then fits a scikit-learn GMM to initialize the latent space.\n",
    "        \"\"\"\n",
    "        print(\"Initializing GMM from data embeddings...\")\n",
    "        self.eval() # Set model to evaluation mode\n",
    "        \n",
    "        # 1. Gather embeddings from the autoencoder\n",
    "        all_embeddings = []\n",
    "        samples_gathered = 0\n",
    "        with torch.no_grad():\n",
    "            for x, a in data_loader:\n",
    "                # Assuming x,a are on the correct device\n",
    "                embeddings = self.encoder(x, a)\n",
    "                all_embeddings.append(embeddings.cpu())\n",
    "                samples_gathered += embeddings.size(0)\n",
    "                if samples_gathered >= n_samples:\n",
    "                    break\n",
    "        \n",
    "        all_embeddings = torch.cat(all_embeddings, dim=0).numpy()\n",
    "        if all_embeddings.shape[0] > n_samples:\n",
    "            all_embeddings = all_embeddings[:n_samples]\n",
    "\n",
    "        # 2. Fit a scikit-learn GMM\n",
    "        from sklearn.mixture import GaussianMixture\n",
    "        print(f\"Fitting scikit-learn GMM on {all_embeddings.shape[0]} samples...\")\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=self.latent_space.n_components,\n",
    "            covariance_type=\"diag\",\n",
    "            reg_covar=1e-04,\n",
    "        ).fit(all_embeddings)\n",
    "\n",
    "        # 3. Assign the learned parameters to the model's latent space\n",
    "        print(\"Assigning learned GMM parameters to the model.\")\n",
    "        self.latent_space.gmm_means.data = torch.from_numpy(gmm.means_).float()\n",
    "        # Convert covariance (variance) to log-variance for the model\n",
    "        self.latent_space.gmm_log_vars.data = torch.from_numpy(np.log(gmm.covariances_)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc113fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_recurrent_block_weights(tf_model, pt_model):\n",
    "    \"\"\"Transfers weights for the full recurrent block with GRU gate permutation.\"\"\"\n",
    "    conv_td, _, gru1_td, norm1, gru2_td, norm2 = tf_model.layers[1:]\n",
    "\n",
    "\n",
    "    def permute_gru_weights(keras_weights):\n",
    "        W_ih, W_hh, B = keras_weights\n",
    "        W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "        W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "        W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "        W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "        B_ih, B_hh = B\n",
    "        B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "        B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "        B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "        B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "        return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_td.layer.get_weights()[0]).permute(2, 1, 0)\n",
    "    \n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(gru1_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1); pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    \n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(gru1_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1); pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm1.get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm1.get_weights()[1])\n",
    "\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(gru2_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2); pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    \n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(gru2_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2); pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    \n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm2.get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm2.get_weights()[1])\n",
    "\n",
    "    \n",
    "def transfer_censnet_weights(tf_layer, pt_layer):\n",
    "    \"\"\"\n",
    "    Transfers all six weights from a Spektral CensNetConv layer to the\n",
    "    corresponding CensNetConvPT layer.\n",
    "    \"\"\"\n",
    "    # Get all weights from the TensorFlow layer. The order is determined by\n",
    "    # the layer's build order in Spektral's source code.\n",
    "    tf_weights = tf_layer.get_weights()\n",
    "\n",
    "    # Unpack all six weights.\n",
    "    # Order: kernel_node, bias_node, kernel_edge, bias_edge, projector_node, projector_edge\n",
    "    kn_tf, bn_tf, ke_tf, be_tf, pn_tf, pe_tf = tf_weights\n",
    "\n",
    "    # Build weights on first pass\n",
    "    if pt_layer.node_kernel is None:\n",
    "        # Move parameters to the same device as input tensors\n",
    "        pt_layer._build(kn_tf.T.shape, bn_tf.T.shape)\n",
    "        #pt_layer.to(kn_tf.device)\n",
    "\n",
    "    # 1. & 2. Transfer Node Kernel and Bias\n",
    "    # Keras Dense kernel is (in_features, out_features)\n",
    "    pt_layer.node_kernel.data = torch.from_numpy(kn_tf)\n",
    "    pt_layer.edge_kernel.data = torch.from_numpy(bn_tf)\n",
    "\n",
    "    # 3. & 4. Transfer Edge Kernel and Bias\n",
    "    # Same transposition logic applies.\n",
    "    pt_layer.node_weights.data = torch.from_numpy(ke_tf)\n",
    "    pt_layer.edge_weights.data = torch.from_numpy(be_tf)\n",
    "\n",
    "    # 5. Transfer Node Projector Weights (P_n)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.node_bias.data = torch.from_numpy(pn_tf)\n",
    "\n",
    "    # 6. Transfer Edge Projector Weights (P_e)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.edge_bias.data = torch.from_numpy(pe_tf)\n",
    "    \n",
    "\n",
    "def transfer_recurrent_encoder_weights(tf_model, pt_model):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full recurrent encoder, finding layers\n",
    "    by their default names and types to avoid modifying original code.\n",
    "    \"\"\"\n",
    "    # The final dense layer is consistently the last one in the model's layer list.\n",
    "    final_dense_tf = tf_model.layers[-1]\n",
    "    final_dense_pt = pt_model.final_dense\n",
    "    w, b = final_dense_tf.get_weights()\n",
    "    final_dense_pt.weight.data = torch.from_numpy(w.T)\n",
    "    final_dense_pt.bias.data = torch.from_numpy(b)\n",
    "\n",
    "    if pt_model.use_gnn:\n",
    "        # Keras automatically names nested models 'model', 'model_1', etc., by order of creation.\n",
    "        # Node recurrent block is created first.\n",
    "        node_recurrent_model = tf_model.get_layer(\"model\")\n",
    "        # Edge recurrent block is created second.\n",
    "        edge_recurrent_model = tf_model.get_layer(\"model_1\")\n",
    "        # Find the CensNetConv layer by its class type.\n",
    "        gnn_layer = next(l for l in tf_model.layers if isinstance(l, CensNetConv))\n",
    "\n",
    "        transfer_recurrent_block_weights(node_recurrent_model, pt_model.node_recurrent_block)\n",
    "        transfer_recurrent_block_weights(edge_recurrent_model, pt_model.edge_recurrent_block)\n",
    "        transfer_censnet_weights(gnn_layer, pt_model.spatial_gnn_block)\n",
    "    else: # Not using GNN\n",
    "        # There is only one nested model, which Keras names 'model'.\n",
    "        recurrent_model = tf_model.get_layer(\"model\")\n",
    "        transfer_recurrent_block_weights(recurrent_model, pt_model.recurrent_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822b9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_gmm_weights(tf_model, pt_model: GaussianMixtureLatentPT):\n",
    "    \"\"\"\n",
    "    Transfers weights from the final TF model to the refactored PT model,\n",
    "    using the updated attribute names.\n",
    "    \"\"\"\n",
    "    # --- Transfer GMM component parameters ---\n",
    "    # OLD: pt_model.c_mu\n",
    "    pt_model.gmm_means.data = torch.from_numpy(tf_model.c_mu.numpy())\n",
    "    # OLD: pt_model.log_c_sigma\n",
    "    pt_model.gmm_log_vars.data = torch.from_numpy(tf_model.log_c_sigma.numpy())\n",
    "\n",
    "    # --- Transfer Encoder layer parameters ---\n",
    "    tf_mean_weights = tf_model.z_gauss_mean.get_weights()\n",
    "    # OLD: pt_model.z_gauss_mean\n",
    "    pt_model.encoder_mean.weight.data = torch.from_numpy(tf_mean_weights[0].T)\n",
    "    pt_model.encoder_mean.bias.data = torch.from_numpy(tf_mean_weights[1])\n",
    "    \n",
    "    tf_var_weights = tf_model.z_gauss_var.get_weights()\n",
    "    # OLD: pt_model.z_gauss_var\n",
    "    pt_model.encoder_log_var.weight.data = torch.from_numpy(tf_var_weights[0].T)\n",
    "    pt_model.encoder_log_var.bias.data = torch.from_numpy(tf_var_weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e8cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function from the provided example to handle gate order differences\n",
    "def permute_gru_weights(keras_weights):\n",
    "    \"\"\"Permutes GRU weights from Keras (z, r, n) to PyTorch (r, z, n) format.\"\"\"\n",
    "    W_ih, W_hh, B = keras_weights\n",
    "    # Keras gate order: z, r, n (update, reset, new/candidate)\n",
    "    W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "    W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "\n",
    "    # PyTorch gate order: r, z, n (reset, update, new/candidate)\n",
    "    W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "    W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "\n",
    "    # Keras has two bias vectors (input-hidden and recurrent), which are concatenated in B\n",
    "    B_ih, B_hh = B\n",
    "    B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "    B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "\n",
    "    B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "    B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "\n",
    "    return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "    \n",
    "def transfer_recurrent_decoder_weights(tf_model, pt_model):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full recurrent decoder model.\n",
    "    \"\"\"\n",
    "    # Find layers by type to avoid index issues\n",
    "    bidi_layers = [l for l in tf_model.layers if isinstance(l, Bidirectional)]\n",
    "    norm_layers = [l for l in tf_model.layers if isinstance(l, LayerNormalization)]\n",
    "    conv_layers = [l for l in tf_model.layers if isinstance(l, tf.keras.layers.Conv1D)]\n",
    "    prob_dec_layer = next(l for l in tf_model.layers if isinstance(l, deepof.model_utils.ProbabilisticDecoder))\n",
    "\n",
    "    # --- GRU 1 and Norm 1 ---\n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(bidi_layers[0].forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1)\n",
    "    pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(bidi_layers[0].backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1)\n",
    "    pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm_layers[0].get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm_layers[0].get_weights()[1])\n",
    "\n",
    "    # --- GRU 2 and Norm 2 ---\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(bidi_layers[1].forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2)\n",
    "    pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(bidi_layers[1].backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2)\n",
    "    pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm_layers[1].get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm_layers[1].get_weights()[1])\n",
    "\n",
    "    # --- Conv1D and Norm 3 ---\n",
    "    # TF Conv1D weights: (kernel_w, kernel_h, in_c, out_c) -> (5, 1, 4*ld, 2*ld)\n",
    "    # PT Conv1d weights: (out_c, in_c, kernel_w)\n",
    "    conv_weights_tf = conv_layers[0].get_weights()[0]\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_weights_tf).squeeze(1).permute(2, 1, 0)\n",
    "    pt_model.norm3.weight.data = torch.from_numpy(norm_layers[2].get_weights()[0]); pt_model.norm3.bias.data = torch.from_numpy(norm_layers[2].get_weights()[1])\n",
    "\n",
    "    # --- Probabilistic Decoder ---\n",
    "    # TF Dense weights: (in_features, out_features)\n",
    "    # PT Linear weights: (out_features, in_features)\n",
    "    prob_dec_weights, prob_dec_bias = prob_dec_layer.time_distributer.get_weights()\n",
    "    pt_model.prob_decoder.loc_projection.weight.data = torch.from_numpy(prob_dec_weights.T)\n",
    "    pt_model.prob_decoder.loc_projection.bias.data = torch.from_numpy(prob_dec_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf27b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_full_model_and_parts (__main__.TestVaDETranslation)\n",
      "Test the forward pass and helper methods of the VaDEPT class. ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferring weights for all VaDE components...\n",
      "  -> Transferring Encoder weights...\n",
      "  -> Transferring GMM Latent weights...\n",
      "  -> Transferring Decoder weights...\n",
      "Weight transfer complete.\n",
      "\n",
      "--- Testing Self-Contained VaDEPT Class Translation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_full_model_and_parts (__main__.TestVaDETranslation)\n",
      "Test the forward pass and helper methods of the VaDEPT class.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Petron\\AppData\\Local\\Temp\\ipykernel_27132\\2272132106.py\", line 122, in test_full_model_and_parts\n",
      "    pt_lat_out = self.pt_vade.embed(x_pt, a_pt).numpy()\n",
      "  File \"c:\\Users\\Petron\\Desktop\\Python_Projects\\Deepof\\dof\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1940, in __getattr__\n",
      "    raise AttributeError(\n",
      "AttributeError: 'VaDEPT' object has no attribute 'embed'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 12.441s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=1 failures=0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transfer_vade_class_weights(tf_vade_model, tf_decoder_model, pt_vade_model: VaDEPT):\n",
    "    \"\"\"\n",
    "    Transfers weights from a full TensorFlow VaDE model to the self-contained PyTorch VaDEPT class.\n",
    "    \"\"\"\n",
    "    print(\"Transferring weights for all VaDE components...\")\n",
    "    \n",
    "    # 1. Get the inner Keras models/layers by name from the complete TF model\n",
    "    tf_encoder_inner = tf_vade_model.get_layer(\"recurrent_encoder\")\n",
    "    tf_latent_layer = tf_vade_model.get_layer(\"gaussian_mixture_latent\")\n",
    "    \n",
    "    # 2. Use the specialized weight transfer functions, passing the PT sub-modules\n",
    "    print(\"  -> Transferring Encoder weights...\")\n",
    "    transfer_recurrent_encoder_weights(tf_encoder_inner, pt_vade_model.encoder)\n",
    "    print(\"  -> Transferring GMM Latent weights...\")\n",
    "    transfer_gmm_weights(tf_latent_layer, pt_vade_model.latent_space)\n",
    "    print(\"  -> Transferring Decoder weights...\")\n",
    "    transfer_recurrent_decoder_weights(tf_decoder_model, pt_vade_model.decoder)\n",
    "    \n",
    "    print(\"Weight transfer complete.\")\n",
    "\n",
    "\n",
    "class TestVaDETranslation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up parameters, models, and data for testing.\"\"\"\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.keras.backend.set_epsilon(1e-3)\n",
    "\n",
    "        # --- 1. Define Fundamental Dimensions ---\n",
    "        self.batch_size = 128\n",
    "        self.window_length = 25\n",
    "        self.num_nodes = 11\n",
    "        # In your example, total features (n=33) / num_nodes (11) = 3\n",
    "        self.features_per_node = 3\n",
    "        self.num_edges = 11\n",
    "        self.features_per_edge = 1 # Assuming 1 feature per edge\n",
    "\n",
    "        # --- 2. Define Model Parameters ---\n",
    "        self.latent_dim = 6\n",
    "        self.n_components = 10\n",
    "        self.kmeans_loss = 1.0\n",
    "        self.use_gnn = False\n",
    "\n",
    "        # --- 3. Create Adjacency Matrix ---\n",
    "        m = np.zeros((self.num_nodes, self.num_nodes))\n",
    "        ui = np.triu_indices(self.num_nodes)\n",
    "        num_possible_edges = len(ui[0])\n",
    "        c = np.random.choice(num_possible_edges, min(self.num_edges, num_possible_edges), replace=False)\n",
    "        m[ui[0][c], ui[1][c]] = 1\n",
    "        m += m.T # Make symmetric\n",
    "        self.adj_matrix = m\n",
    "\n",
    "        # --- 4. Create Framework-Specific Shapes for Model Instantiation ---\n",
    "        \n",
    "        # TensorFlow expects (batch, time, total_features)\n",
    "        self.input_shape_tf = (self.batch_size, self.window_length, self.num_nodes * self.features_per_node)\n",
    "        self.edge_feature_shape_tf = (self.batch_size, self.window_length, self.num_edges * self.features_per_edge)\n",
    "        \n",
    "        # PyTorch VaDEPT expects (time, nodes, features_per_node) for a SINGLE sample\n",
    "        self.input_shape_pt = (self.window_length, self.num_nodes, self.features_per_node)\n",
    "        self.edge_feature_shape_pt = (self.window_length, self.num_edges, self.features_per_edge)\n",
    "\n",
    "        # --- 5. Instantiate Models ---\n",
    "        tf_model = VaDE(\n",
    "            input_shape=self.input_shape_tf,\n",
    "            edge_feature_shape=self.edge_feature_shape_tf,\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=self.use_gnn,\n",
    "            n_components=self.n_components,\n",
    "            batch_size=self.batch_size,\n",
    "            kmeans_loss=self.kmeans_loss\n",
    "        )\n",
    "        self.tf_decoder = tf_model.decoder\n",
    "        self.tf_vade = tf_model.vade\n",
    "        self.tf_embedding = tf_model.encoder\n",
    "        self.tf_grouper = tf_model.grouper\n",
    "        \n",
    "        self.pt_vade = VaDEPT(\n",
    "            input_shape=self.input_shape_pt,\n",
    "            edge_feature_shape=self.edge_feature_shape_pt,\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            n_components=self.n_components,\n",
    "            use_gnn=self.use_gnn,\n",
    "            kmeans_loss=self.kmeans_loss\n",
    "        )\n",
    "        self.pt_vade.eval()\n",
    "\n",
    "        # --- 6. Prepare Data Tensors for Each Framework ---\n",
    "        np.random.seed(42)\n",
    "        # The \"canonical\" data is 4D, as expected by the new PyTorch models\n",
    "        self.x_np_4d = np.random.rand(\n",
    "            self.batch_size, self.window_length, self.num_nodes, self.features_per_node\n",
    "        ).astype(np.float32)\n",
    "        self.a_np_4d = np.random.rand(\n",
    "            self.batch_size, self.window_length, self.num_edges, self.features_per_edge\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        # Create the 3D version for the legacy TensorFlow model by reshaping\n",
    "        self.x_np_tf = self.x_np_4d.reshape(self.input_shape_tf)\n",
    "        self.a_np_tf = self.a_np_4d.reshape(self.edge_feature_shape_tf)\n",
    "        \n",
    "        # --- 7. Transfer Weights ---\n",
    "        transfer_vade_class_weights(self.tf_vade, self.tf_decoder, self.pt_vade)\n",
    "\n",
    "    def test_full_model_and_parts(self):\n",
    "        \"\"\"Test the forward pass and helper methods of the VaDEPT class.\"\"\"\n",
    "        print(\"\\n--- Testing Self-Contained VaDEPT Class Translation ---\")\n",
    "        \n",
    "        # --- TensorFlow Execution (with its required 3D input) ---\n",
    "        tf_start = time.time()\n",
    "        tf_rec_dist = self.tf_vade([self.x_np_tf, self.a_np_tf], training=False)\n",
    "        tf_rec_mean = tf_rec_dist.mean().numpy()\n",
    "        tf_lat_out = self.tf_embedding([self.x_np_tf, self.a_np_tf], training=False).numpy()\n",
    "        tf_cat_out = self.tf_grouper([self.x_np_tf, self.a_np_tf], training=False).numpy()\n",
    "        tf_end = time.time()\n",
    "        \n",
    "        # --- PyTorch Execution (with its required 4D input) ---\n",
    "        x_pt = torch.from_numpy(self.x_np_4d)\n",
    "        a_pt = torch.from_numpy(self.a_np_4d)\n",
    "        \n",
    "        pt_start = time.time()\n",
    "        with torch.no_grad():\n",
    "            pt_rec_dist, _, _, _ = self.pt_vade(x_pt, a_pt)\n",
    "            pt_rec_mean = pt_rec_dist.mean.numpy() \n",
    "            pt_lat_out = self.pt_vade.embed(x_pt, a_pt).numpy()\n",
    "            pt_cat_out = self.pt_vade.group(x_pt, a_pt).numpy()\n",
    "        pt_end = time.time()\n",
    "\n",
    "        print(f\"TensorFlow execution time: {tf_end - tf_start:.6f}s\")\n",
    "        print(f\"PyTorch execution time: {pt_end - pt_start:.6f}s\")\n",
    "        \n",
    "        # --- Assertions ---\n",
    "        print(\"\\nComparing latent space embeddings (from .embed() vs 'embedding' model)...\")\n",
    "        # Both outputs should be (batch_size, latent_dim), so (128, 6)\n",
    "        np.testing.assert_allclose(tf_lat_out, pt_lat_out, rtol=1e-5, atol=1e-4)\n",
    "        print(\"✅ Latent embeddings match.\")\n",
    "\n",
    "        print(\"Comparing categorical probabilities (from .group() vs 'grouper' model)...\")\n",
    "        # Both outputs should be (batch_size, n_components), so (128, 10)\n",
    "        np.testing.assert_allclose(tf_cat_out, pt_cat_out, rtol=1e-5, atol=1e-5)\n",
    "        print(\"✅ Categorical probabilities match.\")\n",
    "        \n",
    "        print(\"Comparing final reconstruction means (from forward() vs 'vade' model)...\")\n",
    "        # Both outputs should be (batch_size, time_steps, total_features), so (128, 25, 33)\n",
    "        np.testing.assert_allclose(tf_rec_mean, pt_rec_mean, rtol=1e-5, atol=1e-4)\n",
    "        print(\"✅ Reconstructions match.\")\n",
    "\n",
    "        print(\"\\n✅ Self-contained VaDEPT class translation test PASSED!\")\n",
    "\n",
    "# To run the test\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestVaDETranslation)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c1c84",
   "metadata": {},
   "source": [
    "# TCN encoder test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "874077da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple, Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from spektral.layers import CensNetConv\n",
    "from deepof.clustering.censNetConv_pt import CensNetConvPT\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Bidirectional, GRU, LayerNormalization, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    LayerNormalization,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    ")\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import tcn as tcn_pkg\n",
    "import tcn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c117294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TCN_encoder(\n",
    "    input_shape: tuple,\n",
    "    edge_feature_shape: tuple,\n",
    "    adjacency_matrix: np.ndarray,\n",
    "    latent_dim: int,\n",
    "    use_gnn: bool = True,\n",
    "    conv_filters: int = 32,\n",
    "    kernel_size: int = 4,\n",
    "    conv_stacks: int = 2,\n",
    "    conv_dilations: tuple = (1, 2, 4, 8),\n",
    "    padding: str = \"causal\",\n",
    "    use_skip_connections: bool = True,\n",
    "    dropout_rate: int = 0,\n",
    "    activation: str = \"relu\",\n",
    "    interaction_regularization: float = 0.0,\n",
    "):\n",
    "    \"\"\"Return a Temporal Convolutional Network (TCN) encoder.\n",
    "\n",
    "    Builds a neural network that can be used to encode motion tracking instances into a\n",
    "    vector. Each layer contains a residual block with a convolutional layer and a skip connection. See the following\n",
    "    paper for more details: https://arxiv.org/pdf/1803.01271.pdf\n",
    "\n",
    "    Args:\n",
    "        input_shape: shape of the input data\n",
    "        edge_feature_shape (tuple): shape of the adjacency matrix to use in the graph attention layers. Should be time x edges x features.\n",
    "        adjacency_matrix (np.ndarray): adjacency matrix for the mice connectivity graph. Shape should be nodes x nodes.\n",
    "        latent_dim: dimensionality of the latent space\n",
    "        use_gnn (bool): If True, the encoder uses a graph representation of the input, with coordinates and speeds as node attributes, and distances as edge attributes. If False, a regular 3D tensor is used as input.\n",
    "        conv_filters: number of filters in the TCN layers\n",
    "        kernel_size: size of the convolutional kernels\n",
    "        conv_stacks: number of TCN layers\n",
    "        conv_dilations: list of dilation factors for each TCN layer\n",
    "        padding: padding mode for the TCN layers\n",
    "        use_skip_connections: whether to use skip connections between TCN layers\n",
    "        dropout_rate: dropout rate for the TCN layers\n",
    "        activation: activation function for the TCN layers\n",
    "        interaction_regularization (float): Regularization parameter for the interaction features\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: a keras model that can be trained to encode a sequence of motion tracking instances into a latent\n",
    "        space using temporal convolutional networks.\n",
    "\n",
    "    \"\"\"\n",
    "    # Define feature and adjacency inputs\n",
    "    x = Input(shape=input_shape)\n",
    "    a = Input(shape=edge_feature_shape)\n",
    "\n",
    "    if use_gnn:\n",
    "        x_reshaped = tf.transpose(\n",
    "            tf.reshape(\n",
    "                tf.transpose(x),\n",
    "                [\n",
    "                    -1,\n",
    "                    adjacency_matrix.shape[-1],\n",
    "                    x.shape[1],\n",
    "                    input_shape[-1] // adjacency_matrix.shape[-1],\n",
    "                ][::-1],\n",
    "            )\n",
    "        )\n",
    "        a_reshaped = tf.transpose(\n",
    "            tf.reshape(\n",
    "                tf.transpose(a),\n",
    "                [\n",
    "                    -1,\n",
    "                    edge_feature_shape[-1],\n",
    "                    a.shape[1],\n",
    "                    1,\n",
    "                ][::-1],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        x_reshaped = tf.expand_dims(x, axis=1)\n",
    "\n",
    "    encoder = TimeDistributed(\n",
    "        tcn.TCN(\n",
    "            conv_filters,\n",
    "            kernel_size,\n",
    "            conv_stacks,\n",
    "            conv_dilations,\n",
    "            padding,\n",
    "            use_skip_connections,\n",
    "            dropout_rate,\n",
    "            return_sequences=False,\n",
    "            activation=activation,\n",
    "            kernel_initializer=\"random_normal\",\n",
    "            use_batch_norm=True,\n",
    "        )\n",
    "    )(x_reshaped)\n",
    "\n",
    "    # Instantiate spatial graph block\n",
    "    if use_gnn:\n",
    "\n",
    "        # Embed edge features too\n",
    "        a_encoder = TimeDistributed(\n",
    "            tcn.TCN(\n",
    "                conv_filters,\n",
    "                kernel_size,\n",
    "                conv_stacks,\n",
    "                conv_dilations,\n",
    "                padding,\n",
    "                use_skip_connections,\n",
    "                dropout_rate,\n",
    "                return_sequences=False,\n",
    "                activation=activation,\n",
    "                kernel_initializer=\"random_normal\",\n",
    "                use_batch_norm=True,\n",
    "            )\n",
    "        )(a_reshaped)\n",
    "\n",
    "        spatial_block = CensNetConv(\n",
    "            node_channels=latent_dim,\n",
    "            edge_channels=latent_dim,\n",
    "            activation=\"relu\",\n",
    "            node_regularizer=tf.keras.regularizers.l1(interaction_regularization),\n",
    "        )\n",
    "\n",
    "        # Process adjacency matrix\n",
    "        laplacian, edge_laplacian, incidence = spatial_block.preprocess(\n",
    "            adjacency_matrix\n",
    "        )\n",
    "\n",
    "        # Get and concatenate node and edge embeddings\n",
    "        x_nodes, x_edges = spatial_block(\n",
    "            [encoder, (laplacian, edge_laplacian, incidence), a_encoder], mask=None\n",
    "        )\n",
    "\n",
    "        x_nodes = tf.reshape(\n",
    "            x_nodes,\n",
    "            [-1, adjacency_matrix.shape[-1] * latent_dim],\n",
    "        )\n",
    "\n",
    "        x_edges = tf.reshape(\n",
    "            x_edges,\n",
    "            [-1, edge_feature_shape[-1] * latent_dim],\n",
    "        )\n",
    "\n",
    "        encoder = tf.concat([x_nodes, x_edges], axis=-1)\n",
    "\n",
    "    else:\n",
    "        encoder = tf.squeeze(encoder, axis=1)\n",
    "\n",
    "    encoder = tf.keras.layers.Dense(2 * latent_dim, activation=\"relu\")(encoder)\n",
    "    encoder = tf.keras.layers.BatchNormalization()(encoder)\n",
    "    encoder = Dense(latent_dim, activation=\"relu\")(encoder)\n",
    "    encoder = tf.keras.layers.BatchNormalization()(encoder)\n",
    "    encoder = tf.keras.layers.Dense(latent_dim)(encoder)\n",
    "\n",
    "    return Model([x, a], encoder, name=\"TCN_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3b15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from deepof.clustering.censNetConv_pt import CensNetConvPT\n",
    "\n",
    "\n",
    "def _act(name: str) -> nn.Module:\n",
    "    name = (name or \"relu\").lower()\n",
    "    if name == \"relu\":\n",
    "        return nn.ReLU()\n",
    "    if name == \"gelu\":\n",
    "        return nn.GELU()\n",
    "    if name == \"tanh\":\n",
    "        return nn.Tanh()\n",
    "    if name == \"leaky_relu\":\n",
    "        return nn.LeakyReLU(0.2)\n",
    "    if name in {\"linear\", \"identity\", \"none\"}:\n",
    "        return nn.Identity()\n",
    "    raise ValueError(f\"Unsupported activation: {name}\")\n",
    "\n",
    "\n",
    "class TemporalBlockPT(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual TCN block compatible with keras-tcn:\n",
    "      - Conv1d -> BN(eps=1e-3) -> Act -> Drop\n",
    "      - Conv1d -> BN(eps=1e-3) -> Act -> Drop\n",
    "      - Residual add (with 1x1 projection if channels differ) -> Act\n",
    "    Returns:\n",
    "      out: post-residual activation\n",
    "      skip: post-second-conv activation (summed across blocks when skip connections are used)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        dilation: int,\n",
    "        padding: str = \"causal\",\n",
    "        dropout_rate: float = 0.0,\n",
    "        activation: str = \"relu\",\n",
    "        use_batch_norm: bool = True,\n",
    "        conv_init_std: float = 0.05,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert padding in {\"causal\", \"same\"}\n",
    "        self.dilation = int(dilation)\n",
    "        self.kernel_size = int(kernel_size)\n",
    "        self.padding_mode = padding\n",
    "        self.act = _act(activation)\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "\n",
    "        pad = lambda: ((self.kernel_size - 1) * self.dilation) // 2 if padding == \"same\" else 0\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, self.kernel_size, dilation=self.dilation, padding=pad(), bias=True)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels, eps=1e-3) if use_batch_norm else nn.Identity()\n",
    "        self.drop1 = nn.Dropout(float(dropout_rate)) if dropout_rate else nn.Identity()\n",
    "\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, self.kernel_size, dilation=self.dilation, padding=pad(), bias=True)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels, eps=1e-3) if use_batch_norm else nn.Identity()\n",
    "        self.drop2 = nn.Dropout(float(dropout_rate)) if dropout_rate else nn.Identity()\n",
    "\n",
    "        # 1x1 residual projection if channels differ\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=True) if in_channels != out_channels else None\n",
    "\n",
    "        # Init similar to keras random_normal\n",
    "        nn.init.normal_(self.conv1.weight, mean=0.0, std=conv_init_std); nn.init.zeros_(self.conv1.bias)\n",
    "        nn.init.normal_(self.conv2.weight, mean=0.0, std=conv_init_std); nn.init.zeros_(self.conv2.bias)\n",
    "        if self.downsample is not None:\n",
    "            nn.init.normal_(self.downsample.weight, mean=0.0, std=conv_init_std); nn.init.zeros_(self.downsample.bias)\n",
    "\n",
    "    def _causal_pad(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        pad = (self.kernel_size - 1) * self.dilation\n",
    "        return F.pad(x, (pad, 0))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # x: (B, C_in, T)\n",
    "        y = self._causal_pad(x) if self.padding_mode == \"causal\" else x\n",
    "        y = self.drop1(self.act(self.bn1(self.conv1(y))))\n",
    "\n",
    "        y = self._causal_pad(y) if self.padding_mode == \"causal\" else y\n",
    "        y = self.drop2(self.act(self.bn2(self.conv2(y))))\n",
    "\n",
    "        skip = y  # per-block skip is the post-second-activation output\n",
    "\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        out = self.act(y + res)\n",
    "        return out, skip  # both (B, C_out, T)\n",
    "\n",
    "\n",
    "class TCN1DPT(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal Convolutional Network over sequences (B, T, C_in).\n",
    "    - When use_skip_connections=True: sum per-block skip outputs, then apply a final activation.\n",
    "    - Otherwise: use the last block’s residual output.\n",
    "    - return_sequences=False: returns last timestep features (B, C_out).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_filters: int = 32,\n",
    "        kernel_size: int = 4,\n",
    "        conv_stacks: int = 2,\n",
    "        conv_dilations: Iterable[int] = (1, 2, 4, 8),\n",
    "        padding: str = \"causal\",\n",
    "        use_skip_connections: bool = True,\n",
    "        dropout_rate: float = 0.0,\n",
    "        activation: str = \"relu\",\n",
    "        use_batch_norm: bool = True,\n",
    "        return_sequences: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_skip_connections = use_skip_connections\n",
    "        self.return_sequences = return_sequences\n",
    "        self.final_act = _act(activation)\n",
    "\n",
    "        blocks = []\n",
    "        c_in = in_channels\n",
    "        for _ in range(int(conv_stacks)):\n",
    "            for d in tuple(conv_dilations):\n",
    "                blocks.append(\n",
    "                    TemporalBlockPT(\n",
    "                        in_channels=c_in,\n",
    "                        out_channels=conv_filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        dilation=int(d),\n",
    "                        padding=padding,\n",
    "                        dropout_rate=dropout_rate,\n",
    "                        activation=activation,\n",
    "                        use_batch_norm=use_batch_norm,\n",
    "                    )\n",
    "                )\n",
    "                c_in = conv_filters\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, T, C_in) -> Conv1d expects (B, C_in, T)\n",
    "        y = x.transpose(1, 2)\n",
    "        skip_sum, last_out = None, None\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            y, skip = blk(y)\n",
    "            last_out = y\n",
    "            if self.use_skip_connections:\n",
    "                skip_sum = skip if skip_sum is None else (skip_sum + skip)\n",
    "\n",
    "        out = skip_sum if self.use_skip_connections else last_out  # (B, C, T)\n",
    "        out = self.final_act(out)\n",
    "        return out.transpose(1, 2) if self.return_sequences else out[:, :, -1]\n",
    "\n",
    "\n",
    "class TCNEncoderPT(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch port of the TF get_TCN_encoder with matching behavior:\n",
    "      - Inputs:\n",
    "          x: (B, W, N, NF)   node features\n",
    "          a: (B, W, E, EF)   edge features\n",
    "      - use_gnn=True:\n",
    "          TimeDistributed(TCN) over nodes/edges -> (B, N, C) and (B, E, C)\n",
    "          CensNetConvPT([node, (lap, edge_lap, inc), edge]) -> (B, N, latent), (B, E, latent)\n",
    "          Flatten and MLP head\n",
    "      - use_gnn=False:\n",
    "          Flatten nodes+features -> TCN -> MLP head\n",
    "\n",
    "      Parity details:\n",
    "        - keras-tcn-compatible skip semantics and activation placement\n",
    "        - BN eps=1e-3 everywhere\n",
    "        - 'causal' and 'same' paddings supported\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: Tuple[int, int, int],        # (W, N, NF)\n",
    "        edge_feature_shape: Tuple[int, int, int], # (W, E, EF)\n",
    "        adjacency_matrix: np.ndarray,\n",
    "        latent_dim: int,\n",
    "        use_gnn: bool = True,\n",
    "        conv_filters: int = 32,\n",
    "        kernel_size: int = 4,\n",
    "        conv_stacks: int = 2,\n",
    "        conv_dilations: Iterable[int] = (1, 2, 4, 8),\n",
    "        padding: str = \"causal\",\n",
    "        use_skip_connections: bool = True,\n",
    "        dropout_rate: float = 0.0,\n",
    "        activation: str = \"relu\",\n",
    "        interaction_regularization: float = 0.0,  # not used explicitly in PT\n",
    "        use_batch_norm: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_gnn = use_gnn\n",
    "        self.latent_dim = int(latent_dim)\n",
    "        self.conv_filters = int(conv_filters)\n",
    "\n",
    "        W, N, F_node = input_shape\n",
    "        _, E, F_edge = edge_feature_shape\n",
    "        assert adjacency_matrix.shape[0] == N == adjacency_matrix.shape[1], \"Adjacency must be NxN and match input nodes.\"\n",
    "\n",
    "        tcn_cfg = dict(\n",
    "            conv_filters=conv_filters,\n",
    "            kernel_size=kernel_size,\n",
    "            conv_stacks=conv_stacks,\n",
    "            conv_dilations=tuple(conv_dilations),\n",
    "            padding=padding,\n",
    "            use_skip_connections=use_skip_connections,\n",
    "            dropout_rate=float(dropout_rate),\n",
    "            activation=activation,\n",
    "            use_batch_norm=use_batch_norm,\n",
    "            return_sequences=False,\n",
    "        )\n",
    "\n",
    "        if use_gnn:\n",
    "            # Per-node and per-edge TCNs\n",
    "            self.node_tcn = TCN1DPT(in_channels=F_node, **tcn_cfg)\n",
    "            self.edge_tcn = TCN1DPT(in_channels=F_edge, **tcn_cfg)\n",
    "\n",
    "            # Graph block and buffers\n",
    "            self.spatial_gnn_block = CensNetConvPT(node_channels=latent_dim, edge_channels=latent_dim, activation=\"relu\")\n",
    "            lap, edge_lap, inc = self.spatial_gnn_block.preprocess(torch.tensor(adjacency_matrix))\n",
    "            self.register_buffer(\"laplacian\", lap.float())\n",
    "            self.register_buffer(\"edge_laplacian\", edge_lap.float())\n",
    "            self.register_buffer(\"incidence\", inc.float())\n",
    "\n",
    "            final_in = (N * latent_dim) + (E * latent_dim)\n",
    "        else:\n",
    "            # Single TCN over flattened node features\n",
    "            self.flat_tcn = TCN1DPT(in_channels=N * F_node, **tcn_cfg)\n",
    "            final_in = conv_filters\n",
    "\n",
    "        # Head MLP: Dense(2*latent) -> BN -> Dense(latent) -> BN -> Dense(latent)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(final_in, 2 * latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2 * latent_dim, eps=1e-3),\n",
    "            nn.Linear(2 * latent_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(latent_dim, eps=1e-3),\n",
    "            nn.Linear(latent_dim, latent_dim),\n",
    "        )\n",
    "        for m in self.head.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight); nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, a: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B, W, N, NF)  a: (B, W, E, EF)  -> returns (B, latent_dim)\n",
    "        \"\"\"\n",
    "        B, W, N, F_node = x.shape\n",
    "        _, _, E, F_edge = a.shape\n",
    "\n",
    "        if self.use_gnn:\n",
    "            # Nodes: TF-style reshape pipeline to match memory layout exactly\n",
    "            x_3d = x.view(B, W, N * F_node)          # (B, W, N*F)\n",
    "            x_t = x_3d.permute(2, 1, 0)              # (N*F, W, B)\n",
    "            x_reshaped_t = x_t.reshape(F_node, W, N, B)\n",
    "            x_nodes = x_reshaped_t.permute(3, 2, 1, 0)  # (B, N, W, F)\n",
    "\n",
    "            node_in = x_nodes.reshape(B * N, W, F_node)\n",
    "            node_out = self.node_tcn(node_in).view(B, N, self.conv_filters)  # (B, N, C)\n",
    "\n",
    "            # Edges: TF-style reshape pipeline to match memory layout exactly\n",
    "            a_3d = a.view(B, W, E * F_edge)          # (B, W, E*F_edge)\n",
    "            a_t = a_3d.permute(2, 1, 0)              # (E*F_edge, W, B)\n",
    "            a_reshaped_t = a_t.reshape(F_edge, W, E, B)\n",
    "            a_edges = a_reshaped_t.permute(3, 2, 1, 0)  # (B, E, W, F_edge)\n",
    "\n",
    "            edge_in = a_edges.reshape(B * E, W, F_edge)\n",
    "            edge_out = self.edge_tcn(edge_in).view(B, E, self.conv_filters)  # (B, E, C)\n",
    "\n",
    "            # Graph block\n",
    "            adj_tuple = (self.laplacian, self.edge_laplacian, self.incidence)\n",
    "            x_nodes_g, x_edges_g = self.spatial_gnn_block([node_out, adj_tuple, edge_out])\n",
    "            x_nodes_g = F.relu(x_nodes_g)\n",
    "            x_edges_g = F.relu(x_edges_g)\n",
    "\n",
    "            enc = torch.cat([x_nodes_g.reshape(B, -1), x_edges_g.reshape(B, -1)], dim=-1)\n",
    "        else:\n",
    "            # Non-GNN unchanged\n",
    "            x_flat = x.view(B, W, N * F_node)        # (B, W, N*NF)\n",
    "            enc = self.flat_tcn(x_flat)              # (B, C)\n",
    "\n",
    "        return self.head(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1005e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import tcn as tcn_pkg\n",
    "\n",
    "def _tf_conv1d_to_torch(w_keras: np.ndarray) -> torch.Tensor:\n",
    "    # TF Conv1D [K, Cin, Cout] -> PT Conv1d [Cout, Cin, K]\n",
    "    return torch.from_numpy(np.transpose(w_keras, (2, 1, 0)))\n",
    "\n",
    "def _load_bn_tf_to_pt(pt_bn: nn.BatchNorm1d, tf_bn: tf.keras.layers.BatchNormalization):\n",
    "    gamma, beta, moving_mean, moving_var = tf_bn.get_weights()\n",
    "    pt_bn.weight.data = torch.from_numpy(gamma)\n",
    "    pt_bn.bias.data = torch.from_numpy(beta)\n",
    "    pt_bn.running_mean.data = torch.from_numpy(moving_mean)\n",
    "    pt_bn.running_var.data = torch.from_numpy(moving_var)\n",
    "\n",
    "def _kernel_size_1(conv: tf.keras.layers.Conv1D) -> bool:\n",
    "    ks = conv.kernel_size\n",
    "    ks = ks[0] if isinstance(ks, tuple) else ks\n",
    "    return ks == 1\n",
    "\n",
    "def _collect_tcn_sublayers(tf_tcn_layer: tf.keras.layers.Layer):\n",
    "    # Use submodules as before; we’ll still verify counts and assign conservatively\n",
    "    convs = [m for m in tf_tcn_layer.submodules if isinstance(m, tf.keras.layers.Conv1D)]\n",
    "    bns = [m for m in tf_tcn_layer.submodules if isinstance(m, tf.keras.layers.BatchNormalization)]\n",
    "    return convs, bns\n",
    "\n",
    "def transfer_td_tcn_weights(tf_td_tcn: tf.keras.layers.TimeDistributed, pt_tcn) -> None:\n",
    "    \"\"\"\n",
    "    Transfer weights from TF TimeDistributed(tcn.TCN) into PT TCN1DPT:\n",
    "      - Map per-block [conv1, conv2] (in order) and their BN layers\n",
    "      - Map the single residual 1x1 projection (matching_conv1D), if present\n",
    "      - No skip 1x1 convs (your model has none)\n",
    "    \"\"\"\n",
    "    assert isinstance(tf_td_tcn, tf.keras.layers.TimeDistributed)\n",
    "    assert isinstance(tf_td_tcn.layer, tcn_pkg.TCN)\n",
    "    tf_tcn = tf_td_tcn.layer\n",
    "\n",
    "    convs, bns = _collect_tcn_sublayers(tf_tcn)\n",
    "    block_convs = [c for c in convs if not _kernel_size_1(c)]   # conv1D_0 / conv1D_1 pairs per block\n",
    "    proj_1x1 = [c for c in convs if _kernel_size_1(c)]          # matching_conv1D (0 or 1 in your build)\n",
    "\n",
    "    num_blocks = len(pt_tcn.blocks)\n",
    "    assert len(block_convs) == 2 * num_blocks, f\"Conv count mismatch: TF block convs={len(block_convs)}, PT blocks={num_blocks}\"\n",
    "\n",
    "    use_bn = isinstance(pt_tcn.blocks[0].bn1, nn.BatchNorm1d)\n",
    "    if use_bn:\n",
    "        assert len(bns) >= 2 * num_blocks, f\"BN count mismatch: TF BNs={len(bns)}, expected >= {2 * num_blocks}\"\n",
    "\n",
    "    # Load per-block convs and BN stats\n",
    "    for i, blk in enumerate(pt_tcn.blocks):\n",
    "        k1, b1 = block_convs[2 * i].get_weights()\n",
    "        blk.conv1.weight.data = _tf_conv1d_to_torch(k1)\n",
    "        blk.conv1.bias.data = torch.from_numpy(b1)\n",
    "\n",
    "        k2, b2 = block_convs[2 * i + 1].get_weights()\n",
    "        blk.conv2.weight.data = _tf_conv1d_to_torch(k2)\n",
    "        blk.conv2.bias.data = torch.from_numpy(b2)\n",
    "\n",
    "        if use_bn:\n",
    "            _load_bn_tf_to_pt(blk.bn1, bns[2 * i])\n",
    "            _load_bn_tf_to_pt(blk.bn2, bns[2 * i + 1])\n",
    "\n",
    "    # Residual projection for the first block if needed\n",
    "    proj_idx = 0\n",
    "    for blk in pt_tcn.blocks:\n",
    "        if isinstance(getattr(blk, \"downsample\", None), nn.Conv1d):\n",
    "            rk, rb = proj_1x1[proj_idx].get_weights()\n",
    "            blk.downsample.weight.data = _tf_conv1d_to_torch(rk)\n",
    "            blk.downsample.bias.data = torch.from_numpy(rb)\n",
    "            proj_idx += 1\n",
    "\n",
    "\n",
    "# ---------- MLP head transfer ----------\n",
    "\n",
    "def transfer_head_mlp(tf_model, pt_model_head: nn.Sequential):\n",
    "    \"\"\"\n",
    "    Transfer the final MLP head:\n",
    "      Dense(2*latent, relu) -> BN -> Dense(latent, relu) -> BN -> Dense(latent)\n",
    "    from TF model to PT head (Linear, BN, Linear, BN, Linear).\n",
    "    \"\"\"\n",
    "    # Extract the final [Dense, BN, Dense, BN, Dense] from TF model\n",
    "    tail = [l for l in tf_model.layers if isinstance(l, (tf.keras.layers.Dense, tf.keras.layers.BatchNormalization))]\n",
    "    d1, bn1, d2, bn2, d3 = tail[-5:]\n",
    "\n",
    "    # PT head layout: [Linear, ReLU, BN, Linear, ReLU, BN, Linear]\n",
    "    lin1: nn.Linear = pt_model_head[0]\n",
    "    bn1_pt: nn.BatchNorm1d = pt_model_head[2]\n",
    "    lin2: nn.Linear = pt_model_head[3]\n",
    "    bn2_pt: nn.BatchNorm1d = pt_model_head[5]\n",
    "    lin3: nn.Linear = pt_model_head[6]\n",
    "\n",
    "    # Dense 1\n",
    "    w, b = d1.get_weights()\n",
    "    lin1.weight.data = torch.from_numpy(w.T)\n",
    "    lin1.bias.data = torch.from_numpy(b)\n",
    "    # BN 1\n",
    "    _load_bn_tf_to_pt(bn1_pt, bn1)\n",
    "    # Dense 2\n",
    "    w, b = d2.get_weights()\n",
    "    lin2.weight.data = torch.from_numpy(w.T)\n",
    "    lin2.bias.data = torch.from_numpy(b)\n",
    "    # BN 2\n",
    "    _load_bn_tf_to_pt(bn2_pt, bn2)\n",
    "    # Dense 3\n",
    "    w, b = d3.get_weights()\n",
    "    lin3.weight.data = torch.from_numpy(w.T)\n",
    "    lin3.bias.data = torch.from_numpy(b)\n",
    "\n",
    "\n",
    "# ---------- High-level: TCN encoder transfer ----------\n",
    "\n",
    "def transfer_tcn_encoder_weights(tf_model, pt_model, use_gnn: bool):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full TCN encoder.\n",
    "      - Node and edge TimeDistributed(TCN) blocks\n",
    "      - CensNetConv (if use_gnn)\n",
    "      - Final MLP head\n",
    "    \"\"\"\n",
    "    # 1) Final head\n",
    "    transfer_head_mlp(tf_model, pt_model.head)\n",
    "\n",
    "    # 2) TimeDistributed(TCN) blocks\n",
    "    td_layers = [l for l in tf_model.layers if isinstance(l, tf.keras.layers.TimeDistributed) and isinstance(l.layer, tcn.TCN)]\n",
    "    if use_gnn:\n",
    "        assert len(td_layers) >= 2, \"Expected two TimeDistributed(TCN) layers (node and edge) for use_gnn=True\"\n",
    "        # Heuristically: first TD is nodes, second is edges (matches build order)\n",
    "        node_td = td_layers[0]\n",
    "        edge_td = td_layers[1]\n",
    "        transfer_td_tcn_weights(node_td, pt_model.node_tcn)\n",
    "        transfer_td_tcn_weights(edge_td, pt_model.edge_tcn)\n",
    "\n",
    "        # 3) CensNetConv\n",
    "        gnn_layer = next(l for l in tf_model.layers if isinstance(l, CensNetConv))\n",
    "        transfer_censnet_weights(gnn_layer, pt_model.spatial_gnn_block)\n",
    "\n",
    "    else:\n",
    "        # Non-GNN: single TD(TCN); TF input_shape should be (T, N*F_node)\n",
    "        assert len(td_layers) >= 1, \"Expected one TimeDistributed(TCN) layer for use_gnn=False\"\n",
    "        transfer_td_tcn_weights(td_layers[0], pt_model.flat_tcn)\n",
    "\n",
    "def transfer_censnet_weights(tf_layer, pt_layer):\n",
    "    \"\"\"\n",
    "    Transfers all six weights from a Spektral CensNetConv layer to the\n",
    "    corresponding CensNetConvPT layer.\n",
    "    \"\"\"\n",
    "    # Get all weights from the TensorFlow layer. The order is determined by\n",
    "    # the layer's build order in Spektral's source code.\n",
    "    tf_weights = tf_layer.get_weights()\n",
    "\n",
    "    # Unpack all six weights.\n",
    "    # Order: kernel_node, bias_node, kernel_edge, bias_edge, projector_node, projector_edge\n",
    "    kn_tf, bn_tf, ke_tf, be_tf, pn_tf, pe_tf = tf_weights\n",
    "\n",
    "    # Build weights on first pass\n",
    "    if pt_layer.node_kernel is None:\n",
    "        # Move parameters to the same device as input tensors\n",
    "        pt_layer._build(kn_tf.T.shape, bn_tf.T.shape)\n",
    "        #pt_layer.to(kn_tf.device)\n",
    "\n",
    "    # 1. & 2. Transfer Node Kernel and Bias\n",
    "    # Keras Dense kernel is (in_features, out_features)\n",
    "    pt_layer.node_kernel.data = torch.from_numpy(kn_tf)\n",
    "    pt_layer.edge_kernel.data = torch.from_numpy(bn_tf)\n",
    "\n",
    "    # 3. & 4. Transfer Edge Kernel and Bias\n",
    "    # Same transposition logic applies.\n",
    "    pt_layer.node_weights.data = torch.from_numpy(ke_tf)\n",
    "    pt_layer.edge_weights.data = torch.from_numpy(be_tf)\n",
    "\n",
    "    # 5. Transfer Node Projector Weights (P_n)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.node_bias.data = torch.from_numpy(pn_tf)\n",
    "\n",
    "    # 6. Transfer Edge Projector Weights (P_e)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.edge_bias.data = torch.from_numpy(pe_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aa734e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward_pass_gnn (__main__.TestTCNEncoderTranslation) ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "ok\n",
      "test_forward_pass_no_gnn (__main__.TestTCNEncoderTranslation) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN TF time: 0.8204047679901123 PT time: 0.03664565086364746\n",
      "✅ TCNEncoderPT (GNN path) parity PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 3.062s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TCNEncoderPT (non-GNN path) parity PASSED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest, time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def count_undirected_edges(adj: np.ndarray) -> int:\n",
    "    # Count upper-triangular non-zero entries (undirected edges)\n",
    "    return int(np.count_nonzero(np.triu(adj, 1)))\n",
    "\n",
    "class TestTCNEncoderTranslation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        # Fundamental dims (use your conventions)\n",
    "        self.R = 2048                 # number of rows (not used for model build)\n",
    "        self.W = 25                   # window length\n",
    "        self.N = 11                   # nodes\n",
    "        self.NF = 3                   # features per node\n",
    "        self.EF = 1                   # features per edge (TF expects 1 for the reshape quirk)\n",
    "        self.latent_dim = 6\n",
    "        self.use_gnn = True\n",
    "\n",
    "        # Batch used for parity test\n",
    "        self.B = 128\n",
    "\n",
    "        # Make an adjacency whose undirected edge count E matches the edge axis we'll use\n",
    "        # Example: pick a sparse symmetric adjacency with E edges\n",
    "        # If you already have an adjacency, just set self.adj_matrix = your_matrix and let E = count_undirected_edges(A)\n",
    "        rng = np.random.default_rng(0)\n",
    "        A = np.zeros((self.N, self.N), dtype=np.float32)\n",
    "        # randomly pick E edges; here we choose E = 11 (as in your typical config)\n",
    "        target_E = 11\n",
    "        iu = np.triu_indices(self.N, 1)\n",
    "        idx = rng.choice(len(iu[0]), size=target_E, replace=False)\n",
    "        A[iu[0][idx], iu[1][idx]] = 1.0\n",
    "        A = A + A.T\n",
    "        self.adj_matrix = A\n",
    "        self.E = count_undirected_edges(self.adj_matrix)  # should be target_E\n",
    "\n",
    "        # TF input shapes (flattened)\n",
    "        self.tf_input_shape_gnn = (self.W, self.N * self.NF)  # (W, NNF)\n",
    "        self.tf_edge_shape      = (self.W, self.E * self.EF)  # (W, EEF) -> with EF=1, equals (W, E)\n",
    "\n",
    "        # PT input shapes (split)\n",
    "        self.pt_input_shape = (self.W, self.N, self.NF)       # (W, N, NF)\n",
    "        self.pt_edge_shape  = (self.W, self.E, self.EF)       # (W, E, EF)\n",
    "\n",
    "        # Random inputs\n",
    "        self.x_pt = rng.normal(size=(self.B, self.W, self.N, self.NF)).astype(np.float32)\n",
    "        self.a_pt = rng.normal(size=(self.B, self.W, self.E, self.EF)).astype(np.float32)\n",
    "        # Flatten for TF model\n",
    "        self.x_tf = self.x_pt.reshape(self.B, self.W, self.N * self.NF)\n",
    "        self.a_tf = self.a_pt.reshape(self.B, self.W, self.E * self.EF)  # with EF=1, (B, W, E)\n",
    "\n",
    "        # Common TCN params\n",
    "        self.conv_filters = 32\n",
    "        self.kernel_size = 3\n",
    "        self.conv_stacks = 2\n",
    "        self.conv_dilations = (1, 2)\n",
    "        self.padding = \"causal\"\n",
    "        self.use_skip = True\n",
    "        self.dropout = 0.0\n",
    "        self.activation = \"relu\"\n",
    "\n",
    "    def test_forward_pass_gnn(self):\n",
    "        # Build TF and PT models\n",
    "        tf_model = get_TCN_encoder(\n",
    "            input_shape=self.tf_input_shape_gnn,   # (W, NNF)\n",
    "            edge_feature_shape=self.tf_edge_shape, # (W, EEF) -> E when EF=1\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=True,\n",
    "            conv_filters=self.conv_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            conv_stacks=self.conv_stacks,\n",
    "            conv_dilations=self.conv_dilations,\n",
    "            padding=self.padding,\n",
    "            use_skip_connections=self.use_skip,\n",
    "            dropout_rate=self.dropout,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "        pt_model = TCNEncoderPT(\n",
    "            input_shape=self.pt_input_shape,       # (W, N, NF)\n",
    "            edge_feature_shape=self.pt_edge_shape, # (W, E, EF)\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=True,\n",
    "            conv_filters=self.conv_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            conv_stacks=self.conv_stacks,\n",
    "            conv_dilations=self.conv_dilations,\n",
    "            padding=self.padding,\n",
    "            use_skip_connections=self.use_skip,\n",
    "            dropout_rate=self.dropout,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "        pt_model.eval()\n",
    "\n",
    "        # Warm-up PT graph (optional)\n",
    "        with torch.no_grad():\n",
    "            _ = pt_model(torch.from_numpy(self.x_pt), torch.from_numpy(self.a_pt))\n",
    "\n",
    "        # Transfer weights TF -> PT\n",
    "        transfer_tcn_encoder_weights(tf_model, pt_model, use_gnn=True)\n",
    "\n",
    "        # Compare outputs (TF expects flattened a)\n",
    "        t0 = time.time()\n",
    "        y_tf = tf_model([self.x_tf, self.a_tf], training=False).numpy()\n",
    "        t1 = time.time()\n",
    "        with torch.no_grad():\n",
    "            y_pt = pt_model(torch.from_numpy(self.x_pt), torch.from_numpy(self.a_pt)).cpu().numpy()\n",
    "        t2 = time.time()\n",
    "        print(\"GNN TF time:\", t1 - t0, \"PT time:\", t2 - t1)\n",
    "        np.testing.assert_allclose(y_tf, y_pt, rtol=1e-5, atol=2e-4)\n",
    "        print(\"✅ TCNEncoderPT (GNN path) parity PASSED\")\n",
    "\n",
    "    def test_forward_pass_no_gnn(self):\n",
    "        # Build TF and PT models (TF expects flattened x, a still provided but unused)\n",
    "        tf_model = get_TCN_encoder(\n",
    "            input_shape=self.tf_input_shape_gnn,   # (W, NNF) in your pipeline\n",
    "            edge_feature_shape=self.tf_edge_shape, # (W, EEF)\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=False,\n",
    "            conv_filters=self.conv_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            conv_stacks=self.conv_stacks,\n",
    "            conv_dilations=self.conv_dilations,\n",
    "            padding=self.padding,\n",
    "            use_skip_connections=self.use_skip,\n",
    "            dropout_rate=self.dropout,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "        pt_model = TCNEncoderPT(\n",
    "            input_shape=self.pt_input_shape,       # (W, N, NF)\n",
    "            edge_feature_shape=self.pt_edge_shape, # (W, E, EF)\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=False,\n",
    "            conv_filters=self.conv_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            conv_stacks=self.conv_stacks,\n",
    "            conv_dilations=self.conv_dilations,\n",
    "            padding=self.padding,\n",
    "            use_skip_connections=self.use_skip,\n",
    "            dropout_rate=self.dropout,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "        pt_model.eval()\n",
    "\n",
    "        # Transfer weights TF -> PT\n",
    "        transfer_tcn_encoder_weights(tf_model, pt_model, use_gnn=False)\n",
    "\n",
    "        # Compare outputs (TF expects flattened x, a flattened to EEF)\n",
    "        y_tf = tf_model([self.x_tf, self.a_tf], training=False).numpy()\n",
    "        with torch.no_grad():\n",
    "            y_pt = pt_model(torch.from_numpy(self.x_pt), torch.from_numpy(self.a_pt)).cpu().numpy()\n",
    "\n",
    "        np.testing.assert_allclose(y_tf, y_pt, rtol=1e-5, atol=2e-4)\n",
    "        print(\"✅ TCNEncoderPT (non-GNN path) parity PASSED\")\n",
    "\n",
    "# Run\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestTCNEncoderTranslation)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "386550a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCN-only shapes -> TF: (128, 32) PT: (128, 32)\n",
      "TCN-only mean abs diff: 2.9500695e-08\n",
      "TCN-only max abs diff: 2.9802322e-07\n"
     ]
    }
   ],
   "source": [
    "# TCN-only parity diagnostic (non-GNN), fully executable with your provided dims\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import tcn as tcn_pkg\n",
    "\n",
    "# Assumes get_TCN_encoder and TCNEncoderPT are already defined/imported in your notebook.\n",
    "\n",
    "# -------------------------\n",
    "# 1) Your provided settings\n",
    "# -------------------------\n",
    "batch_size = 128\n",
    "window_length = 25\n",
    "num_nodes = 11\n",
    "features_per_node = 3\n",
    "num_edges = 11\n",
    "features_per_edge = 1\n",
    "\n",
    "latent_dim = 6\n",
    "use_gnn = False\n",
    "\n",
    "# Adjacency matrix\n",
    "m = np.zeros((num_nodes, num_nodes), dtype=np.float32)\n",
    "ui = np.triu_indices(num_nodes)\n",
    "num_possible_edges = len(ui[0])\n",
    "c = np.random.choice(num_possible_edges, min(num_edges, num_possible_edges), replace=False)\n",
    "m[ui[0][c], ui[1][c]] = 1\n",
    "m = (m + m.T).astype(np.float32)  # symmetric\n",
    "adj_matrix = m\n",
    "\n",
    "# Input shapes\n",
    "tf_input_shape = (window_length, num_nodes * features_per_node)     # TF non-GNN expects flattened features\n",
    "pt_input_shape = (window_length, num_nodes, features_per_node)      # PT expects (T, N, F_node)\n",
    "edge_shape = (window_length, num_edges, features_per_edge)\n",
    "\n",
    "# Random inputs\n",
    "rng = np.random.default_rng(0)\n",
    "x_np = rng.normal(size=(batch_size, window_length, num_nodes, features_per_node)).astype(np.float32)\n",
    "a_np = rng.normal(size=(batch_size, window_length, num_edges, features_per_edge)).astype(np.float32)\n",
    "\n",
    "# ------------------------------------\n",
    "# 2) Build TF and PT (non-GNN) models\n",
    "# ------------------------------------\n",
    "tf_model = get_TCN_encoder(\n",
    "    input_shape=tf_input_shape,\n",
    "    edge_feature_shape=edge_shape,\n",
    "    adjacency_matrix=adj_matrix,\n",
    "    latent_dim=latent_dim,\n",
    "    use_gnn=False,\n",
    "    conv_filters=32,\n",
    "    kernel_size=3,\n",
    "    conv_stacks=2,\n",
    "    conv_dilations=(1, 2),\n",
    "    padding=\"causal\",\n",
    "    use_skip_connections=True,\n",
    "    dropout_rate=0.0,\n",
    "    activation=\"relu\",\n",
    ")\n",
    "\n",
    "pt_model = TCNEncoderPT(\n",
    "    input_shape=pt_input_shape,\n",
    "    edge_feature_shape=edge_shape,\n",
    "    adjacency_matrix=adj_matrix,\n",
    "    latent_dim=latent_dim,\n",
    "    use_gnn=False,\n",
    "    conv_filters=32,\n",
    "    kernel_size=3,\n",
    "    conv_stacks=2,\n",
    "    conv_dilations=(1, 2),\n",
    "    padding=\"causal\",\n",
    "    use_skip_connections=True,\n",
    "    dropout_rate=0.0,\n",
    "    activation=\"relu\",\n",
    ")\n",
    "\n",
    "pt_model.eval()\n",
    "\n",
    "# Ensure PT BN eps=1e-3 inside TCN (BN eps mismatch is a common source of diffs)\n",
    "for blk in pt_model.flat_tcn.blocks:\n",
    "    if isinstance(blk.bn1, nn.BatchNorm1d):\n",
    "        blk.bn1.eps = 1e-3\n",
    "    if isinstance(blk.bn2, nn.BatchNorm1d):\n",
    "        blk.bn2.eps = 1e-3\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Helpers: extract TD(TCN) and transfer weights\n",
    "# ------------------------------------------------\n",
    "def get_first_td_tcn(tf_model):\n",
    "    for l in tf_model.layers:\n",
    "        if isinstance(l, tf.keras.layers.TimeDistributed) and isinstance(l.layer, tcn_pkg.TCN):\n",
    "            return l\n",
    "    raise RuntimeError(\"No TimeDistributed(TCN) found in TF model.\")\n",
    "\n",
    "def _tf_conv1d_to_torch(w_keras: np.ndarray) -> torch.Tensor:\n",
    "    # TF/Keras Conv1D: [kernel, in, out] -> PT Conv1d: [out, in, kernel]\n",
    "    return torch.from_numpy(np.transpose(w_keras, (2, 1, 0)))\n",
    "\n",
    "def _load_bn_tf_to_pt(pt_bn: nn.BatchNorm1d, tf_bn: tf.keras.layers.BatchNormalization):\n",
    "    gamma, beta, moving_mean, moving_var = tf_bn.get_weights()\n",
    "    pt_bn.weight.data = torch.from_numpy(gamma)\n",
    "    pt_bn.bias.data = torch.from_numpy(beta)\n",
    "    pt_bn.running_mean.data = torch.from_numpy(moving_mean)\n",
    "    pt_bn.running_var.data = torch.from_numpy(moving_var)\n",
    "\n",
    "def _kernel_size_1(conv: tf.keras.layers.Conv1D) -> bool:\n",
    "    ks = conv.kernel_size\n",
    "    ks = ks[0] if isinstance(ks, tuple) else ks\n",
    "    return ks == 1\n",
    "\n",
    "def _collect_tcn_sublayers(tf_tcn_layer: tf.keras.layers.Layer):\n",
    "    convs = [m for m in tf_tcn_layer.submodules if isinstance(m, tf.keras.layers.Conv1D)]\n",
    "    bns = [m for m in tf_tcn_layer.submodules if isinstance(m, tf.keras.layers.BatchNormalization)]\n",
    "    return convs, bns\n",
    "\n",
    "def transfer_td_tcn_weights(tf_td_tcn: tf.keras.layers.TimeDistributed, pt_tcn) -> None:\n",
    "    assert isinstance(tf_td_tcn, tf.keras.layers.TimeDistributed)\n",
    "    assert isinstance(tf_td_tcn.layer, tcn_pkg.TCN)\n",
    "    tf_tcn = tf_td_tcn.layer\n",
    "\n",
    "    convs, bns = _collect_tcn_sublayers(tf_tcn)\n",
    "    block_convs = [c for c in convs if not _kernel_size_1(c)]\n",
    "    resid_convs = [c for c in convs if _kernel_size_1(c)]  # includes residual 1x1 (and possibly skip 1x1s)\n",
    "\n",
    "    num_blocks = len(pt_tcn.blocks)\n",
    "    assert len(block_convs) == 2 * num_blocks, f\"Conv count mismatch: TF block convs={len(block_convs)}, PT blocks={num_blocks}\"\n",
    "\n",
    "    # Map conv1/conv2 + BN1/BN2\n",
    "    use_bn = isinstance(pt_tcn.blocks[0].bn1, nn.BatchNorm1d)\n",
    "    if use_bn:\n",
    "        assert len(bns) >= 2 * num_blocks, f\"BN count mismatch: TF BNs={len(bns)}, expected >= {2 * num_blocks}\"\n",
    "\n",
    "    for i, blk in enumerate(pt_tcn.blocks):\n",
    "        k1, b1 = block_convs[2 * i].get_weights()\n",
    "        blk.conv1.weight.data = _tf_conv1d_to_torch(k1)\n",
    "        blk.conv1.bias.data = torch.from_numpy(b1)\n",
    "\n",
    "        k2, b2 = block_convs[2 * i + 1].get_weights()\n",
    "        blk.conv2.weight.data = _tf_conv1d_to_torch(k2)\n",
    "        blk.conv2.bias.data = torch.from_numpy(b2)\n",
    "\n",
    "        if use_bn:\n",
    "            _load_bn_tf_to_pt(blk.bn1, bns[2 * i])\n",
    "            _load_bn_tf_to_pt(blk.bn2, bns[2 * i + 1])\n",
    "\n",
    "    # Residual 1x1 projection: only if PT block has it (assumes attribute name 'downsample' as you set)\n",
    "    resid_idx = 0\n",
    "    for blk in pt_tcn.blocks:\n",
    "        if isinstance(getattr(blk, \"downsample\", None), nn.Conv1d):\n",
    "            rk, rb = resid_convs[resid_idx].get_weights()\n",
    "            blk.downsample.weight.data = _tf_conv1d_to_torch(rk)\n",
    "            blk.downsample.bias.data = torch.from_numpy(rb)\n",
    "            resid_idx += 1\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4) Compare TCN-only outputs (TF TD(TCN) vs PT flat_tcn)\n",
    "# ------------------------------------------------------\n",
    "# Build a TF submodel that outputs the TimeDistributed(TCN) output only\n",
    "td = get_first_td_tcn(tf_model)\n",
    "tf_tcn_sub = tf.keras.Model(tf_model.inputs, td.output)  # -> (B, 1, conv_filters)\n",
    "\n",
    "# Transfer only the TCN weights TF -> PT (no head)\n",
    "transfer_td_tcn_weights(td, pt_model.flat_tcn)\n",
    "\n",
    "# Prepare inputs\n",
    "x_tf = x_np.reshape(batch_size, window_length, num_nodes * features_per_node)  # flattened for TF\n",
    "x_pt = torch.from_numpy(x_np)\n",
    "\n",
    "# Run\n",
    "tf_out = tf_tcn_sub([x_tf, a_np], training=False).numpy()   # (B, 1, C)\n",
    "tf_out = np.squeeze(tf_out, axis=1)                         # (B, C)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pt_out = pt_model.flat_tcn(x_pt.view(batch_size, window_length, num_nodes * features_per_node)).cpu().numpy()  # (B, C)\n",
    "\n",
    "# Report basic stats\n",
    "abs_diff = np.abs(tf_out - pt_out)\n",
    "print(\"TCN-only shapes -> TF:\", tf_out.shape, \"PT:\", pt_out.shape)\n",
    "print(\"TCN-only mean abs diff:\", abs_diff.mean())\n",
    "print(\"TCN-only max abs diff:\", abs_diff.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0754177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convs:\n",
      "   0: name=conv1D_0, kernel_size=3, filters=32\n",
      "   1: name=conv1D_1, kernel_size=3, filters=32\n",
      "   2: name=matching_conv1D, kernel_size=1, filters=32\n",
      "   3: name=conv1D_0, kernel_size=3, filters=32\n",
      "   4: name=conv1D_1, kernel_size=3, filters=32\n",
      "   5: name=conv1D_0, kernel_size=3, filters=32\n",
      "   6: name=conv1D_1, kernel_size=3, filters=32\n",
      "   7: name=conv1D_0, kernel_size=3, filters=32\n",
      "   8: name=conv1D_1, kernel_size=3, filters=32\n",
      "BNs:\n",
      "   0: name=batch_normalization, epsilon=0.001, momentum=0.99\n",
      "   1: name=batch_normalization_1, epsilon=0.001, momentum=0.99\n",
      "   2: name=batch_normalization_2, epsilon=0.001, momentum=0.99\n",
      "   3: name=batch_normalization_3, epsilon=0.001, momentum=0.99\n",
      "   4: name=batch_normalization_4, epsilon=0.001, momentum=0.99\n",
      "   5: name=batch_normalization_5, epsilon=0.001, momentum=0.99\n",
      "   6: name=batch_normalization_6, epsilon=0.001, momentum=0.99\n",
      "   7: name=batch_normalization_7, epsilon=0.001, momentum=0.99\n"
     ]
    }
   ],
   "source": [
    "def inspect_tf_tcn(tf_model):\n",
    "    import tcn as tcn_pkg\n",
    "    from tensorflow.keras.layers import TimeDistributed, Conv1D, BatchNormalization\n",
    "\n",
    "    td = None\n",
    "    for l in tf_model.layers:\n",
    "        if isinstance(l, TimeDistributed) and isinstance(l.layer, tcn_pkg.TCN):\n",
    "            td = l; break\n",
    "    assert td is not None, \"No TimeDistributed(TCN) found.\"\n",
    "\n",
    "    tf_tcn = td.layer\n",
    "    convs = [m for m in tf_tcn.submodules if isinstance(m, Conv1D)]\n",
    "    bns   = [m for m in tf_tcn.submodules if isinstance(m, BatchNormalization)]\n",
    "\n",
    "    print(\"Convs:\")\n",
    "    for i, c in enumerate(convs):\n",
    "        ks = c.kernel_size[0] if isinstance(c.kernel_size, tuple) else c.kernel_size\n",
    "        print(f\"  {i:2d}: name={c.name}, kernel_size={ks}, filters={c.filters}\")\n",
    "    print(\"BNs:\")\n",
    "    for i, b in enumerate(bns):\n",
    "        print(f\"  {i:2d}: name={b.name}, epsilon={b.epsilon}, momentum={b.momentum}\")\n",
    "\n",
    "inspect_tf_tcn(tf_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
