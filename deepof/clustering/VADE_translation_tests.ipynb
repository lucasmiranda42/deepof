{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d41506e",
   "metadata": {},
   "source": [
    "# Recurrent block Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c137f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Bidirectional, GRU, LayerNormalization, Masking\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    LayerNormalization,\n",
    "    TimeDistributed,\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb64eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentBlockPT(nn.Module):\n",
    "    # __init__ remains correct.\n",
    "    def __init__(self, input_features: int, latent_dim: int, bidirectional_merge: str = \"concat\"):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        if bidirectional_merge != \"concat\":\n",
    "            warnings.warn(\"Bidirectional merge mode defaulting to 'concat'.\")\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_features, out_channels=2 * latent_dim, kernel_size=5, padding=\"same\", bias=False)\n",
    "        self.gru1 = nn.GRU(input_size=2 * latent_dim, hidden_size=2 * latent_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.norm1 = nn.LayerNorm(4 * latent_dim, eps=1e-3)\n",
    "        self.gru2 = nn.GRU(input_size=4 * latent_dim, hidden_size=latent_dim, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.norm2 = nn.LayerNorm(2 * latent_dim, eps=1e-3)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, T, N, _ = x.shape\n",
    "        \n",
    "        # Stage 1: Convolution\n",
    "        conv_in = x.reshape(B * T, N, -1).permute(0, 2, 1) # B*T as TF TimeDistributed analogon\n",
    "        conv_out = F.relu(self.conv1d(conv_in))\n",
    "        gru1_in = conv_out.permute(0, 2, 1) # Shape: (B*T, N, F_conv)\n",
    "        \n",
    "        # --- Prepare for packing ---\n",
    "        # Calculate mask from convolution output (TF GRU layer with masking analogon)\n",
    "        mask = (torch.abs(gru1_in).sum(dim=-1) > 0) # Shape: (B*T, N)\n",
    "        lengths = mask.sum(dim=1).cpu()\n",
    "        valid_indices = torch.where(lengths > 0)[0]\n",
    "        \n",
    "        # --- Stage 2: First GRU with packing ---\n",
    "        gru1_out_full = torch.zeros(B * T, N, 4 * self.latent_dim, device=x.device, dtype=x.dtype) # allocate data\n",
    "        if len(valid_indices) > 0:\n",
    "            valid_lengths = lengths[valid_indices]\n",
    "            # Apply GRU whilst ignoring masked data\n",
    "            packed_input = pack_padded_sequence(\n",
    "                gru1_in[valid_indices], valid_lengths, batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            packed_output, _ = self.gru1(packed_input)\n",
    "            unpacked_output, _ = pad_packed_sequence(\n",
    "                packed_output, batch_first=True, total_length=N\n",
    "            )\n",
    "            gru1_out_full[valid_indices] = unpacked_output\n",
    "\n",
    "        # Stage 3: First LayerNorm\n",
    "        norm1_in = gru1_out_full.reshape(B, T, N, -1)\n",
    "        norm1_out = self.norm1(norm1_in)\n",
    "\n",
    "        # --- Stage 4: Second GRU with packing ---\n",
    "        gru2_in = norm1_out.reshape(B * T, N, -1)\n",
    "        gru2_h_n_full = torch.zeros(2, B * T, self.latent_dim, device=x.device, dtype=x.dtype)\n",
    "        if len(valid_indices) > 0:\n",
    "            valid_lengths = lengths[valid_indices] # Use the same lengths\n",
    "            packed_input_2 = pack_padded_sequence(\n",
    "                gru2_in[valid_indices], valid_lengths, batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, h_n_2 = self.gru2(packed_input_2)\n",
    "            gru2_h_n_full[:, valid_indices, :] = h_n_2\n",
    "        gru2_final_state = gru2_h_n_full.permute(1, 0, 2).reshape(B * T, -1)\n",
    "\n",
    "        # Stage 5: Second LayerNorm\n",
    "        norm2_out = self.norm2(gru2_final_state)\n",
    "        \n",
    "        final_output = norm2_out.reshape(B, T, -1)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d022d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recurrent_block(\n",
    "    x: tf.Tensor, latent_dim: int, gru_unroll: bool, bidirectional_merge: str\n",
    "):\n",
    "    \"\"\"Build a recurrent embedding block, using a 1D convolution followed by two bidirectional GRU layers.\n",
    "\n",
    "    Args:\n",
    "        x (tf.Tensor): Input tensor.\n",
    "        latent_dim (int): Number of dimensions of the output tensor.\n",
    "        gru_unroll (bool): whether to unroll the GRU layers. Defaults to False.\n",
    "        bidirectional_merge (str): how to merge the forward and backward GRU layers. Defaults to \"concat\".\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.models.Model object with the specified architecture.\n",
    "\n",
    "    \"\"\"\n",
    "    encoder = TimeDistributed(\n",
    "        tf.keras.layers.Conv1D(\n",
    "            filters=2 * latent_dim,\n",
    "            kernel_size=5,\n",
    "            strides=1,  # Increased strides yield shorter sequences\n",
    "            padding=\"same\",\n",
    "            activation=\"relu\",\n",
    "            kernel_initializer=he_uniform(),\n",
    "            use_bias=False,\n",
    "        )\n",
    "    )(x)\n",
    "    encoder = tf.keras.layers.Masking(mask_value=0.0)(encoder)\n",
    "    encoder = TimeDistributed(\n",
    "        Bidirectional(\n",
    "            GRU(\n",
    "                2 * latent_dim,\n",
    "                activation=\"tanh\",\n",
    "                recurrent_activation=\"sigmoid\",\n",
    "                return_sequences=True,\n",
    "                unroll=gru_unroll,\n",
    "                use_bias=True,\n",
    "            ),\n",
    "            merge_mode=bidirectional_merge,\n",
    "        )\n",
    "    )(encoder)\n",
    "    encoder = LayerNormalization()(encoder)\n",
    "    encoder = TimeDistributed(\n",
    "        Bidirectional(\n",
    "            GRU(\n",
    "                latent_dim,\n",
    "                activation=\"tanh\",\n",
    "                recurrent_activation=\"sigmoid\",\n",
    "                return_sequences=False,\n",
    "                unroll=gru_unroll,\n",
    "                use_bias=True,\n",
    "            ),\n",
    "            merge_mode=bidirectional_merge,\n",
    "        )\n",
    "    )(encoder)\n",
    "    encoder = LayerNormalization()(encoder)\n",
    "    \n",
    "\n",
    "    return tf.keras.models.Model(x, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3224b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_recurrent_block_weights(tf_model, pt_model):\n",
    "    \"\"\"Transfers weights for the full recurrent block with GRU gate permutation.\"\"\"\n",
    "    conv_td, _, gru1_td, norm1, gru2_td, norm2 = tf_model.layers[1:]\n",
    "\n",
    "\n",
    "    def permute_gru_weights(keras_weights):\n",
    "        W_ih, W_hh, B = keras_weights\n",
    "        W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "        W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "        W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "        W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "        B_ih, B_hh = B\n",
    "        B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "        B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "        B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "        B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "        return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_td.layer.get_weights()[0]).permute(2, 1, 0)\n",
    "    \n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(gru1_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1); pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    \n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(gru1_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1); pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm1.get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm1.get_weights()[1])\n",
    "\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(gru2_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2); pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    \n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(gru2_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2); pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    \n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm2.get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm2.get_weights()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bae0d189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_final_forward_pass_with_masking (__main__.TestRecurrentBlockTranslation)\n",
      "Test the full block with the pack_padded_sequence masking method. ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.421s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow execution time: 0.07317900657653809\n",
      "Pytorch execution time: 0.024010419845581055\n",
      "✅ Full `RecurrentBlockPT` translation test PASSED!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestRecurrentBlockTranslation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up the full models and transfer weights.\"\"\"\n",
    "        tf.keras.backend.clear_session()\n",
    "        self.latent_dim = 8\n",
    "        self.input_shape = (10, 6, 3) # (T, N, F)\n",
    "        \n",
    "        self.tf_model = get_recurrent_block(\n",
    "            tf.keras.Input(shape=self.input_shape), self.latent_dim, False, \"concat\"\n",
    "        )\n",
    "        self.pt_model = RecurrentBlockPT(self.input_shape[-1], self.latent_dim)\n",
    "        self.pt_model.eval()\n",
    "\n",
    "        transfer_recurrent_block_weights(self.tf_model, self.pt_model)\n",
    "        \n",
    "        # Create test data WITH MASKING\n",
    "        self.np_input = np.random.rand(4, *self.input_shape).astype(np.float32)\n",
    "        # Mask the last two \"nodes\" for the first sample in the batch\n",
    "        self.np_input[0, :, :, :] = 0.0\n",
    "\n",
    "    def test_final_forward_pass_with_masking(self):\n",
    "        \"\"\"Test the full block with the pack_padded_sequence masking method.\"\"\"\n",
    "        tf_start=time.time()\n",
    "        tf_output = self.tf_model(self.np_input, training=False)\n",
    "        tf_end=time.time()\n",
    "        tf_output_np = tf_output.numpy()\n",
    "        \n",
    "\n",
    "        pt_input_tensor = torch.from_numpy(self.np_input)\n",
    "        with torch.no_grad():\n",
    "            pt_start = time.time()\n",
    "            pt_output = self.pt_model(pt_input_tensor)\n",
    "            pt_end=time.time()\n",
    "        pt_output_np = pt_output.cpu().numpy()\n",
    "        print(\"Tensorflow execution time: \" + str(tf_end-tf_start))\n",
    "        print(\"Pytorch execution time: \" + str(pt_end-pt_start))\n",
    "\n",
    "        np.testing.assert_allclose(tf_output_np, pt_output_np, rtol=1e-5, atol=1e-5)\n",
    "        print(\"✅ Full `RecurrentBlockPT` translation test PASSED!\")\n",
    "        \n",
    "#To run in Jupyter:\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestRecurrentBlockTranslation)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75eadde",
   "metadata": {},
   "source": [
    "# ProbabilisticDecoder Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6046e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import layers as tfpl\n",
    "from tensorflow_probability import distributions as tfd\n",
    "from tensorflow_probability.python.bijectors import scale as tfb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Distribution, TransformedDistribution\n",
    "from torch.distributions.transforms import AffineTransform\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8e56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbabilisticDecoder(tf.keras.layers.Layer):\n",
    "    \"\"\"Map the reconstruction output of a given decoder to a multivariate normal distribution.\"\"\"\n",
    "\n",
    "    def __init__(self, output_data_shape, **kwargs):\n",
    "        \"\"\"Initialize the probabilistic decoder.\"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.time_distributer = tf.keras.layers.Dense(\n",
    "            tfpl.IndependentNormal.params_size(output_data_shape) // 2\n",
    "        )\n",
    "        self.probabilistic_decoding = tfpl.DistributionLambda(\n",
    "            make_distribution_fn=lambda decoded: tfd.Masked(\n",
    "                tfd.Independent(\n",
    "                    tfd.Normal(\n",
    "                        loc=decoded[0], scale=tf.ones_like(decoded[0]),\n",
    "                        validate_args=False, allow_nan_stats=False,\n",
    "                    ),\n",
    "                    reinterpreted_batch_ndims=1,\n",
    "                ),\n",
    "                validity_mask=decoded[1],\n",
    "            ),\n",
    "            convert_to_tensor_fn=\"mean\",\n",
    "        )\n",
    "        self.scaled_probabilistic_decoding = tfpl.DistributionLambda(\n",
    "            make_distribution_fn=lambda decoded: tfd.Masked(\n",
    "                tfd.TransformedDistribution(\n",
    "                    decoded[0], # base distribution\n",
    "                    tfb.Scale(tf.cast(tf.expand_dims(decoded[1], axis=2), tf.float32)), # bijector\n",
    "                    name=\"vae_reconstruction\",\n",
    "                ),\n",
    "                validity_mask=decoded[1],\n",
    "            ),\n",
    "            convert_to_tensor_fn=\"mean\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        hidden, validity_mask = inputs\n",
    "        loc_params = tf.keras.layers.TimeDistributed(self.time_distributer)(hidden)\n",
    "        prob_decoded = self.probabilistic_decoding([loc_params, validity_mask])\n",
    "        scaled_prob_decoded = self.scaled_probabilistic_decoding(\n",
    "            [prob_decoded, validity_mask]\n",
    "        )\n",
    "        return scaled_prob_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bf4048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: Create a subclass that knows how to compute the mean for an Affine transform.\n",
    "class AffineTransformedDistribution(TransformedDistribution):\n",
    "    \"\"\"\n",
    "    A specific TransformedDistribution for Affine transforms that implements .mean.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_distribution, transform):\n",
    "        super().__init__(base_distribution, transform)\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        \"\"\"\n",
    "        Computes the mean of the transformed distribution.\n",
    "        E[loc + scale * X] = loc + scale * E[X]\n",
    "        \"\"\"\n",
    "        # The transform itself is callable and applies the affine transformation.\n",
    "        return self.transforms[0](self.base_dist.mean)\n",
    "\n",
    "class ProbabilisticDecoderPT(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch translation of the ProbabilisticDecoder, including scaling transform.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim: int, data_dim: int):\n",
    "        super().__init__()\n",
    "        self.loc_projection = nn.Linear(in_features=hidden_dim, out_features=data_dim)\n",
    "\n",
    "    def forward(self, hidden: torch.Tensor, validity_mask: torch.Tensor) -> AffineTransformedDistribution:\n",
    "        B, T, D = hidden.shape\n",
    "        # Reconstruct mean locations\n",
    "        loc_params = self.loc_projection(hidden.view(B * T, -1)).reshape(B, T, -1)\n",
    "\n",
    "        # Define Gaussian distributions with means (init: var=1)\n",
    "        scale_params = torch.ones_like(loc_params)\n",
    "        base_dist = torch.distributions.Normal(loc=loc_params, scale=scale_params)\n",
    "\n",
    "        # Multivariate Gaussian distributions for feature vector\n",
    "        independent_dist = torch.distributions.Independent(base_dist, 1)\n",
    "        \n",
    "        # Define transform to map masked values to 0 (y = 0 + 0 * x) and unmasked-values to themselves (y = 0 + 1.0 * x)\n",
    "        scale_transform = validity_mask.unsqueeze(-1).to(hidden.dtype)\n",
    "        transform = AffineTransform(loc=0, scale=scale_transform)\n",
    "        \n",
    "        # Returns a custom class instead of the generic one as \"mean\" functionality otherwise would be missing.\n",
    "        final_dist = AffineTransformedDistribution(independent_dist, transform)\n",
    "        return final_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "895ba3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_probabilistic_decoder_weights(tf_model, pt_model):\n",
    "    dense_layer = tf_model.time_distributer\n",
    "    W, b = dense_layer.get_weights()\n",
    "    pt_model.loc_projection.weight.data = torch.from_numpy(W.T)\n",
    "    pt_model.loc_projection.bias.data = torch.from_numpy(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95a69952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_final_forward_pass (__main__.TestProbabilisticDecoderFinal)\n",
      "Tests that the .mean() of the final transformed distributions are identical. ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Weights transferred successfully for final test.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.437s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow execution time: 0.03962516784667969\n",
      "Pytorch execution time: 0.2196040153503418\n",
      "\n",
      "✅ `ProbabilisticDecoderPT` FINAL translation test PASSED!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestProbabilisticDecoderFinal(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        tf.keras.backend.clear_session()\n",
    "        self.batch_size, self.time_steps, self.hidden_dim, self.data_dim = 4, 10, 32, 5\n",
    "\n",
    "        # Create TF model\n",
    "        self.tf_model = ProbabilisticDecoder(output_data_shape=(self.data_dim,))\n",
    "        \n",
    "        # Create PyTorch model\n",
    "        self.pt_model = ProbabilisticDecoderPT(hidden_dim=self.hidden_dim, data_dim=self.data_dim)\n",
    "        self.pt_model.eval()\n",
    "\n",
    "        # --- THE FIX: Zero out the input tensor based on the mask ---\n",
    "        np_hidden_original = np.random.rand(self.batch_size, self.time_steps, self.hidden_dim).astype(np.float32)\n",
    "        \n",
    "        # Create a float mask (1.0/0.0)\n",
    "        self.np_float_mask = np.ones((self.batch_size, self.time_steps), dtype=np.float32)\n",
    "        self.np_float_mask[0, -1] = 0.0 # Mask last step of first item\n",
    "        self.np_float_mask[1, 5:] = 0.0 # Mask multiple steps of second item\n",
    "\n",
    "        # Apply the mask to the input data itself before feeding it to the models\n",
    "        self.np_hidden_masked = np_hidden_original * self.np_float_mask[:, :, np.newaxis]\n",
    "\n",
    "        # TF needs a boolean mask for tfd.Masked\n",
    "        self.np_bool_mask = self.np_float_mask.astype(bool)\n",
    "\n",
    "        # Build the TF model by calling it once with the masked input\n",
    "        self.tf_model([tf.constant(self.np_hidden_masked), tf.constant(self.np_bool_mask)])\n",
    "        \n",
    "        # Transfer weights\n",
    "        transfer_probabilistic_decoder_weights(self.tf_model, self.pt_model)\n",
    "        print(\"✅ Weights transferred successfully for final test.\")\n",
    "\n",
    "    def test_final_forward_pass(self):\n",
    "        \"\"\"Tests that the .mean() of the final transformed distributions are identical.\"\"\"\n",
    "        # --- TensorFlow ---\n",
    "        # Pass the zeroed-out hidden data and the boolean mask\n",
    "        tf_start=time.time()\n",
    "        tf_dist = self.tf_model([self.np_hidden_masked, self.np_bool_mask])\n",
    "        tf_mean_np = tf_dist.mean().numpy()\n",
    "        tf_end=time.time()\n",
    "\n",
    "\n",
    "        # --- PyTorch ---\n",
    "        pt_hidden_tensor = torch.from_numpy(self.np_hidden_masked)\n",
    "        pt_mask_tensor = torch.from_numpy(self.np_float_mask)\n",
    "        with torch.no_grad():\n",
    "            pt_start=time.time()\n",
    "            pt_dist = self.pt_model(pt_hidden_tensor, pt_mask_tensor)\n",
    "        pt_mean_np = pt_dist.mean.cpu().numpy()\n",
    "        pt_end=time.time()\n",
    "\n",
    "        # --- Verification ---\n",
    "        np.testing.assert_allclose(tf_mean_np, pt_mean_np, rtol=1e-6, atol=1e-6)\n",
    "        \n",
    "        # Check a masked-out part is zero\n",
    "        self.assertTrue(np.all(pt_mean_np[0, -1, :] == 0.0))\n",
    "        # Check an un-masked part is not zero\n",
    "        self.assertFalse(np.all(pt_mean_np[0, 0, :] == 0.0))\n",
    "\n",
    "        print(\"Tensorflow execution time: \" + str(tf_end-tf_start))\n",
    "        print(\"Pytorch execution time: \" + str(pt_end-pt_start))\n",
    "        \n",
    "        print(\"\\n✅ `ProbabilisticDecoderPT` FINAL translation test PASSED!\")\n",
    "\n",
    "# To run in Jupyter or a script:\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestProbabilisticDecoderFinal)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250a323",
   "metadata": {},
   "source": [
    "# Recurrent Decoder Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27becafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tcn\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from spektral.layers import CensNetConv\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    LayerNormalization,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import time\n",
    "import deepof.model_utils\n",
    "import deepof.clustering.model_utils_new\n",
    "from deepof.clustering.censNetConv_pt import CensNetConvPT\n",
    "import deepof.utils\n",
    "from deepof.data_loading import get_dt\n",
    "import warnings\n",
    "from deepof.clustering.model_utils_new import ProbabilisticDecoderPT\n",
    "from torch.distributions import Distribution, TransformedDistribution\n",
    "from torch.distributions.transforms import AffineTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "478bf738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recurrent_decoder(\n",
    "    input_shape: tuple,\n",
    "    latent_dim: int,\n",
    "    gru_unroll: bool = False,\n",
    "    bidirectional_merge: str = \"concat\",\n",
    "):\n",
    "    \"\"\"Return a recurrent neural decoder.\n",
    "\n",
    "    Builds a deep neural network capable of decoding the structured latent space generated by one of the compatible\n",
    "    classes into a sequence of motion tracking instances, either reconstructing the original\n",
    "    input, or generating new data from given clusters.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): shape of the input data\n",
    "        latent_dim (int): dimensionality of the latent space\n",
    "        gru_unroll (bool): whether to unroll the GRU layers. Defaults to False.\n",
    "        bidirectional_merge (str): how to merge the forward and backward GRU layers. Defaults to \"concat\".\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: a keras model that can be trained to decode the latent space into a series of motion tracking\n",
    "        sequences.\n",
    "\n",
    "    \"\"\"\n",
    "    # Define and instantiate generator\n",
    "    g = Input(shape=latent_dim)  # Decoder input, shaped as the latent space\n",
    "    x = Input(shape=input_shape)  # Encoder input, used to generate an output mask\n",
    "    validity_mask = tf.math.logical_not(tf.reduce_all(x == 0.0, axis=2))\n",
    "\n",
    "    generator = RepeatVector(input_shape[0])(g)\n",
    "    generator = Bidirectional(\n",
    "        GRU(\n",
    "            latent_dim,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            return_sequences=True,\n",
    "            unroll=gru_unroll,\n",
    "            use_bias=True,\n",
    "        ),\n",
    "        merge_mode=bidirectional_merge,\n",
    "    )(generator, mask=validity_mask)\n",
    "    generator = LayerNormalization()(generator)\n",
    "    generator = Bidirectional(\n",
    "        GRU(\n",
    "            2 * latent_dim,\n",
    "            activation=\"tanh\",\n",
    "            recurrent_activation=\"sigmoid\",\n",
    "            return_sequences=True,\n",
    "            unroll=gru_unroll,\n",
    "            use_bias=True,\n",
    "        ),\n",
    "        merge_mode=bidirectional_merge,\n",
    "    )(generator)\n",
    "    generator = LayerNormalization()(generator)\n",
    "    generator = tf.keras.layers.Conv1D(\n",
    "        filters=2 * latent_dim,\n",
    "        kernel_size=5,\n",
    "        strides=1,\n",
    "        padding=\"same\",\n",
    "        activation=\"relu\",\n",
    "        kernel_initializer=he_uniform(),\n",
    "        use_bias=False,\n",
    "    )(generator)\n",
    "    generator = LayerNormalization()(generator)\n",
    "\n",
    "    x_decoded = deepof.model_utils.ProbabilisticDecoder(input_shape)(\n",
    "        [generator, validity_mask]\n",
    "    )\n",
    "\n",
    "    return Model([g, x], x_decoded, name=\"recurrent_decoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f31c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentDecoderPT(nn.Module):\n",
    "    \"\"\"\n",
    "    A full PyTorch implementation of the recurrent decoder.\n",
    "    \"\"\"\n",
    "    def __init__(self, output_shape: tuple, latent_dim: int, bidirectional_merge: str = \"concat\"):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.output_shape = output_shape\n",
    "        if bidirectional_merge != \"concat\":\n",
    "            warnings.warn(\"Bidirectional merge mode is fixed to 'concat' to correspond with original TensorFlow implementation.\")\n",
    "\n",
    "        # First Bi-GRU layer\n",
    "        self.gru1 = nn.GRU(\n",
    "            input_size=latent_dim,\n",
    "            hidden_size=latent_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(2 * latent_dim, eps=1e-3)\n",
    "\n",
    "        # Second Bi-GRU layer\n",
    "        self.gru2 = nn.GRU(\n",
    "            input_size=2 * latent_dim, # Input from first Bi-GRU\n",
    "            hidden_size=2 * latent_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(4 * latent_dim, eps=1e-3) # Output of second Bi-GRU is 2 * (2*latent_dim)\n",
    "\n",
    "        # Convolutional Layer\n",
    "        self.conv1d = nn.Conv1d(\n",
    "            in_channels=4 * latent_dim, # Input from second norm layer\n",
    "            out_channels=2 * latent_dim,\n",
    "            kernel_size=5,\n",
    "            padding=\"same\",\n",
    "            bias=False\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(2 * latent_dim, eps=1e-3) # Output of Conv1D\n",
    "\n",
    "        # Probabilistic Layer \n",
    "        self.prob_decoder = ProbabilisticDecoderPT(\n",
    "            hidden_dim=2 * latent_dim, # Input from third norm layer\n",
    "            data_dim=output_shape[1]\n",
    "        )\n",
    "\n",
    "    def forward(self, g: torch.Tensor, x: torch.Tensor) -> TransformedDistribution:\n",
    "        B, T, _ = x.shape\n",
    "\n",
    "        # 1. Create the validity mask and sequence lengths from input 'x'\n",
    "        validity_mask = ~torch.all(x == 0.0, dim=2)\n",
    "        lengths = validity_mask.sum(dim=1).cpu().to(torch.int64)\n",
    "        valid_indices = torch.where(lengths > 0)[0]\n",
    "\n",
    "        # 2. Emulate RepeatVector\n",
    "        generator = g.unsqueeze(1).expand(-1, T, -1)\n",
    "\n",
    "        # 3. First Bi-GRU with masking\n",
    "        gru1_out_full = torch.zeros(B, T, 2 * self.latent_dim, device=g.device, dtype=g.dtype)\n",
    "        if len(valid_indices) > 0:\n",
    "            # Apply GRU whilst ignoring masked data\n",
    "            packed_input_1 = pack_padded_sequence(\n",
    "                generator[valid_indices], lengths[valid_indices], batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            packed_output_1, _ = self.gru1(packed_input_1)\n",
    "            unpacked_output_1, _ = pad_packed_sequence(\n",
    "                packed_output_1, batch_first=True, total_length=T\n",
    "            )\n",
    "            gru1_out_full[valid_indices] = unpacked_output_1\n",
    "        norm1_out = self.norm1(gru1_out_full)\n",
    "\n",
    "        # 4. Second Bi-GRU with masking (reusing the same mask/lengths)\n",
    "        gru2_out_full = torch.zeros(B, T, 4 * self.latent_dim, device=g.device, dtype=g.dtype)\n",
    "        if len(valid_indices) > 0:\n",
    "            packed_input_2 = pack_padded_sequence(\n",
    "                norm1_out[valid_indices], lengths[valid_indices], batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            packed_output_2, _ = self.gru2(packed_input_2)\n",
    "            unpacked_output_2, _ = pad_packed_sequence(\n",
    "                packed_output_2, batch_first=True, total_length=T\n",
    "            )\n",
    "            gru2_out_full[valid_indices] = unpacked_output_2\n",
    "        norm2_out = self.norm2(gru2_out_full)\n",
    "\n",
    "        # 5. Convolution Block\n",
    "        # Conv1d expects (B, C, T), so we permute\n",
    "        conv_in = norm2_out.permute(0, 2, 1)\n",
    "        conv_out = F.relu(self.conv1d(conv_in))\n",
    "        # Permute back to (B, T, C) for LayerNorm\n",
    "        norm3_in = conv_out.permute(0, 2, 1)\n",
    "        norm3_out = self.norm3(norm3_in)\n",
    "\n",
    "        # 6. Final Probabilistic Decoder\n",
    "        final_dist = self.prob_decoder(norm3_out, validity_mask)\n",
    "\n",
    "        return final_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8f44e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function from the provided example to handle gate order differences\n",
    "def permute_gru_weights(keras_weights):\n",
    "    \"\"\"Permutes GRU weights from Keras (z, r, n) to PyTorch (r, z, n) format.\"\"\"\n",
    "    W_ih, W_hh, B = keras_weights\n",
    "    # Keras gate order: z, r, n (update, reset, new/candidate)\n",
    "    W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "    W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "\n",
    "    # PyTorch gate order: r, z, n (reset, update, new/candidate)\n",
    "    W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "    W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "\n",
    "    # Keras has two bias vectors (input-hidden and recurrent), which are concatenated in B\n",
    "    B_ih, B_hh = B\n",
    "    B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "    B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "\n",
    "    B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "    B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "\n",
    "    return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "    \n",
    "def transfer_recurrent_decoder_weights(tf_model, pt_model):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full recurrent decoder model.\n",
    "    \"\"\"\n",
    "    # Find layers by type to avoid index issues\n",
    "    bidi_layers = [l for l in tf_model.layers if isinstance(l, Bidirectional)]\n",
    "    norm_layers = [l for l in tf_model.layers if isinstance(l, LayerNormalization)]\n",
    "    conv_layers = [l for l in tf_model.layers if isinstance(l, tf.keras.layers.Conv1D)]\n",
    "    prob_dec_layer = next(l for l in tf_model.layers if isinstance(l, deepof.model_utils.ProbabilisticDecoder))\n",
    "\n",
    "    # --- GRU 1 and Norm 1 ---\n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(bidi_layers[0].forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1)\n",
    "    pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(bidi_layers[0].backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1)\n",
    "    pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm_layers[0].get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm_layers[0].get_weights()[1])\n",
    "\n",
    "    # --- GRU 2 and Norm 2 ---\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(bidi_layers[1].forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2)\n",
    "    pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(bidi_layers[1].backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2)\n",
    "    pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm_layers[1].get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm_layers[1].get_weights()[1])\n",
    "\n",
    "    # --- Conv1D and Norm 3 ---\n",
    "    # TF Conv1D weights: (kernel_w, kernel_h, in_c, out_c) -> (5, 1, 4*ld, 2*ld)\n",
    "    # PT Conv1d weights: (out_c, in_c, kernel_w)\n",
    "    conv_weights_tf = conv_layers[0].get_weights()[0]\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_weights_tf).squeeze(1).permute(2, 1, 0)\n",
    "    pt_model.norm3.weight.data = torch.from_numpy(norm_layers[2].get_weights()[0]); pt_model.norm3.bias.data = torch.from_numpy(norm_layers[2].get_weights()[1])\n",
    "\n",
    "    # --- Probabilistic Decoder ---\n",
    "    # TF Dense weights: (in_features, out_features)\n",
    "    # PT Linear weights: (out_features, in_features)\n",
    "    prob_dec_weights, prob_dec_bias = prob_dec_layer.time_distributer.get_weights()\n",
    "    pt_model.prob_decoder.loc_projection.weight.data = torch.from_numpy(prob_dec_weights.T)\n",
    "    pt_model.prob_decoder.loc_projection.bias.data = torch.from_numpy(prob_dec_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e2439d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_full_forward_pass_with_masking (__main__.TestRecurrentDecoderTranslation)\n",
      "Test the full decoder translation against the original TF model. ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.539s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow execution time: 0.11825919151306152\n",
      "Pytorch execution time: 0.022947072982788086\n",
      "✅ Full `RecurrentDecoderPT` translation test PASSED!\n"
     ]
    }
   ],
   "source": [
    "class TestRecurrentDecoderTranslation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up the full models and transfer weights.\"\"\"\n",
    "        tf.keras.backend.clear_session()\n",
    "        # Make epsilon consistent between TF and PT LayerNorm\n",
    "        tf.keras.backend.set_epsilon(1e-3)\n",
    "\n",
    "        self.latent_dim = 16\n",
    "        self.input_shape = (15, 8)  # (T, Features)\n",
    "        self.batch_size = 4\n",
    "\n",
    "        # Instantiate the original full TensorFlow model\n",
    "        self.tf_model = get_recurrent_decoder(\n",
    "            input_shape=self.input_shape,\n",
    "            latent_dim=self.latent_dim,\n",
    "            bidirectional_merge=\"concat\"\n",
    "        )\n",
    "\n",
    "        # Instantiate the full PyTorch model\n",
    "        self.pt_model = RecurrentDecoderPT(\n",
    "            output_shape=self.input_shape,\n",
    "            latent_dim=self.latent_dim\n",
    "        )\n",
    "        self.pt_model.eval()\n",
    "\n",
    "        # Transfer all weights\n",
    "        transfer_recurrent_decoder_weights(self.tf_model, self.pt_model)\n",
    "\n",
    "        # Create test data WITH MASKING\n",
    "        self.np_latent_input = np.random.rand(self.batch_size, self.latent_dim).astype(np.float32)\n",
    "        self.np_sequence_input = np.random.rand(self.batch_size, *self.input_shape).astype(np.float32)\n",
    "        # Mask some steps for sample 0\n",
    "        self.np_sequence_input[0, -3:, :] = 0.0\n",
    "        # Mask all steps for sample 1\n",
    "        self.np_sequence_input[1, :, :] = 0.0\n",
    "\n",
    "    def test_full_forward_pass_with_masking(self):\n",
    "        \"\"\"Test the full decoder translation against the original TF model.\"\"\"\n",
    "        # TensorFlow execution\n",
    "        tf_start = time.time()\n",
    "        tf_output_dist = self.tf_model([self.np_latent_input, self.np_sequence_input], training=False)\n",
    "        # CORRECTED LINE: Call .mean() on the distribution object first\n",
    "        tf_output_np = tf_output_dist.mean().numpy()\n",
    "        tf_end = time.time()\n",
    "\n",
    "\n",
    "        # PyTorch execution\n",
    "        pt_latent_tensor = torch.from_numpy(self.np_latent_input)\n",
    "        pt_sequence_tensor = torch.from_numpy(self.np_sequence_input)\n",
    "        with torch.no_grad():\n",
    "            pt_start = time.time()\n",
    "            pt_dist = self.pt_model(pt_latent_tensor, pt_sequence_tensor)\n",
    "            # Use the .mean property to get the tensor output\n",
    "            pt_output = pt_dist.mean\n",
    "        pt_output_np = pt_output.cpu().numpy()\n",
    "        pt_end = time.time()\n",
    "\n",
    "        print(\"Tensorflow execution time: \" + str(tf_end-tf_start))\n",
    "        print(\"Pytorch execution time: \" + str(pt_end-pt_start))\n",
    "\n",
    "        # Compare the final tensor outputs\n",
    "        np.testing.assert_allclose(tf_output_np, pt_output_np, rtol=1e-5, atol=1e-4)\n",
    "        print(\"✅ Full `RecurrentDecoderPT` translation test PASSED!\")\n",
    "\n",
    "# To run in a Python script or Jupyter notebook:\n",
    "if __name__ == '__main__':\n",
    "    # Add deepof and other necessary imports from the original problem description\n",
    "    # Then run the test suite\n",
    "    runner = unittest.TextTestRunner(verbosity=2)\n",
    "    suite = unittest.TestLoader().loadTestsFromTestCase(TestRecurrentDecoderTranslation)\n",
    "    runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a263a9d1",
   "metadata": {},
   "source": [
    "# Recurrent Encoder Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9744cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tcn\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from spektral.layers import CensNetConv\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    LayerNormalization,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    ")\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import time\n",
    "import deepof.model_utils\n",
    "import deepof.clustering.model_utils_new\n",
    "from deepof.clustering.censNetConv_pt import CensNetConvPT\n",
    "import deepof.utils\n",
    "from deepof.data_loading import get_dt\n",
    "import warnings\n",
    "from deepof.clustering.model_utils_new import ProbabilisticDecoderPT, RecurrentBlockPT\n",
    "from torch.distributions import Distribution, TransformedDistribution\n",
    "from torch.distributions.transforms import AffineTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e9f456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recurrent_encoder(\n",
    "    input_shape: tuple,\n",
    "    edge_feature_shape: tuple,\n",
    "    adjacency_matrix: np.ndarray,\n",
    "    latent_dim: int,\n",
    "    use_gnn: bool = True,\n",
    "    gru_unroll: bool = False,\n",
    "    bidirectional_merge: str = \"concat\",\n",
    "    interaction_regularization: float = 0.0,\n",
    "):\n",
    "    \"\"\"Return a deep recurrent neural encoder.\n",
    "\n",
    "     Builds a neural network capable of encoding the motion tracking instances into a vector ready to be fed to\n",
    "    one of the provided structured latent spaces.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): shape of the node features for the input data. Should be time x nodes x features.\n",
    "        edge_feature_shape (tuple): shape of the adjacency matrix to use in the graph attention layers. Should be time x edges x features.\n",
    "        adjacency_matrix (np.ndarray): adjacency matrix for the mice connectivity graph. Shape should be nodes x nodes.\n",
    "        latent_dim (int): dimension of the latent space.\n",
    "        use_gnn (bool): If True, the encoder uses a graph representation of the input, with coordinates and speeds as node attributes, and distances as edge attributes. If False, a regular 3D tensor is used as input.\n",
    "        gru_unroll (bool): whether to unroll the GRU layers. Defaults to False.\n",
    "        bidirectional_merge (str): how to merge the forward and backward GRU layers. Defaults to \"concat\".\n",
    "        interaction_regularization (float): Regularization parameter for the interaction features.\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: a keras model that can be trained to encode motion tracking instances into a vector.\n",
    "\n",
    "    \"\"\"\n",
    "    # Define feature and adjacency inputs\n",
    "    x = Input(shape=input_shape)\n",
    "    a = Input(shape=edge_feature_shape)\n",
    "\n",
    "    if use_gnn:\n",
    "        x_reshaped = tf.transpose(\n",
    "            tf.reshape(\n",
    "                tf.transpose(x),\n",
    "                [\n",
    "                    -1,\n",
    "                    adjacency_matrix.shape[-1],\n",
    "                    x.shape[1],\n",
    "                    input_shape[-1] // adjacency_matrix.shape[-1],\n",
    "                ][::-1],\n",
    "            )\n",
    "        )\n",
    "        a_reshaped = tf.transpose(\n",
    "            tf.reshape(\n",
    "                tf.transpose(a),\n",
    "                [\n",
    "                    -1,\n",
    "                    edge_feature_shape[-1],\n",
    "                    a.shape[1],\n",
    "                    1,\n",
    "                ][::-1],\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    else:\n",
    "        x_flat = tf.reshape(x, [-1, input_shape[0], input_shape[1] * input_shape[2]])\n",
    "        x_reshaped = tf.expand_dims(x_flat, axis=1)\n",
    "\n",
    "    # Instantiate temporal RNN block\n",
    "    encoder = deepof.clustering.model_utils_new.get_recurrent_block(\n",
    "        x_reshaped, latent_dim, gru_unroll, bidirectional_merge\n",
    "    )(x_reshaped)\n",
    "\n",
    "\n",
    "    # Instantiate spatial graph block\n",
    "    if use_gnn:\n",
    "\n",
    "        # Embed edge features too\n",
    "        a_encoder = deepof.clustering.model_utils_new.get_recurrent_block(\n",
    "            a_reshaped, latent_dim, gru_unroll, bidirectional_merge\n",
    "        )(a_reshaped)\n",
    "    \n",
    "        spatial_block = CensNetConv(\n",
    "            node_channels=latent_dim,\n",
    "            edge_channels=latent_dim,\n",
    "            activation=\"relu\",\n",
    "            node_regularizer=tf.keras.regularizers.l1(interaction_regularization),\n",
    "        )\n",
    "\n",
    "        # Process adjacency matrix\n",
    "        laplacian, edge_laplacian, incidence = spatial_block.preprocess(\n",
    "            adjacency_matrix\n",
    "        )\n",
    "\n",
    "        # Get and concatenate node and edge embeddings\n",
    "        x_nodes, x_edges = spatial_block(\n",
    "            [encoder, (laplacian, edge_laplacian, incidence), a_encoder], mask=None\n",
    "        )\n",
    "        \n",
    "\n",
    "        x_nodes = tf.reshape(\n",
    "            x_nodes,\n",
    "            [-1, adjacency_matrix.shape[-1] * latent_dim],\n",
    "        )\n",
    "\n",
    "        x_edges = tf.reshape(\n",
    "            x_edges,\n",
    "            [-1, edge_feature_shape[-1] * latent_dim],\n",
    "        )\n",
    "\n",
    "        encoder = tf.concat([x_nodes, x_edges], axis=-1)\n",
    "\n",
    "    else:\n",
    "        encoder = tf.squeeze(encoder, axis=1)\n",
    "\n",
    "    encoder_output = tf.keras.layers.Dense(latent_dim, kernel_initializer=\"he_uniform\")(\n",
    "        encoder\n",
    "    )\n",
    "    \n",
    "    return Model([x, a], encoder_output, name=\"recurrent_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f588403",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentEncoderPT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: tuple,\n",
    "        edge_feature_shape: tuple,\n",
    "        adjacency_matrix: np.ndarray,\n",
    "        latent_dim: int,\n",
    "        use_gnn: bool = True,\n",
    "        interaction_regularization: float = 0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_gnn = use_gnn\n",
    "        self.num_nodes = adjacency_matrix.shape[0]\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        if self.use_gnn:\n",
    "            # Node path initialization \n",
    "            node_feat_per_animal = input_shape[-1] // self.num_nodes\n",
    "            self.node_recurrent_block = RecurrentBlockPT(\n",
    "                input_features=node_feat_per_animal, latent_dim=latent_dim\n",
    "            )\n",
    "\n",
    "            # Edge path initialization \n",
    "            self.edge_recurrent_block = RecurrentBlockPT(\n",
    "                input_features=1, latent_dim=latent_dim\n",
    "            )\n",
    "\n",
    "            self.spatial_gnn_block = CensNetConvPT(\n",
    "                node_channels=latent_dim,\n",
    "                edge_channels=latent_dim,\n",
    "            )\n",
    "            lap, edge_lap, inc = self.spatial_gnn_block.preprocess(torch.tensor(adjacency_matrix))\n",
    "            self.register_buffer(\"laplacian\", lap.float())\n",
    "            self.register_buffer(\"edge_laplacian\", edge_lap.float())\n",
    "            self.register_buffer(\"incidence\", inc.float())\n",
    "            \n",
    "            self.num_edges = edge_feature_shape[1]\n",
    "            final_dense_in = (self.num_nodes * latent_dim) + (self.num_edges * latent_dim)\n",
    "            self.final_dense = nn.Linear(final_dense_in, latent_dim)\n",
    "\n",
    "        else: # Non-GNN path \n",
    "            in_features = input_shape[1] * input_shape[2]\n",
    "            self.recurrent_block = RecurrentBlockPT(\n",
    "                input_features=in_features, latent_dim=latent_dim\n",
    "            )\n",
    "            self.final_dense = nn.Linear(latent_dim, latent_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, a: torch.Tensor) -> torch.Tensor:\n",
    "        B, T, N_nodes_total, F_nodes_total = x.shape\n",
    "        _, _, E_edges_total, F_edges_total = a.shape\n",
    "\n",
    "        if self.use_gnn:\n",
    "            # --- Attempt to replicate the exact TensorFlow reshape logic ---\n",
    "            \n",
    "            # 1. Node Path\n",
    "            F_per_node = F_nodes_total // self.num_nodes\n",
    "            x_t = x.permute(3, 2, 1, 0)\n",
    "            target_shape_x = (F_per_node, T, self.num_nodes, -1)\n",
    "            x_reshaped_t = x_t.reshape(target_shape_x)\n",
    "            x_reshaped = x_reshaped_t.permute(3, 2, 1, 0)\n",
    "            \n",
    "            # 2. Edge Path\n",
    "            a_t = a.permute(3, 2, 1, 0)\n",
    "            target_shape_a = (1, T, F_edges_total, -1)\n",
    "            a_reshaped_t = a_t.reshape(target_shape_a)\n",
    "            a_reshaped = a_reshaped_t.permute(3, 2, 1, 0)\n",
    "\n",
    "            # 3. Pass through Recurrent Blocks\n",
    "            node_output = self.node_recurrent_block(x_reshaped)           \n",
    "            edge_output = self.edge_recurrent_block(a_reshaped)\n",
    "            \n",
    "            # 4. GNN and Final Layers\n",
    "            adj_tuple = (self.laplacian, self.edge_laplacian, self.incidence)\n",
    "            x_nodes, x_edges = self.spatial_gnn_block(\n",
    "                [node_output, adj_tuple, edge_output]\n",
    "            )\n",
    "            x_nodes=F.relu(x_nodes)\n",
    "            x_edges=F.relu(x_edges)\n",
    "            \n",
    "            b_prime = x_nodes.shape[0]\n",
    "            x_nodes_flat = x_nodes.view(b_prime, -1)\n",
    "            x_edges_flat = x_edges.view(b_prime, -1)\n",
    "            encoder = torch.cat([x_nodes_flat, x_edges_flat], dim=-1)\n",
    "            \n",
    "\n",
    "        else: # Non-GNN path \n",
    "            x_reshaped = x.view(B, T, N_nodes_total * F_nodes_total).unsqueeze(1)\n",
    "            encoder = self.recurrent_block(x_reshaped).squeeze(1)\n",
    "\n",
    "        return self.final_dense(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ad0fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_recurrent_block_weights(tf_model, pt_model):\n",
    "    \"\"\"Transfers weights for the full recurrent block with GRU gate permutation.\"\"\"\n",
    "    conv_td, _, gru1_td, norm1, gru2_td, norm2 = tf_model.layers[1:]\n",
    "\n",
    "\n",
    "    def permute_gru_weights(keras_weights):\n",
    "        W_ih, W_hh, B = keras_weights\n",
    "        W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "        W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "        W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "        W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "        B_ih, B_hh = B\n",
    "        B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "        B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "        B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "        B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "        return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_td.layer.get_weights()[0]).permute(2, 1, 0)\n",
    "    \n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(gru1_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1); pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    \n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(gru1_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1); pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm1.get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm1.get_weights()[1])\n",
    "\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(gru2_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2); pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    \n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(gru2_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2); pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    \n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm2.get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm2.get_weights()[1])\n",
    "\n",
    "    \n",
    "def transfer_censnet_weights(tf_layer, pt_layer):\n",
    "    \"\"\"\n",
    "    Transfers all six weights from a Spektral CensNetConv layer to the\n",
    "    corresponding CensNetConvPT layer.\n",
    "    \"\"\"\n",
    "    # Get all weights from the TensorFlow layer. The order is determined by\n",
    "    # the layer's build order in Spektral's source code.\n",
    "    tf_weights = tf_layer.get_weights()\n",
    "\n",
    "    # Unpack all six weights.\n",
    "    # Order: kernel_node, bias_node, kernel_edge, bias_edge, projector_node, projector_edge\n",
    "    kn_tf, bn_tf, ke_tf, be_tf, pn_tf, pe_tf = tf_weights\n",
    "\n",
    "    # 1. & 2. Transfer Node Kernel and Bias\n",
    "    # Keras Dense kernel is (in_features, out_features)\n",
    "    pt_layer.node_kernel.data = torch.from_numpy(kn_tf)\n",
    "    pt_layer.edge_kernel.data = torch.from_numpy(bn_tf)\n",
    "\n",
    "    # 3. & 4. Transfer Edge Kernel and Bias\n",
    "    # Same transposition logic applies.\n",
    "    pt_layer.node_weights.data = torch.from_numpy(ke_tf)\n",
    "    pt_layer.edge_weights.data = torch.from_numpy(be_tf)\n",
    "\n",
    "    # 5. Transfer Node Projector Weights (P_n)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.node_bias.data = torch.from_numpy(pn_tf)\n",
    "\n",
    "    # 6. Transfer Edge Projector Weights (P_e)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.edge_bias.data = torch.from_numpy(pe_tf)\n",
    "    \n",
    "\n",
    "def transfer_recurrent_encoder_weights(tf_model, pt_model):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full recurrent encoder, finding layers\n",
    "    by their default names and types to avoid modifying original code.\n",
    "    \"\"\"\n",
    "    # The final dense layer is consistently the last one in the model's layer list.\n",
    "    final_dense_tf = tf_model.layers[-1]\n",
    "    final_dense_pt = pt_model.final_dense\n",
    "    w, b = final_dense_tf.get_weights()\n",
    "    final_dense_pt.weight.data = torch.from_numpy(w.T)\n",
    "    final_dense_pt.bias.data = torch.from_numpy(b)\n",
    "\n",
    "    if pt_model.use_gnn:\n",
    "        # Keras automatically names nested models 'model', 'model_1', etc., by order of creation.\n",
    "        # Node recurrent block is created first.\n",
    "        node_recurrent_model = tf_model.get_layer(\"model\")\n",
    "        # Edge recurrent block is created second.\n",
    "        edge_recurrent_model = tf_model.get_layer(\"model_1\")\n",
    "        # Find the CensNetConv layer by its class type.\n",
    "        gnn_layer = next(l for l in tf_model.layers if isinstance(l, CensNetConv))\n",
    "\n",
    "        transfer_recurrent_block_weights(node_recurrent_model, pt_model.node_recurrent_block)\n",
    "        transfer_recurrent_block_weights(edge_recurrent_model, pt_model.edge_recurrent_block)\n",
    "        transfer_censnet_weights(gnn_layer, pt_model.spatial_gnn_block)\n",
    "    else: # Not using GNN\n",
    "        # There is only one nested model, which Keras names 'model'.\n",
    "        recurrent_model = tf_model.get_layer(\"model\")\n",
    "        transfer_recurrent_block_weights(recurrent_model, pt_model.recurrent_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e744d26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward_pass_gnn (__main__.TestRecurrentEncoderTranslation)\n",
      "Test the GNN-enabled path of the encoder. ... The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "ok\n",
      "test_forward_pass_no_gnn (__main__.TestRecurrentEncoderTranslation)\n",
      "Test the non-GNN path of the encoder. ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow execution time: 0.09568667411804199\n",
      "Pytorch execution time: 0.003713369369506836\n",
      "✅ `RecurrentEncoderPT` (GNN path) translation test PASSED!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 8.027s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ `RecurrentEncoderPT` (non-GNN path) translation test PASSED!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestRecurrentEncoderTranslation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up parameters and create random data that matches model assumptions.\"\"\"\n",
    "        tf.keras.backend.clear_session()\n",
    "        self.latent_dim = 8\n",
    "        \n",
    "        # Inits\n",
    "        self.b, self.t, self.n, self.f = 2, 10, 3, 12  # Batch, Time, Nodes, Features\n",
    "        self.e, self.f_edge = 3, 3  # Edges, Edge Features\n",
    "\n",
    "        self.input_shape = (self.t, self.n, self.f)\n",
    "        self.edge_shape = (self.t, self.e, self.f_edge)\n",
    "        self.adj_matrix = np.ones((self.n, self.n)) - np.eye(self.n)\n",
    "\n",
    "        # Create random input data\n",
    "        self.x_np = np.random.rand(self.b, self.t, self.n, self.f).astype(np.float32)\n",
    "        self.a_np = np.random.rand(self.b, self.t, self.e, self.f_edge).astype(np.float32)\n",
    "        \n",
    "    def test_forward_pass_gnn(self):\n",
    "        \"\"\"Test the GNN-enabled path of the encoder.\"\"\"\n",
    "        # Build TF and PT models\n",
    "        tf_model_gnn = get_recurrent_encoder(\n",
    "            self.input_shape, self.edge_shape, self.adj_matrix, self.latent_dim, use_gnn=True\n",
    "        )\n",
    "        pt_model_gnn = RecurrentEncoderPT(\n",
    "            self.input_shape, self.edge_shape, self.adj_matrix, self.latent_dim, use_gnn=True\n",
    "        )\n",
    "        pt_model_gnn.eval()\n",
    "\n",
    "        # Run a single \"dummy\" forward pass on the PyTorch model.\n",
    "        with torch.no_grad():\n",
    "            pt_model_gnn(torch.from_numpy(self.x_np), torch.from_numpy(self.a_np))\n",
    "\n",
    "        # Now that the weights have been initialized, we can transfer the TF values into them.\n",
    "        transfer_recurrent_encoder_weights(tf_model_gnn, pt_model_gnn)\n",
    "\n",
    "        # Execute and compare the outputs\n",
    "        tf_start = time.time()\n",
    "        tf_output = tf_model_gnn([self.x_np, self.a_np], training=False).numpy()\n",
    "        tf_end = time.time()\n",
    "        pt_start = time.time()\n",
    "        with torch.no_grad():\n",
    "            pt_output = pt_model_gnn(torch.from_numpy(self.x_np), torch.from_numpy(self.a_np)).detach().numpy()\n",
    "        pt_end = time.time()\n",
    "\n",
    "        print(\"Tensorflow execution time: \" + str(tf_end-tf_start))\n",
    "        print(\"Pytorch execution time: \" + str(pt_end-pt_start))\n",
    "\n",
    "        np.testing.assert_allclose(tf_output, pt_output, rtol=1e-5, atol=1e-4)\n",
    "        print(\"✅ `RecurrentEncoderPT` (GNN path) translation test PASSED!\")\n",
    "\n",
    "    def test_forward_pass_no_gnn(self):\n",
    "        \"\"\"Test the non-GNN path of the encoder.\"\"\"\n",
    "        # Build TF and PT models\n",
    "        tf_model_no_gnn = get_recurrent_encoder(\n",
    "            self.input_shape, self.edge_shape, self.adj_matrix, self.latent_dim, use_gnn=False\n",
    "        )\n",
    "        pt_model_no_gnn = RecurrentEncoderPT(\n",
    "            self.input_shape, self.edge_shape, self.adj_matrix, self.latent_dim, use_gnn=False\n",
    "        )\n",
    "        pt_model_no_gnn.eval()\n",
    "\n",
    "        # Transfer weights\n",
    "        transfer_recurrent_encoder_weights(tf_model_no_gnn, pt_model_no_gnn)\n",
    "\n",
    "        # Execute and compare\n",
    "        tf_output = tf_model_no_gnn([self.x_np, self.a_np], training=False).numpy()\n",
    "        pt_output = pt_model_no_gnn(torch.from_numpy(self.x_np), torch.from_numpy(self.a_np)).detach().numpy()\n",
    "\n",
    "        np.testing.assert_allclose(tf_output, pt_output, rtol=1e-5, atol=1e-5)\n",
    "        print(\"✅ `RecurrentEncoderPT` (non-GNN path) translation test PASSED!\")\n",
    "\n",
    "# To run:\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestRecurrentEncoderTranslation)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86be78f0",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28daa27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "import tensorflow_probability as tfp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from typing import List, Tuple, Dict\n",
    "import time\n",
    "import deepof.model_utils\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b0bb13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.layers import Layer # Assuming ClusterControl inherits from this\n",
    "from typing import List\n",
    "\n",
    "# These are placeholders for the external utilities used in the original model\n",
    "# to make the class definition self-contained and runnable.\n",
    "class ClusterControl(Layer):\n",
    "    \"\"\"Placeholder for the custom deepof.model_utils.ClusterControl layer.\"\"\"\n",
    "    def __init__(self, batch_size, n_components, encoding_dim, k, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, inputs: List[tf.Tensor]) -> tf.Tensor:\n",
    "        # The layer is pass-through for the latent vector\n",
    "        return inputs[0]\n",
    "\n",
    "def compute_kmeans_loss(latent_means: tf.Tensor, weight: float, batch_size: int) -> tf.Tensor:\n",
    "    \"\"\"Placeholder for the custom deepof.model_utils.compute_kmeans_loss function.\"\"\"\n",
    "    gram_matrix = (tf.transpose(latent_means) @ latent_means) / tf.cast(batch_size, tf.float32)\n",
    "    s = tf.linalg.svd(gram_matrix, compute_uv=False)\n",
    "    s = tf.sqrt(tf.maximum(s, 1e-9))\n",
    "    return weight * tf.reduce_mean(s)\n",
    "\n",
    "# TensorFlow Probability layers\n",
    "tfpl = tfp.layers\n",
    "tfd = tfp.distributions\n",
    "\n",
    "\n",
    "class GaussianMixtureLatent(tf.keras.models.Model):\n",
    "    \"\"\"Gaussian Mixture probabilistic latent space model.\n",
    "\n",
    "    Used to represent the embedding of motion tracking data in a mixture of Gaussians\n",
    "    with a provided number of components, with means, covariances and weights.\n",
    "    Implementation based on VaDE (https://arxiv.org/abs/1611.05148)\n",
    "    and VaDE-SC (https://openreview.net/forum?id=RQ428ZptQfU).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: tuple,\n",
    "        n_components: int,\n",
    "        latent_dim: int,\n",
    "        batch_size: int,\n",
    "        kl_warmup: int = 5,\n",
    "        kl_annealing_mode: str = \"linear\",\n",
    "        mc_kl: int = 100,\n",
    "        mmd_warmup: int = 15,\n",
    "        mmd_annealing_mode: str = \"linear\",\n",
    "        kmeans_loss: float = 0.0,\n",
    "        reg_cluster_variance: bool = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Initialize the Gaussian Mixture Latent layer.\n",
    "\n",
    "        Args:\n",
    "            input_shape (tuple): shape of the input data\n",
    "            n_components (int): number of components in the Gaussian mixture.\n",
    "            latent_dim (int): dimensionality of the latent space.\n",
    "            batch_size (int): batch size for training.\n",
    "            kl_warmup (int): number of epochs to warm up the KL divergence.\n",
    "            kl_annealing_mode (str): mode to use for annealing the KL divergence. Must be one of \"linear\" and \"sigmoid\".\n",
    "            mc_kl (int): number of Monte Carlo samples to use for computing the KL divergence.\n",
    "            mmd_warmup (int): number of epochs to warm up the MMD.\n",
    "            mmd_annealing_mode (str): mode to use for annealing the MMD. Must be one of \"linear\" and \"sigmoid\".\n",
    "            kmeans_loss (float): weight of the Gram matrix regularization loss.\n",
    "            reg_cluster_variance (bool): whether to penalize uneven cluster variances in the latent space.\n",
    "            **kwargs: keyword arguments passed to the parent class\n",
    "\n",
    "        \"\"\"\n",
    "        super(GaussianMixtureLatent, self).__init__(**kwargs)\n",
    "        self.seq_shape = input_shape[0] \n",
    "        self.n_components = n_components\n",
    "        self.latent_dim = latent_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.kl_warmup = kl_warmup\n",
    "        self.kl_annealing_mode = kl_annealing_mode\n",
    "        self.mc_kl = mc_kl\n",
    "        self.mmd_warmup = mmd_warmup\n",
    "        self.mmd_annealing_mode = mmd_annealing_mode\n",
    "        self.kmeans = kmeans_loss\n",
    "        self.optimizer = Nadam(learning_rate=1e-3, clipvalue=0.75)\n",
    "        self.reg_cluster_variance = reg_cluster_variance\n",
    "        self.pretrain = tf.Variable(0.0, name=\"pretrain\", trainable=False)\n",
    "\n",
    "        # Initialize GM parameters\n",
    "        self.c_mu = tf.Variable(\n",
    "            tf.initializers.GlorotNormal()(shape=[self.n_components, self.latent_dim]),\n",
    "            name=\"mu_c\",\n",
    "        )\n",
    "        self.log_c_sigma = tf.Variable(\n",
    "            tf.initializers.GlorotNormal()([self.n_components, self.latent_dim]),\n",
    "            name=\"log_sigma_c\",\n",
    "        )\n",
    "\n",
    "        # Initialize the Gaussian Mixture prior with the specified number of components\n",
    "        self.prior = tf.constant(tf.ones([self.n_components]) * (1 / self.n_components))\n",
    "\n",
    "        # Initialize layers\n",
    "        self.z_gauss_mean = Dense(\n",
    "            tfpl.IndependentNormal.params_size(self.latent_dim) // 2,\n",
    "            name=\"cluster_means\",\n",
    "            activation=\"linear\",\n",
    "            kernel_initializer=\"glorot_uniform\",\n",
    "            activity_regularizer=None,\n",
    "        )\n",
    "        self.z_gauss_var = Dense(\n",
    "            tfpl.IndependentNormal.params_size(self.latent_dim) // 2,\n",
    "            name=\"cluster_variances\",\n",
    "            activation=\"softplus\",\n",
    "            kernel_initializer=\"glorot_uniform\",\n",
    "            activity_regularizer=tf.keras.regularizers.l1(0.1),\n",
    "        )\n",
    "\n",
    "        self.cluster_control_layer = deepof.model_utils.ClusterControl(\n",
    "            batch_size=self.batch_size,\n",
    "            n_components=self.n_components,\n",
    "            encoding_dim=self.latent_dim,\n",
    "            k=self.n_components,\n",
    "        )\n",
    "\n",
    "        # control KL weight\n",
    "        self.kl_warm_up_iters = tf.cast(\n",
    "            self.kl_warmup * (self.seq_shape // self.batch_size), tf.int64\n",
    "        )\n",
    "        self._kl_weight = tf.Variable(\n",
    "            1.0, trainable=False, dtype=tf.float32, name=\"kl_weight\"\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, training=False, epsilon=None, return_all_outputs_for_testing=False): # pragma: no cover\n",
    "        \"\"\"Compute the output of the layer.\"\"\"\n",
    "        z_gauss_mean = self.z_gauss_mean(inputs)\n",
    "        z_gauss_var = self.z_gauss_var(inputs)\n",
    "\n",
    "        if epsilon is not None:\n",
    "            # Use deterministic reparameterization for testing\n",
    "            z_sample = z_gauss_mean + tf.math.sqrt(tf.math.exp(z_gauss_var)) * epsilon\n",
    "        else:\n",
    "            # Original stochastic sampling for production\n",
    "            z_dist = tfd.MultivariateNormalDiag(\n",
    "                loc=z_gauss_mean, scale_diag=tf.math.sqrt(tf.math.exp(z_gauss_var))\n",
    "            )\n",
    "            z_sample = tf.squeeze(z_dist.sample())\n",
    "\n",
    "        # Compute embedding probabilities given each cluster\n",
    "        p_z_c = tf.stack(\n",
    "            [\n",
    "                tfd.MultivariateNormalDiag(\n",
    "                    loc=self.c_mu[i, :],\n",
    "                    scale_diag=tf.math.exp(self.log_c_sigma)[i, :],\n",
    "                ).log_prob((z_sample if training else z_gauss_mean))\n",
    "                + 1e-6\n",
    "                for i in range(self.n_components)\n",
    "            ],\n",
    "            axis=-1,\n",
    "        )\n",
    "\n",
    "        # Update prior\n",
    "        prior = self.prior\n",
    "\n",
    "        # Compute cluster probabilitie given embedding\n",
    "        z_cat = tf.math.log(prior + 1e-6) + p_z_c\n",
    "        z_cat = tf.nn.log_softmax(z_cat, axis=-1)\n",
    "        z_cat = tf.math.exp(z_cat)\n",
    "\n",
    "        # Add clustering loss\n",
    "        loss_clustering = -tf.reduce_sum(\n",
    "            tf.multiply(z_cat, tf.math.softmax(p_z_c, axis=-1)), axis=-1\n",
    "        ) * (1.0 - tf.cast(self.pretrain, tf.float32))\n",
    "        loss_prior = -tf.math.reduce_sum(\n",
    "            tf.math.xlogy(z_cat, 1e-6 + prior), axis=-1\n",
    "        ) * (1.0 - tf.cast(self.pretrain, tf.float32))\n",
    "\n",
    "        #self.add_metric(loss_clustering, name=\"clustering_loss\", aggregation=\"mean\")\n",
    "        #self.add_metric(loss_prior, name=\"prior_loss\", aggregation=\"mean\")\n",
    "\n",
    "        # Update KL weight based on the current iteration\n",
    "        if self.kl_warm_up_iters > 0:\n",
    "            if self.kl_annealing_mode in [\"linear\", \"sigmoid\"]:\n",
    "                self._kl_weight = tf.cast(\n",
    "                    tf.keras.backend.min(\n",
    "                        [self.optimizer.iterations / self.kl_warm_up_iters, 1.0]\n",
    "                    ),\n",
    "                    tf.float32,\n",
    "                )\n",
    "                if self.kl_annealing_mode == \"sigmoid\":\n",
    "                    self._kl_weight = tf.math.sigmoid(\n",
    "                        (2 * self._kl_weight - 1)\n",
    "                        / (self._kl_weight - self._kl_weight**2)\n",
    "                    )\n",
    "            else:\n",
    "                raise NotImplementedError(\n",
    "                    \"annealing_mode must be one of 'linear' and 'sigmoid'\"\n",
    "                )\n",
    "        else:\n",
    "            self._kl_weight = tf.cast(1.0, tf.float32)\n",
    "\n",
    "        loss_variational_1 = -1 / 2 * tf.reduce_sum(z_gauss_var + 1, axis=-1)\n",
    "        loss_variational_2 = tf.math.reduce_sum(\n",
    "            tf.math.xlogy(z_cat, 1e-6 + z_cat), axis=-1\n",
    "        )\n",
    "        kl = loss_variational_1 + loss_variational_2 * (\n",
    "            1.0 - tf.cast(self.pretrain, tf.float32)\n",
    "        )\n",
    "        kl_batch = self._kl_weight * kl\n",
    "\n",
    "        #self.add_metric(self._kl_weight, aggregation=\"mean\", name=\"kl_weight\")\n",
    "        #self.add_metric(kl, aggregation=\"mean\", name=\"kl_divergence\")\n",
    "\n",
    "        #self.add_loss(tf.math.reduce_mean(loss_clustering))\n",
    "        #self.add_loss(tf.math.reduce_mean(loss_prior))\n",
    "        #self.add_loss(tf.math.reduce_mean(kl_batch))\n",
    "\n",
    "\n",
    "        # Calculate metrics for potential return\n",
    "        hard_groups = tf.math.argmax(z_cat, axis=1)\n",
    "        max_groups = tf.reduce_max(z_cat, axis=1)\n",
    "        n_populated = tf.cast(tf.shape(tf.unique(tf.reshape(hard_groups, [-1]))[0])[0], tf.float32)\n",
    "        confidence = tf.reduce_mean(max_groups)\n",
    "\n",
    "        z = z_sample if training else z_gauss_mean\n",
    "\n",
    "        if self.n_components > 1:\n",
    "            z = self.cluster_control_layer([z, z_cat])\n",
    "\n",
    "        k_loss = 0.0\n",
    "        if self.kmeans:\n",
    "            k_loss = deepof.model_utils.compute_kmeans_loss(z, weight=self.kmeans, batch_size=self.batch_size)\n",
    "            #self.add_loss(k_loss)\n",
    "            #self.add_metric(k_loss, name=\"kmeans_loss\")\n",
    "\n",
    "        # MODIFIED: Add a switch for the return value\n",
    "        if return_all_outputs_for_testing:\n",
    "            # In test mode, return all computed values for direct comparison\n",
    "            return z, z_cat, n_populated, confidence, k_loss\n",
    "        else:\n",
    "            # In production mode, use side effects (add_loss/add_metric) and return the original signature\n",
    "            loss_clustering = -tf.reduce_sum(tf.multiply(z_cat, tf.math.softmax(p_z_c, axis=-1)), axis=-1) * (1.0 - tf.cast(self.pretrain, tf.float32))\n",
    "            loss_prior = -tf.reduce_sum(tf.math.xlogy(z_cat, 1e-6 + self.prior), axis=-1) * (1.0 - tf.cast(self.pretrain, tf.float32))\n",
    "            self.add_metric(loss_clustering, name=\"clustering_loss\", aggregation=\"mean\")\n",
    "            self.add_metric(loss_prior, name=\"prior_loss\", aggregation=\"mean\")\n",
    "\n",
    "            self.add_metric(self._kl_weight, aggregation=\"mean\", name=\"kl_weight\")\n",
    "            self.add_metric(kl, aggregation=\"mean\", name=\"kl_divergence\")\n",
    "\n",
    "            self.add_loss(tf.math.reduce_mean(loss_clustering))\n",
    "            self.add_loss(tf.math.reduce_mean(loss_prior))\n",
    "            self.add_loss(tf.math.reduce_mean(kl_batch))\n",
    "\n",
    "            if self.kmeans:\n",
    "                self.add_loss(k_loss)\n",
    "                self.add_metric(k_loss, name=\"kmeans_loss\")\n",
    "\n",
    "            # ... all other add_loss and add_metric calls from the original ...\n",
    "            return z, z_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "034c7a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "\n",
    "class ClusterControlPT(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates clustering metrics. This is a pass-through layer for the main\n",
    "    latent vector `z`, returning it unmodified alongside a dictionary of metrics.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(\n",
    "        self, z: torch.Tensor, z_cat: torch.Tensor\n",
    "    ) -> Tuple[torch.Tensor, Dict[str, torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Calculates metrics and passes the latent vector `z` through.\n",
    "\n",
    "        Args:\n",
    "            z: The latent vector (batch_size, latent_dim).\n",
    "            z_cat: Cluster probabilities (batch_size, n_components).\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing the unmodified `z` and a dictionary of metrics.\n",
    "        \"\"\"\n",
    "        confidence, hard_groups = torch.max(z_cat, dim=1)\n",
    "        \n",
    "        # Calculate the number of unique clusters populated in the batch\n",
    "        num_populated = torch.unique(hard_groups).numel()\n",
    "        \n",
    "        metrics = {\n",
    "            \"number_of_populated_clusters\": torch.tensor(\n",
    "                float(num_populated), device=z.device\n",
    "            ),\n",
    "            \"confidence_in_selected_cluster\": torch.mean(confidence),\n",
    "        }\n",
    "        \n",
    "        return z, metrics\n",
    "\n",
    "def compute_kmeans_loss_pt(latent_means: torch.Tensor, weight: float) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes a loss based on the singular values of the Gram matrix of the\n",
    "    latent vectors, encouraging orthogonality.\n",
    "\n",
    "    Args:\n",
    "        latent_means: The latent vectors from the model (batch_size, latent_dim).\n",
    "        weight: The weight to apply to this loss component.\n",
    "\n",
    "    Returns:\n",
    "        The calculated scalar loss tensor.\n",
    "    \"\"\"\n",
    "    batch_size = float(latent_means.shape[0])\n",
    "    gram_matrix = (latent_means.T @ latent_means) / batch_size\n",
    "    \n",
    "    # Compute singular values, which are the square roots of the eigenvalues for a symmetric matrix\n",
    "    singular_values = torch.linalg.svdvals(gram_matrix)\n",
    "    \n",
    "    # Clamp to avoid NaN gradients from sqrt(0)\n",
    "    penalization = torch.sqrt(torch.clamp(singular_values, min=1e-9))\n",
    "    \n",
    "    return weight * torch.mean(penalization)\n",
    "\n",
    "\n",
    "class GaussianMixtureLatentPT(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of the Gaussian Mixture probabilistic latent space model.\n",
    "    It embeds data into a latent space and models that space as a mixture of Gaussians.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        n_components: int,\n",
    "        latent_dim: int,\n",
    "        kmeans: float,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.n_components = n_components\n",
    "        self.latent_dim = latent_dim\n",
    "        self.kmeans_weight = kmeans\n",
    "\n",
    "        # --- Trainable Parameters for the GMM components ---\n",
    "        self.gmm_means = nn.Parameter(torch.empty(n_components, latent_dim))\n",
    "        self.gmm_log_vars = nn.Parameter(torch.empty(n_components, latent_dim))\n",
    "        nn.init.xavier_normal_(self.gmm_means)\n",
    "        nn.init.xavier_normal_(self.gmm_log_vars)\n",
    "\n",
    "        # --- Encoder Layers to produce the latent distribution ---\n",
    "        self.encoder_mean = nn.Linear(self.input_dim, self.latent_dim)\n",
    "        self.encoder_log_var = nn.Linear(self.input_dim, self.latent_dim)\n",
    "\n",
    "        # --- Non-trainable Buffers ---\n",
    "        self.register_buffer('prior', torch.ones(n_components) / n_components)\n",
    "        self.register_buffer('pretrain', torch.tensor(0.0))\n",
    "        \n",
    "        # --- Helper Layers ---\n",
    "        self.cluster_control = ClusterControlPT()\n",
    "\n",
    "    def _encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Encodes the input into mean and log-variance of the latent distribution.\"\"\"\n",
    "        z_mean = self.encoder_mean(x)\n",
    "        z_log_var = self.encoder_log_var(x) # Note: softplus is applied in the forward pass\n",
    "        return z_mean, z_log_var\n",
    "\n",
    "    def _reparameterize(\n",
    "        self, mean: torch.Tensor, var: torch.Tensor, epsilon: torch.Tensor = None\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Performs reparameterization.\n",
    "        MODIFIED to exactly replicate the original TF model's non-standard scale calculation.\n",
    "        \"\"\"\n",
    "        # Original TF logic: scale = sqrt(exp(variance))\n",
    "        # The 'var' input here is the direct output of the softplus activation.\n",
    "        scale = torch.sqrt(torch.exp(var))\n",
    "        \n",
    "        if epsilon is None:\n",
    "            epsilon = torch.randn_like(scale)\n",
    "        return mean + scale * epsilon\n",
    "\n",
    "    def _calculate_posterior(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Calculates the posterior probability p(c|z) for each sample.\"\"\"\n",
    "        # MODIFIED: The GMM parameters from TF are log-std-dev, not log-variance.\n",
    "        # So we just exponentiate them to get the scale.\n",
    "        gmm_scale = torch.exp(self.gmm_log_vars)\n",
    "\n",
    "        gmm_dist = Normal(\n",
    "            loc=self.gmm_means.unsqueeze(0),\n",
    "            scale=gmm_scale.unsqueeze(0)\n",
    "        )\n",
    "        log_p_z_given_c = gmm_dist.log_prob(z.unsqueeze(1)).sum(dim=-1)\n",
    "        \n",
    "        log_p_c_given_z = torch.log(self.prior + 1e-9) + log_p_z_given_c\n",
    "        \n",
    "        return F.softmax(log_p_c_given_z, dim=-1)\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, epsilon: torch.Tensor = None\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        z_mean, z_var_raw = self._encode(x)\n",
    "        z_var = F.softplus(z_var_raw) # Apply activation\n",
    "\n",
    "        # Pass z_var directly, not z_log_var\n",
    "        z_sample = self._reparameterize(z_mean, z_var, epsilon)\n",
    "        # ... rest of the method is the same ...\n",
    "        z_for_downstream = z_sample if self.training else z_mean\n",
    "        z_cat = self._calculate_posterior(z_for_downstream)\n",
    "        z_final, metrics = self.cluster_control(z_for_downstream, z_cat)\n",
    "        kmeans_loss = torch.tensor(0.0, device=x.device)\n",
    "        if self.kmeans_weight > 0:\n",
    "            kmeans_loss = compute_kmeans_loss_pt(z_final, weight=self.kmeans_weight)\n",
    "        return (z_final, z_cat, metrics[\"number_of_populated_clusters\"], metrics[\"confidence_in_selected_cluster\"], kmeans_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e57d957c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_gmm_weights(tf_model, pt_model: GaussianMixtureLatentPT):\n",
    "    \"\"\"\n",
    "    Transfers weights from the final TF model to the refactored PT model,\n",
    "    using the updated attribute names.\n",
    "    \"\"\"\n",
    "    # --- Transfer GMM component parameters ---\n",
    "    # OLD: pt_model.c_mu\n",
    "    pt_model.gmm_means.data = torch.from_numpy(tf_model.c_mu.numpy())\n",
    "    # OLD: pt_model.log_c_sigma\n",
    "    pt_model.gmm_log_vars.data = torch.from_numpy(tf_model.log_c_sigma.numpy())\n",
    "\n",
    "    # --- Transfer Encoder layer parameters ---\n",
    "    tf_mean_weights = tf_model.z_gauss_mean.get_weights()\n",
    "    # OLD: pt_model.z_gauss_mean\n",
    "    pt_model.encoder_mean.weight.data = torch.from_numpy(tf_mean_weights[0].T)\n",
    "    pt_model.encoder_mean.bias.data = torch.from_numpy(tf_mean_weights[1])\n",
    "    \n",
    "    tf_var_weights = tf_model.z_gauss_var.get_weights()\n",
    "    # OLD: pt_model.z_gauss_var\n",
    "    pt_model.encoder_log_var.weight.data = torch.from_numpy(tf_var_weights[0].T)\n",
    "    pt_model.encoder_log_var.bias.data = torch.from_numpy(tf_var_weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "657aeb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_final_pass_eval_mode (__main__.TestGMMFinalSimplified) ... ok\n",
      "test_final_pass_train_mode (__main__.TestGMMFinalSimplified) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing final integration in EVALUATION mode ---\n",
      "Tensorflow execution time: 0.053191423416137695\n",
      "Pytorch execution time: 0.006725311279296875\n",
      "Comparing all outputs...\n",
      "✅ Final integration in EVALUATION mode PASSED!\n",
      "\n",
      "--- Testing final integration in TRAINING mode ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.625s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow execution time: 0.05488920211791992\n",
      "Pytorch execution time: 0.0\n",
      "Comparing all outputs...\n",
      "✅ Final integration in TRAINING mode PASSED!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TestGMMFinalSimplified(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.input_dim, self.latent_dim, self.n_components, self.batch_size = 64, 16, 5, 4\n",
    "        self.seq_shape = self.batch_size * 100\n",
    "        self.kmeans_weight = 0.1\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        # Instantiate the *actual* final TF model\n",
    "        self.tf_model = GaussianMixtureLatent(\n",
    "            input_shape=(self.seq_shape, self.input_dim),\n",
    "            n_components=self.n_components,\n",
    "            latent_dim=self.latent_dim,\n",
    "            batch_size=self.batch_size,\n",
    "            kmeans_loss=self.kmeans_weight\n",
    "        )\n",
    "        # Build the model using the test-mode signature\n",
    "        self.tf_model(\n",
    "            tf.zeros((1, self.input_dim)), \n",
    "            epsilon=tf.zeros((1, self.latent_dim)),\n",
    "            return_all_outputs_for_testing=True\n",
    "        )\n",
    "\n",
    "        # PyTorch model setup remains the same\n",
    "        self.pt_model = GaussianMixtureLatentPT(\n",
    "            input_dim=self.input_dim, n_components=self.n_components,\n",
    "            latent_dim=self.latent_dim, kmeans=self.kmeans_weight\n",
    "        )\n",
    "        \n",
    "        transfer_gmm_weights(self.tf_model, self.pt_model)\n",
    "        \n",
    "        self.np_input = np.random.rand(self.batch_size, self.input_dim).astype(np.float32)\n",
    "        seed = 42\n",
    "        np.random.seed(seed)\n",
    "        epsilon_np = np.random.randn(self.batch_size, self.latent_dim).astype(np.float32)\n",
    "        self.epsilon_tf = tf.convert_to_tensor(epsilon_np)\n",
    "        self.epsilon_pt = torch.from_numpy(epsilon_np)\n",
    "\n",
    "    def run_comparison_test(self, training_mode: bool):\n",
    "        mode_str = \"TRAINING\" if training_mode else \"EVALUATION\"\n",
    "        print(f\"\\n--- Testing final integration in {mode_str} mode ---\")\n",
    "        \n",
    "        self.pt_model.train(training_mode)\n",
    "\n",
    "        tf_start = time.time()\n",
    "        # Call the TF model with test flags enabled\n",
    "        tf_z, tf_z_cat, tf_n_pop, tf_conf, tf_kmeans = self.tf_model(\n",
    "            self.np_input, \n",
    "            training=training_mode, \n",
    "            epsilon=self.epsilon_tf, \n",
    "            return_all_outputs_for_testing=True\n",
    "        )\n",
    "        tf_end = time.time()\n",
    "        \n",
    "        pt_start = time.time()\n",
    "        # PyTorch call remains the same\n",
    "        with torch.no_grad():\n",
    "            pt_z, pt_z_cat, pt_n_pop, pt_conf, pt_kmeans = self.pt_model(\n",
    "                torch.from_numpy(self.np_input), epsilon=self.epsilon_pt\n",
    "            )\n",
    "        pt_end = time.time()\n",
    "        \n",
    "        print(\"Tensorflow execution time: \" + str(tf_end-tf_start))\n",
    "        print(\"Pytorch execution time: \" + str(pt_end-pt_start))\n",
    "        \n",
    "        print(\"Comparing all outputs...\")\n",
    "        np.testing.assert_allclose(tf_z.numpy(), pt_z.numpy(), rtol=1e-5, atol=1e-5)\n",
    "        np.testing.assert_allclose(tf_z_cat.numpy(), pt_z_cat.numpy(), rtol=1e-5, atol=1e-5)\n",
    "        np.testing.assert_allclose(tf_n_pop.numpy(), pt_n_pop.numpy(), rtol=1e-5, atol=1e-5)\n",
    "        np.testing.assert_allclose(tf_conf.numpy(), pt_conf.numpy(), rtol=1e-5, atol=1e-5)\n",
    "        np.testing.assert_allclose(tf_kmeans.numpy(), pt_kmeans.numpy(), rtol=1e-5, atol=1e-5)\n",
    "        print(f\"✅ Final integration in {mode_str} mode PASSED!\")\n",
    "\n",
    "    def test_final_pass_train_mode(self):\n",
    "        self.run_comparison_test(training_mode=True)\n",
    "    \n",
    "    def test_final_pass_eval_mode(self):\n",
    "        self.run_comparison_test(training_mode=False)\n",
    "\n",
    "\n",
    "# Run the test\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestGMMFinalSimplified)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e442e",
   "metadata": {},
   "source": [
    "# Get Vade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c2c93b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "import tensorflow_probability as tfp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "import time\n",
    "import deepof.model_utils\n",
    "from deepof.model_utils import ClusterControl, compute_kmeans_loss, CensNetConv, ProbabilisticDecoder\n",
    "from deepof.models import get_recurrent_encoder, get_recurrent_decoder, GaussianMixtureLatent, get_TCN_encoder, get_TCN_decoder, get_transformer_encoder, get_transformer_decoder\n",
    "from deepof.clustering.models_new import RecurrentEncoderPT, RecurrentDecoderPT, GaussianMixtureLatentPT\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    LayerNormalization,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    ")\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9590d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vade(\n",
    "    input_shape: tuple,\n",
    "    edge_feature_shape: tuple,\n",
    "    adjacency_matrix: np.ndarray,\n",
    "    latent_dim: int,\n",
    "    use_gnn: bool,\n",
    "    n_components: int,\n",
    "    batch_size: int = 64,\n",
    "    kl_warmup: int = 15,\n",
    "    kl_annealing_mode: str = \"sigmoid\",\n",
    "    mc_kl: int = 100,\n",
    "    kmeans_loss: float = 1.0,\n",
    "    reg_cluster_variance: bool = False,\n",
    "    encoder_type: str = \"recurrent\",\n",
    "    interaction_regularization: float = 0.0,\n",
    "):\n",
    "    \"\"\"Build a Gaussian mixture variational autoencoder (VaDE) model, adapted to the DeepOF setting.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): shape of the input data.\n",
    "        edge_feature_shape (tuple): shape of the edge feature matrix used for graph representations.\n",
    "        adjacency_matrix (np.ndarray): adjacency matrix of the connectivity graph to use.\n",
    "        latent_dim (int): dimensionality of the latent space.\n",
    "        use_gnn (bool): If True, the encoder uses a graph representation of the input, with coordinates and speeds as node attributes, and distances as edge attributes. If False, a regular 3D tensor is used as input.\n",
    "        n_components (int): number of components in the Gaussian mixture.\n",
    "        batch_size (int): batch size for training.\n",
    "        kl_warmup (int): Number of iterations during which to warm up the KL divergence.\n",
    "        kl_annealing_mode (str): mode to use for annealing the KL divergence. Must be one of \"linear\" and \"sigmoid\".\n",
    "        mc_kl (int): number of Monte Carlo samples to use for computing the KL divergence.\n",
    "        kmeans_loss (float): weight of the Gram matrix loss as described in deepof.model_utils.compute_kmeans_loss.\n",
    "        reg_cluster_variance (bool): whether to penalize uneven cluster variances in the latent space.\n",
    "        encoder_type (str): type of encoder to use. Can be set to \"recurrent\" (default), \"TCN\", or \"transformer\".\n",
    "        interaction_regularization (float): weight of the interaction regularization term.\n",
    "\n",
    "    Returns:\n",
    "        encoder (tf.keras.Model): connected encoder of the VQ-VAE model. Outputs a vector of shape (latent_dim,).\n",
    "        decoder (tf.keras.Model): connected decoder of the VQ-VAE model.\n",
    "        grouper (tf.keras.Model): deep clustering branch of the VQ-VAE model. Outputs a vector of shape (n_components,) for each training instance, corresponding to the soft counts for each cluster.\n",
    "        vade (tf.keras.Model): complete VaDE model\n",
    "\n",
    "    \"\"\"\n",
    "    if encoder_type == \"recurrent\":\n",
    "        encoder = get_recurrent_encoder(\n",
    "            input_shape=input_shape[1:],\n",
    "            adjacency_matrix=adjacency_matrix,\n",
    "            edge_feature_shape=edge_feature_shape[1:],\n",
    "            latent_dim=latent_dim,\n",
    "            use_gnn=use_gnn,\n",
    "            interaction_regularization=interaction_regularization,\n",
    "        )\n",
    "        decoder = get_recurrent_decoder(\n",
    "            input_shape=input_shape[1:], latent_dim=latent_dim\n",
    "        )\n",
    "\n",
    "    elif encoder_type == \"TCN\":\n",
    "        encoder = get_TCN_encoder(\n",
    "            input_shape=input_shape[1:],\n",
    "            adjacency_matrix=adjacency_matrix,\n",
    "            edge_feature_shape=edge_feature_shape[1:],\n",
    "            latent_dim=latent_dim,\n",
    "            use_gnn=use_gnn,\n",
    "            interaction_regularization=interaction_regularization,\n",
    "        )\n",
    "        decoder = get_TCN_decoder(input_shape=input_shape[1:], latent_dim=latent_dim)\n",
    "\n",
    "    elif encoder_type == \"transformer\":\n",
    "        encoder = get_transformer_encoder(\n",
    "            input_shape[1:],\n",
    "            edge_feature_shape=edge_feature_shape[1:],\n",
    "            adjacency_matrix=adjacency_matrix,\n",
    "            latent_dim=latent_dim,\n",
    "            use_gnn=use_gnn,\n",
    "            interaction_regularization=interaction_regularization,\n",
    "        )\n",
    "        decoder = get_transformer_decoder(input_shape[1:], latent_dim=latent_dim)\n",
    "\n",
    "    latent_space = GaussianMixtureLatent(\n",
    "        input_shape=input_shape[0],\n",
    "        n_components=n_components,\n",
    "        latent_dim=latent_dim,\n",
    "        batch_size=batch_size,\n",
    "        kl_warmup=kl_warmup,\n",
    "        kl_annealing_mode=kl_annealing_mode,\n",
    "        mc_kl=mc_kl,\n",
    "        kmeans_loss=kmeans_loss,\n",
    "        reg_cluster_variance=reg_cluster_variance,\n",
    "        name=\"gaussian_mixture_latent\",\n",
    "    )\n",
    "\n",
    "    # Connect encoder and latent space\n",
    "    inputs = Input(input_shape[1:])\n",
    "    a = tf.keras.layers.Input(edge_feature_shape[1:], name=\"encoder_edge_features\")\n",
    "    encoder_outputs = encoder([inputs, a])\n",
    "    latent, categorical = latent_space(encoder_outputs)\n",
    "    embedding = tf.keras.Model([inputs, a], latent, name=\"encoder\")\n",
    "    grouper = tf.keras.Model([inputs, a], categorical, name=\"grouper\")\n",
    "\n",
    "    # Connect decoder\n",
    "    vade_outputs = decoder([embedding.outputs, inputs])\n",
    "\n",
    "    # Instantiate fully connected model\n",
    "    vade = tf.keras.Model(embedding.inputs, vade_outputs, name=\"VaDE\")\n",
    "\n",
    "    return embedding, decoder, grouper, vade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b985dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "# Assume the following translated blocks are imported and available:\n",
    "# from deepof.clustering.models_new import (\n",
    "#     RecurrentEncoderPT, RecurrentDecoderPT, GaussianMixtureLatentPT\n",
    "# )\n",
    "# And their corresponding TensorFlow versions and weight transfer functions are also available.\n",
    "\n",
    "class VaDEPT(nn.Module):\n",
    "    \"\"\"\n",
    "    A self-contained PyTorch implementation of the VaDE model.\n",
    "\n",
    "    This class encapsulates the entire VaDE architecture, including the encoder,\n",
    "    the Gaussian mixture latent space, and the decoder. It is instantiated with\n",
    "    all necessary configuration parameters, building its sub-modules internally.\n",
    "    This provides a clean, single-object interface for the model.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: tuple,\n",
    "        edge_feature_shape: tuple,\n",
    "        adjacency_matrix: np.ndarray,\n",
    "        latent_dim: int,\n",
    "        n_components: int,\n",
    "        use_gnn: bool = True,\n",
    "        kmeans_loss: float = 1.0,\n",
    "        interaction_regularization: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes and builds the VaDE model and its components.\n",
    "\n",
    "        Args:\n",
    "            input_shape (tuple): Shape of the input node features (Time, Nodes, Features_per_node).\n",
    "            edge_feature_shape (tuple): Shape of the edge features (Time, Edges, Features_per_edge).\n",
    "            adjacency_matrix (np.ndarray): Adjacency matrix of the connectivity graph.\n",
    "            latent_dim (int): Dimensionality of the latent space.\n",
    "            n_components (int): Number of components in the Gaussian mixture.\n",
    "            use_gnn (bool): If True, use the GNN-based encoder.\n",
    "            kmeans_loss (float): Weight of the k-means style loss in the latent space.\n",
    "            interaction_regularization (float): Regularization for GNN interaction features.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store key dimensions for internal use (e.g., reshaping in forward pass)\n",
    "        time_steps, n_nodes, n_features_per_node = input_shape\n",
    "        self.input_n_nodes = n_nodes\n",
    "        self.input_n_features_per_node = n_features_per_node\n",
    "\n",
    "        # 1. Instantiate Encoder\n",
    "        self.encoder = RecurrentEncoderPT(\n",
    "            input_shape=input_shape,\n",
    "            edge_feature_shape=edge_feature_shape,\n",
    "            adjacency_matrix=adjacency_matrix,\n",
    "            latent_dim=latent_dim,\n",
    "            use_gnn=use_gnn,\n",
    "            interaction_regularization=interaction_regularization,\n",
    "        )\n",
    "\n",
    "        # 2. Instantiate Latent Space\n",
    "        self.latent_space = GaussianMixtureLatentPT(\n",
    "            input_dim=latent_dim,\n",
    "            n_components=n_components,\n",
    "            latent_dim=latent_dim,\n",
    "            kmeans=kmeans_loss,\n",
    "        )\n",
    "\n",
    "        # 3. Instantiate Decoder\n",
    "        decoder_output_features = n_nodes * n_features_per_node\n",
    "        self.decoder = RecurrentDecoderPT(\n",
    "            output_shape=(time_steps, decoder_output_features),\n",
    "            latent_dim=latent_dim,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, a: torch.Tensor\n",
    "    ) -> Tuple[torch.distributions.Distribution, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Defines the full forward pass for the VaDE model (training and evaluation).\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input node features tensor (B, T, N, F_node).\n",
    "            a (torch.Tensor): Input edge features tensor (B, T, E, F_edge).\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing:\n",
    "            - reconstruction_dist (torch.distributions.Distribution): The output distribution from the decoder.\n",
    "            - latent (torch.Tensor): The sampled latent representation from the GMM space.\n",
    "            - categorical (torch.Tensor): The cluster probabilities (soft assignments).\n",
    "            - kmeans_loss (torch.Tensor): The k-means regularization loss from the latent space.\n",
    "        \"\"\"\n",
    "        # 1. Encode the input to get the pre-latent representation\n",
    "        encoder_output = self.encoder(x, a)\n",
    "        \n",
    "        # 2. Pass through GMM latent space\n",
    "        latent, categorical, _, _, kmeans_loss, gmm_params = self.latent_space(encoder_output)\n",
    "        \n",
    "        # 3. Decode the latent sample back to the original data space\n",
    "        # Reshape x to (B, T, N*F) for the decoder's masking logic\n",
    "        B, T, _, _ = x.shape\n",
    "        x_for_decoder = x.view(B, T, self.input_n_nodes * self.input_n_features_per_node)\n",
    "        \n",
    "        reconstruction_dist = self.decoder(latent, x_for_decoder)\n",
    "        \n",
    "        return reconstruction_dist, latent, categorical, kmeans_loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def embed(self, x: torch.Tensor, a: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Inference-only method to get the latent embedding. Equivalent to the 'embedding' Keras model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input node features tensor.\n",
    "            a (torch.Tensor): Input edge features tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The latent representation `z`.\n",
    "        \"\"\"\n",
    "        encoder_output = self.encoder(x, a)\n",
    "        latent, _, _, _, _, _ = self.latent_space(encoder_output)\n",
    "        return latent\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def group(self, x: torch.Tensor, a: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Inference-only method to get cluster probabilities. Equivalent to the 'grouper' Keras model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input node features tensor.\n",
    "            a (torch.Tensor): Input edge features tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The soft cluster assignments (categorical probabilities).\n",
    "        \"\"\"\n",
    "        encoder_output = self.encoder(x, a)\n",
    "        _, categorical, _, _, _, _ = self.latent_space(encoder_output)\n",
    "        return categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19ec8fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_recurrent_block_weights(tf_model, pt_model):\n",
    "    \"\"\"Transfers weights for the full recurrent block with GRU gate permutation.\"\"\"\n",
    "    conv_td, _, gru1_td, norm1, gru2_td, norm2 = tf_model.layers[1:]\n",
    "\n",
    "\n",
    "    def permute_gru_weights(keras_weights):\n",
    "        W_ih, W_hh, B = keras_weights\n",
    "        W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "        W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "        W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "        W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "        B_ih, B_hh = B\n",
    "        B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "        B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "        B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "        B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "        return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_td.layer.get_weights()[0]).permute(2, 1, 0)\n",
    "    \n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(gru1_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1); pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    \n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(gru1_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1); pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm1.get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm1.get_weights()[1])\n",
    "\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(gru2_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2); pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    \n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(gru2_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2); pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    \n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm2.get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm2.get_weights()[1])\n",
    "\n",
    "    \n",
    "def transfer_censnet_weights(tf_layer, pt_layer):\n",
    "    \"\"\"\n",
    "    Transfers all six weights from a Spektral CensNetConv layer to the\n",
    "    corresponding CensNetConvPT layer.\n",
    "    \"\"\"\n",
    "    # Get all weights from the TensorFlow layer. The order is determined by\n",
    "    # the layer's build order in Spektral's source code.\n",
    "    tf_weights = tf_layer.get_weights()\n",
    "\n",
    "    # Unpack all six weights.\n",
    "    # Order: kernel_node, bias_node, kernel_edge, bias_edge, projector_node, projector_edge\n",
    "    kn_tf, bn_tf, ke_tf, be_tf, pn_tf, pe_tf = tf_weights\n",
    "\n",
    "    # Build weights on first pass\n",
    "    if pt_layer.node_kernel is None:\n",
    "        # Move parameters to the same device as input tensors\n",
    "        pt_layer._build(kn_tf.T.shape, bn_tf.T.shape)\n",
    "        #pt_layer.to(kn_tf.device)\n",
    "\n",
    "    # 1. & 2. Transfer Node Kernel and Bias\n",
    "    # Keras Dense kernel is (in_features, out_features)\n",
    "    pt_layer.node_kernel.data = torch.from_numpy(kn_tf)\n",
    "    pt_layer.edge_kernel.data = torch.from_numpy(bn_tf)\n",
    "\n",
    "    # 3. & 4. Transfer Edge Kernel and Bias\n",
    "    # Same transposition logic applies.\n",
    "    pt_layer.node_weights.data = torch.from_numpy(ke_tf)\n",
    "    pt_layer.edge_weights.data = torch.from_numpy(be_tf)\n",
    "\n",
    "    # 5. Transfer Node Projector Weights (P_n)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.node_bias.data = torch.from_numpy(pn_tf)\n",
    "\n",
    "    # 6. Transfer Edge Projector Weights (P_e)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.edge_bias.data = torch.from_numpy(pe_tf)\n",
    "    \n",
    "\n",
    "def transfer_recurrent_encoder_weights(tf_model, pt_model):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full recurrent encoder, finding layers\n",
    "    by their default names and types to avoid modifying original code.\n",
    "    \"\"\"\n",
    "    # The final dense layer is consistently the last one in the model's layer list.\n",
    "    final_dense_tf = tf_model.layers[-1]\n",
    "    final_dense_pt = pt_model.final_dense\n",
    "    w, b = final_dense_tf.get_weights()\n",
    "    final_dense_pt.weight.data = torch.from_numpy(w.T)\n",
    "    final_dense_pt.bias.data = torch.from_numpy(b)\n",
    "\n",
    "    if pt_model.use_gnn:\n",
    "        # Keras automatically names nested models 'model', 'model_1', etc., by order of creation.\n",
    "        # Node recurrent block is created first.\n",
    "        node_recurrent_model = tf_model.get_layer(\"model\")\n",
    "        # Edge recurrent block is created second.\n",
    "        edge_recurrent_model = tf_model.get_layer(\"model_1\")\n",
    "        # Find the CensNetConv layer by its class type.\n",
    "        gnn_layer = next(l for l in tf_model.layers if isinstance(l, CensNetConv))\n",
    "\n",
    "        transfer_recurrent_block_weights(node_recurrent_model, pt_model.node_recurrent_block)\n",
    "        transfer_recurrent_block_weights(edge_recurrent_model, pt_model.edge_recurrent_block)\n",
    "        transfer_censnet_weights(gnn_layer, pt_model.spatial_gnn_block)\n",
    "    else: # Not using GNN\n",
    "        # There is only one nested model, which Keras names 'model'.\n",
    "        recurrent_model = tf_model.get_layer(\"model\")\n",
    "        transfer_recurrent_block_weights(recurrent_model, pt_model.recurrent_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "611f492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_gmm_weights(tf_model, pt_model: GaussianMixtureLatentPT):\n",
    "    \"\"\"\n",
    "    Transfers weights from the final TF model to the refactored PT model,\n",
    "    using the updated attribute names.\n",
    "    \"\"\"\n",
    "    # --- Transfer GMM component parameters ---\n",
    "    # OLD: pt_model.c_mu\n",
    "    pt_model.gmm_means.data = torch.from_numpy(tf_model.c_mu.numpy())\n",
    "    # OLD: pt_model.log_c_sigma\n",
    "    pt_model.gmm_log_vars.data = torch.from_numpy(tf_model.log_c_sigma.numpy())\n",
    "\n",
    "    # --- Transfer Encoder layer parameters ---\n",
    "    tf_mean_weights = tf_model.z_gauss_mean.get_weights()\n",
    "    # OLD: pt_model.z_gauss_mean\n",
    "    pt_model.encoder_mean.weight.data = torch.from_numpy(tf_mean_weights[0].T)\n",
    "    pt_model.encoder_mean.bias.data = torch.from_numpy(tf_mean_weights[1])\n",
    "    \n",
    "    tf_var_weights = tf_model.z_gauss_var.get_weights()\n",
    "    # OLD: pt_model.z_gauss_var\n",
    "    pt_model.encoder_log_var.weight.data = torch.from_numpy(tf_var_weights[0].T)\n",
    "    pt_model.encoder_log_var.bias.data = torch.from_numpy(tf_var_weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0084d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function from the provided example to handle gate order differences\n",
    "def permute_gru_weights(keras_weights):\n",
    "    \"\"\"Permutes GRU weights from Keras (z, r, n) to PyTorch (r, z, n) format.\"\"\"\n",
    "    W_ih, W_hh, B = keras_weights\n",
    "    # Keras gate order: z, r, n (update, reset, new/candidate)\n",
    "    W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "    W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "\n",
    "    # PyTorch gate order: r, z, n (reset, update, new/candidate)\n",
    "    W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "    W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "\n",
    "    # Keras has two bias vectors (input-hidden and recurrent), which are concatenated in B\n",
    "    B_ih, B_hh = B\n",
    "    B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "    B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "\n",
    "    B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "    B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "\n",
    "    return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "    \n",
    "def transfer_recurrent_decoder_weights(tf_model, pt_model):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full recurrent decoder model.\n",
    "    \"\"\"\n",
    "    # Find layers by type to avoid index issues\n",
    "    bidi_layers = [l for l in tf_model.layers if isinstance(l, Bidirectional)]\n",
    "    norm_layers = [l for l in tf_model.layers if isinstance(l, LayerNormalization)]\n",
    "    conv_layers = [l for l in tf_model.layers if isinstance(l, tf.keras.layers.Conv1D)]\n",
    "    prob_dec_layer = next(l for l in tf_model.layers if isinstance(l, deepof.model_utils.ProbabilisticDecoder))\n",
    "\n",
    "    # --- GRU 1 and Norm 1 ---\n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(bidi_layers[0].forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1)\n",
    "    pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(bidi_layers[0].backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1)\n",
    "    pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm_layers[0].get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm_layers[0].get_weights()[1])\n",
    "\n",
    "    # --- GRU 2 and Norm 2 ---\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(bidi_layers[1].forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2)\n",
    "    pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(bidi_layers[1].backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2)\n",
    "    pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm_layers[1].get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm_layers[1].get_weights()[1])\n",
    "\n",
    "    # --- Conv1D and Norm 3 ---\n",
    "    # TF Conv1D weights: (kernel_w, kernel_h, in_c, out_c) -> (5, 1, 4*ld, 2*ld)\n",
    "    # PT Conv1d weights: (out_c, in_c, kernel_w)\n",
    "    conv_weights_tf = conv_layers[0].get_weights()[0]\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_weights_tf).squeeze(1).permute(2, 1, 0)\n",
    "    pt_model.norm3.weight.data = torch.from_numpy(norm_layers[2].get_weights()[0]); pt_model.norm3.bias.data = torch.from_numpy(norm_layers[2].get_weights()[1])\n",
    "\n",
    "    # --- Probabilistic Decoder ---\n",
    "    # TF Dense weights: (in_features, out_features)\n",
    "    # PT Linear weights: (out_features, in_features)\n",
    "    prob_dec_weights, prob_dec_bias = prob_dec_layer.time_distributer.get_weights()\n",
    "    pt_model.prob_decoder.loc_projection.weight.data = torch.from_numpy(prob_dec_weights.T)\n",
    "    pt_model.prob_decoder.loc_projection.bias.data = torch.from_numpy(prob_dec_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41c88136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_full_model_and_parts (__main__.TestVaDETranslation)\n",
      "Test the forward pass and helper methods of the VaDEPT class. ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferring weights for all VaDE components...\n",
      "  -> Transferring Encoder weights...\n",
      "  -> Transferring GMM Latent weights...\n",
      "  -> Transferring Decoder weights...\n",
      "Weight transfer complete.\n",
      "\n",
      "--- Testing Self-Contained VaDEPT Class Translation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_full_model_and_parts (__main__.TestVaDETranslation)\n",
      "Test the forward pass and helper methods of the VaDEPT class.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Petron\\AppData\\Local\\Temp\\ipykernel_16880\\2925459415.py\", line 130, in test_full_model_and_parts\n",
      "    pt_rec_dist, _, _, _ = self.pt_vade(x_pt, a_pt)\n",
      "  File \"c:\\Users\\Petron\\Desktop\\Python_Projects\\Deepof\\dof\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\Petron\\Desktop\\Python_Projects\\Deepof\\dof\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\Petron\\AppData\\Local\\Temp\\ipykernel_16880\\3492692028.py\", line 98, in forward\n",
      "    latent, categorical, _, _, kmeans_loss, gmm_params = self.latent_space(encoder_output)\n",
      "ValueError: too many values to unpack (expected 6)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 7.591s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=1 failures=0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports and Mocks from the previous response are assumed to be present\n",
    "import unittest\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "import time\n",
    "import deepof.clustering.models_new\n",
    "# End of Mocks\n",
    "\n",
    "\n",
    "def transfer_vade_class_weights(tf_vade_model, tf_decoder_model, pt_vade_model: VaDEPT):\n",
    "    \"\"\"\n",
    "    Transfers weights from a full TensorFlow VaDE model to the self-contained PyTorch VaDEPT class.\n",
    "    \"\"\"\n",
    "    print(\"Transferring weights for all VaDE components...\")\n",
    "    \n",
    "    # 1. Get the inner Keras models/layers by name from the complete TF model\n",
    "    tf_encoder_inner = tf_vade_model.get_layer(\"recurrent_encoder\")\n",
    "    tf_latent_layer = tf_vade_model.get_layer(\"gaussian_mixture_latent\")\n",
    "    \n",
    "    # 2. Use the specialized weight transfer functions, passing the PT sub-modules\n",
    "    print(\"  -> Transferring Encoder weights...\")\n",
    "    transfer_recurrent_encoder_weights(tf_encoder_inner, pt_vade_model.encoder)\n",
    "    print(\"  -> Transferring GMM Latent weights...\")\n",
    "    transfer_gmm_weights(tf_latent_layer, pt_vade_model.latent_space)\n",
    "    print(\"  -> Transferring Decoder weights...\")\n",
    "    transfer_recurrent_decoder_weights(tf_decoder_model, pt_vade_model.decoder)\n",
    "    \n",
    "    print(\"Weight transfer complete.\")\n",
    "\n",
    "\n",
    "class TestVaDETranslation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up parameters, models, and data for testing.\"\"\"\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.keras.backend.set_epsilon(1e-3)\n",
    "\n",
    "        # --- 1. Define Fundamental Dimensions ---\n",
    "        self.batch_size = 128\n",
    "        self.window_length = 25\n",
    "        self.num_nodes = 11\n",
    "        # In your example, total features (n=33) / num_nodes (11) = 3\n",
    "        self.features_per_node = 33\n",
    "        self.num_edges = 11\n",
    "        self.features_per_edge = 111 # Assuming 1 feature per edge\n",
    "\n",
    "        # --- 2. Define Model Parameters ---\n",
    "        self.latent_dim = 6\n",
    "        self.n_components = 10\n",
    "        self.kmeans_loss = 1.0\n",
    "        self.use_gnn = False\n",
    "\n",
    "        # --- 3. Create Adjacency Matrix ---\n",
    "        m = np.zeros((self.num_nodes, self.num_nodes))\n",
    "        ui = np.triu_indices(self.num_nodes)\n",
    "        num_possible_edges = len(ui[0])\n",
    "        c = np.random.choice(num_possible_edges, min(self.num_edges, num_possible_edges), replace=False)\n",
    "        m[ui[0][c], ui[1][c]] = 1\n",
    "        m += m.T # Make symmetric\n",
    "        self.adj_matrix = m\n",
    "\n",
    "        # --- 4. Create Framework-Specific Shapes for Model Instantiation ---\n",
    "        \n",
    "        # TensorFlow expects (batch, time, total_features)\n",
    "        self.input_shape_tf = (self.batch_size, self.window_length, self.num_nodes * self.features_per_node)\n",
    "        self.edge_feature_shape_tf = (self.batch_size, self.window_length, self.num_edges * self.features_per_edge)\n",
    "        \n",
    "        # PyTorch VaDEPT expects (time, nodes, features_per_node) for a SINGLE sample\n",
    "        self.input_shape_pt = (self.window_length, self.num_nodes, self.features_per_node)\n",
    "        self.edge_feature_shape_pt = (self.window_length, self.num_edges, self.features_per_edge)\n",
    "\n",
    "        # --- 5. Instantiate Models ---\n",
    "        self.tf_embedding, self.tf_decoder, self.tf_grouper, self.tf_vade = get_vade(\n",
    "            input_shape=self.input_shape_tf,\n",
    "            edge_feature_shape=self.edge_feature_shape_tf,\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=self.use_gnn,\n",
    "            n_components=self.n_components,\n",
    "            batch_size=self.batch_size,\n",
    "            kmeans_loss=self.kmeans_loss\n",
    "        )\n",
    "        \n",
    "        self.pt_vade = VaDEPT(\n",
    "            input_shape=self.input_shape_pt,\n",
    "            edge_feature_shape=self.edge_feature_shape_pt,\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            n_components=self.n_components,\n",
    "            use_gnn=self.use_gnn,\n",
    "            kmeans_loss=self.kmeans_loss\n",
    "        )\n",
    "        self.pt_vade.eval()\n",
    "\n",
    "        # --- 6. Prepare Data Tensors for Each Framework ---\n",
    "        np.random.seed(42)\n",
    "        # The \"canonical\" data is 4D, as expected by the new PyTorch models\n",
    "        self.x_np_4d = np.random.rand(\n",
    "            self.batch_size, self.window_length, self.num_nodes, self.features_per_node\n",
    "        ).astype(np.float32)\n",
    "        self.a_np_4d = np.random.rand(\n",
    "            self.batch_size, self.window_length, self.num_edges, self.features_per_edge\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        # Create the 3D version for the legacy TensorFlow model by reshaping\n",
    "        self.x_np_tf = self.x_np_4d.reshape(self.input_shape_tf)\n",
    "        self.a_np_tf = self.a_np_4d.reshape(self.edge_feature_shape_tf)\n",
    "        \n",
    "        # --- 7. Transfer Weights ---\n",
    "        transfer_vade_class_weights(self.tf_vade, self.tf_decoder, self.pt_vade)\n",
    "\n",
    "    def test_full_model_and_parts(self):\n",
    "        \"\"\"Test the forward pass and helper methods of the VaDEPT class.\"\"\"\n",
    "        print(\"\\n--- Testing Self-Contained VaDEPT Class Translation ---\")\n",
    "        \n",
    "        # --- TensorFlow Execution (with its required 3D input) ---\n",
    "        tf_start = time.time()\n",
    "        tf_rec_dist = self.tf_vade([self.x_np_tf, self.a_np_tf], training=False)\n",
    "        tf_rec_mean = tf_rec_dist.mean().numpy()\n",
    "        tf_lat_out = self.tf_embedding([self.x_np_tf, self.a_np_tf], training=False).numpy()\n",
    "        tf_cat_out = self.tf_grouper([self.x_np_tf, self.a_np_tf], training=False).numpy()\n",
    "        tf_end = time.time()\n",
    "        \n",
    "        # --- PyTorch Execution (with its required 4D input) ---\n",
    "        x_pt = torch.from_numpy(self.x_np_4d)\n",
    "        a_pt = torch.from_numpy(self.a_np_4d)\n",
    "        \n",
    "        pt_start = time.time()\n",
    "        with torch.no_grad():\n",
    "            pt_rec_dist, _, _, _ = self.pt_vade(x_pt, a_pt)\n",
    "            pt_rec_mean = pt_rec_dist.mean.numpy() \n",
    "            pt_lat_out = self.pt_vade.embed(x_pt, a_pt).numpy()\n",
    "            pt_cat_out = self.pt_vade.group(x_pt, a_pt).numpy()\n",
    "        pt_end = time.time()\n",
    "\n",
    "        print(f\"TensorFlow execution time: {tf_end - tf_start:.6f}s\")\n",
    "        print(f\"PyTorch execution time: {pt_end - pt_start:.6f}s\")\n",
    "        \n",
    "        # --- Assertions ---\n",
    "        print(\"\\nComparing latent space embeddings (from .embed() vs 'embedding' model)...\")\n",
    "        # Both outputs should be (batch_size, latent_dim), so (128, 6)\n",
    "        np.testing.assert_allclose(tf_lat_out, pt_lat_out, rtol=1e-5, atol=1e-4)\n",
    "        print(\"✅ Latent embeddings match.\")\n",
    "\n",
    "        print(\"Comparing categorical probabilities (from .group() vs 'grouper' model)...\")\n",
    "        # Both outputs should be (batch_size, n_components), so (128, 10)\n",
    "        np.testing.assert_allclose(tf_cat_out, pt_cat_out, rtol=1e-5, atol=1e-5)\n",
    "        print(\"✅ Categorical probabilities match.\")\n",
    "        \n",
    "        print(\"Comparing final reconstruction means (from forward() vs 'vade' model)...\")\n",
    "        # Both outputs should be (batch_size, time_steps, total_features), so (128, 25, 33)\n",
    "        np.testing.assert_allclose(tf_rec_mean, pt_rec_mean, rtol=1e-5, atol=1e-4)\n",
    "        print(\"✅ Reconstructions match.\")\n",
    "\n",
    "        print(\"\\n✅ Self-contained VaDEPT class translation test PASSED!\")\n",
    "\n",
    "# To run the test\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestVaDETranslation)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f3082a",
   "metadata": {},
   "source": [
    "# Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c33fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from typing import List, Tuple, Dict, Callable\n",
    "import time\n",
    "import deepof.model_utils\n",
    "from spektral.layers import CensNetConv\n",
    "from deepof.model_utils import ClusterControl, compute_kmeans_loss, ProbabilisticDecoder\n",
    "import deepof.models\n",
    "from deepof.models import get_recurrent_encoder, get_recurrent_decoder, GaussianMixtureLatent, get_TCN_encoder, get_TCN_decoder, get_transformer_encoder, get_transformer_decoder\n",
    "from deepof.clustering.models_new import RecurrentEncoderPT, RecurrentDecoderPT, GaussianMixtureLatentPT\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    LayerNormalization,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    ")\n",
    "\n",
    "from deepof.data_loading import get_dt\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e67e0726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VaDE(tf.keras.models.Model):\n",
    "    \"\"\"Gaussian Mixture Variational Autoencoder for pose motif elucidation.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: tuple,\n",
    "        edge_feature_shape: tuple,\n",
    "        adjacency_matrix: np.ndarray = None,\n",
    "        latent_dim: int = 8,\n",
    "        use_gnn: bool = True,\n",
    "        n_components: int = 15,\n",
    "        batch_size: int = 64,\n",
    "        kl_annealing_mode: str = \"linear\",\n",
    "        kl_warmup_epochs: int = 15,\n",
    "        montecarlo_kl: int = 100,\n",
    "        kmeans_loss: float = 1.0,\n",
    "        reg_cat_clusters: float = 1.0,\n",
    "        reg_cluster_variance: bool = False,\n",
    "        encoder_type: str = \"recurrent\",\n",
    "        interaction_regularization: float = 0.0,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Init a VaDE model.\n",
    "\n",
    "        Args:\n",
    "            input_shape (tuple): Shape of the input to the full model.\n",
    "            edge_feature_shape (tuple): shape of the edge feature matrix used for graph representations.\n",
    "            adjacency_matrix (np.ndarray): adjacency matrix of the connectivity graph to use.\n",
    "            batch_size (int): Batch size for training.\n",
    "            latent_dim (int): Dimensionality of the latent space.\n",
    "            use_gnn (bool): If True, the encoder uses a graph representation of the input, with coordinates and speeds as node attributes, and distances as edge attributes. If False, a regular 3D tensor is used as input.\n",
    "            kl_annealing_mode (str): Annealing mode for KL annealing. Can be one of 'linear' and 'sigmoid'.\n",
    "            kl_warmup_epochs (int): Number of epochs to warmup KL annealing.\n",
    "            montecarlo_kl (int): Number of Monte Carlo samples for KL divergence.\n",
    "            n_components (int): Number of mixture components in the latent space.\n",
    "            kmeans_loss (float): weight of the gram matrix regularization loss.\n",
    "            reg_cat_clusters (bool): whether to use the penalized uneven cluster membership in the latent space, by minimizing the KL divergence between cluster membership and a uniform categorical distribution.\n",
    "            reg_cluster_variance (bool): whether to penalize uneven cluster variances in the latent space.\n",
    "            encoder_type (str): type of encoder to use. Can be set to \"recurrent\" (default), \"TCN\", or \"transformer\".\n",
    "            interaction_regularization (float): Regularization parameter for the interaction features.\n",
    "            **kwargs: Additional keyword arguments.\n",
    "\n",
    "        \"\"\"\n",
    "        super(VaDE, self).__init__(**kwargs)\n",
    "        self.seq_shape = input_shape\n",
    "        self.edge_feature_shape = edge_feature_shape\n",
    "        self.adjacency_matrix = adjacency_matrix\n",
    "        self.batch_size = batch_size\n",
    "        self.latent_dim = latent_dim\n",
    "        self.use_gnn = use_gnn\n",
    "        self.kl_annealing_mode = kl_annealing_mode\n",
    "        self.kl_warmup = kl_warmup_epochs\n",
    "        self.mc_kl = montecarlo_kl\n",
    "        self.n_components = n_components\n",
    "        self.optimizer = Nadam(learning_rate=1e-3, clipvalue=0.75)\n",
    "        self.kmeans = kmeans_loss\n",
    "        self.reg_cat_clusters = reg_cat_clusters\n",
    "        self.reg_cluster_variance = reg_cluster_variance\n",
    "        self.encoder_type = encoder_type\n",
    "        self.interaction_regularization = interaction_regularization\n",
    "\n",
    "        # Define VaDE model\n",
    "        self.encoder, self.decoder, self.grouper, self.vade = deepof.models.get_vade(\n",
    "            input_shape=self.seq_shape,\n",
    "            edge_feature_shape=self.edge_feature_shape,\n",
    "            adjacency_matrix=self.adjacency_matrix,\n",
    "            n_components=self.n_components,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=use_gnn,\n",
    "            batch_size=self.batch_size,\n",
    "            kl_warmup=self.kl_warmup,\n",
    "            kl_annealing_mode=self.kl_annealing_mode,\n",
    "            mc_kl=self.mc_kl,\n",
    "            kmeans_loss=self.kmeans,\n",
    "            reg_cluster_variance=self.reg_cluster_variance,\n",
    "            encoder_type=self.encoder_type,\n",
    "            interaction_regularization=self.interaction_regularization,\n",
    "        )\n",
    "\n",
    "        # Propagate the optimizer to all relevant sub-models, to enable metric annealing\n",
    "        self.vade.optimizer = self.optimizer\n",
    "        self.vade.get_layer(\"gaussian_mixture_latent\").optimizer = self.optimizer\n",
    "\n",
    "        # Define metrics to track\n",
    "\n",
    "        # Track all loss function components\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.val_total_loss_tracker = tf.keras.metrics.Mean(name=\"val_total_loss\")\n",
    "\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.val_reconstruction_loss_tracker = tf.keras.metrics.Mean(\n",
    "            name=\"val_reconstruction_loss\"\n",
    "        )\n",
    "\n",
    "        if self.reg_cat_clusters:\n",
    "            self.cat_cluster_loss_tracker = tf.keras.metrics.Mean(\n",
    "                name=\"cat_cluster_loss\"\n",
    "            )\n",
    "            self.val_cat_cluster_loss_tracker = tf.keras.metrics.Mean(\n",
    "                name=\"val_cat_cluster_loss\"\n",
    "            )\n",
    "\n",
    "    @property\n",
    "    def metrics(self):  # pragma: no cover\n",
    "        \"\"\"Initializes tracked metrics of VaDE model.\"\"\"\n",
    "        metrics = [\n",
    "            self.total_loss_tracker,\n",
    "            self.val_total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.val_reconstruction_loss_tracker,\n",
    "        ]\n",
    "\n",
    "        if self.reg_cat_clusters:\n",
    "            metrics += [\n",
    "                self.cat_cluster_loss_tracker,\n",
    "                self.val_cat_cluster_loss_tracker,\n",
    "            ]\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    @property\n",
    "    def get_gmm_params(self):\n",
    "        \"\"\"Return the GMM parameters of the model.\"\"\"\n",
    "        # Get GMM parameters\n",
    "        return {\n",
    "            \"means\": self.grouper.get_layer(\"gaussian_mixture_latent\").c_mu,\n",
    "            \"sigmas\": tf.math.exp(\n",
    "                self.grouper.get_layer(\"gaussian_mixture_latent\").log_c_sigma\n",
    "            ),\n",
    "            \"weights\": tf.math.softmax(\n",
    "                self.grouper.get_layer(\"gaussian_mixture_latent\").prior\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def set_pretrain_mode(self, switch):\n",
    "        \"\"\"Set the pretrain mode of the model.\"\"\"\n",
    "        self.grouper.get_layer(\"gaussian_mixture_latent\").pretrain.assign(switch)\n",
    "\n",
    "    def pretrain(\n",
    "        self,\n",
    "        data,\n",
    "        embed_x,\n",
    "        embed_a,\n",
    "        epochs=10,\n",
    "        samples=10000,\n",
    "        gmm_initialize=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Run a GMM directed pretraining of the encoder, to minimize the likelihood of getting stuck in a local minimum.\"\"\"\n",
    "        # Turn on pretrain mode\n",
    "        self.set_pretrain_mode(1.0)\n",
    "\n",
    "        # pre-train\n",
    "        self.fit(\n",
    "            data,\n",
    "            epochs=epochs,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "\n",
    "        # Turn off pretrain mode\n",
    "        self.set_pretrain_mode(0.0)\n",
    "\n",
    "        if gmm_initialize:\n",
    "\n",
    "            with tf.device(\"CPU\"):\n",
    "                # Get embedding samples\n",
    "                em_x=get_dt(embed_x, 'embed_x')\n",
    "                em_a=get_dt(embed_a, 'embed_a')\n",
    "\n",
    "                emb_idx = np.random.choice(range(em_x.shape[0]), samples)\n",
    "\n",
    "                # map to latent\n",
    "                z = self.encoder([em_x[emb_idx], em_a[emb_idx]])\n",
    "                \n",
    "                del em_x\n",
    "                del em_a\n",
    "                del emb_idx\n",
    "\n",
    "                # fit GMM\n",
    "                gmm = deepof.models.GaussianMixture(\n",
    "                    n_components=self.n_components,\n",
    "                    covariance_type=\"diag\",\n",
    "                    reg_covar=1e-04,\n",
    "                    **kwargs,\n",
    "                ).fit(z)\n",
    "                # get GMM parameters\n",
    "                mu = gmm.means_\n",
    "                sigma2 = gmm.covariances_\n",
    "\n",
    "            # initialize mixture components\n",
    "            self.grouper.get_layer(\"gaussian_mixture_latent\").c_mu.assign(\n",
    "                tf.convert_to_tensor(value=mu, dtype=tf.float32)\n",
    "            )\n",
    "            self.grouper.get_layer(\"gaussian_mixture_latent\").log_c_sigma.assign(\n",
    "                tf.math.log(\n",
    "                    tf.math.sqrt(tf.convert_to_tensor(value=sigma2, dtype=tf.float32))\n",
    "                )\n",
    "            )\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\"Call the VaDE model.\"\"\"\n",
    "        return self.vade(inputs, **kwargs)\n",
    "\n",
    "    def train_step(self, data):  # pragma: no cover\n",
    "        \"\"\"Perform a training step.\"\"\"\n",
    "        # Unpack data, repacking labels into a generator\n",
    "        x, a, y = data\n",
    "        if not isinstance(y, tuple):\n",
    "            y = [y]\n",
    "        y = (labels for labels in y)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Get outputs from the full model\n",
    "            outputs = self.vade([x, a], training=True)\n",
    "\n",
    "            # Get rid of the attention scores that the transformer decoder outputs\n",
    "            if self.encoder_type == \"transformer\":\n",
    "                outputs = outputs[0]\n",
    "\n",
    "            if isinstance(outputs, list):\n",
    "                reconstructions = outputs[0]\n",
    "            else:\n",
    "                reconstructions = outputs\n",
    "\n",
    "            # Regularize embeddings\n",
    "            # groups = self.grouper(x, training=True)\n",
    "\n",
    "            # Compute losses\n",
    "            seq_inputs = next(y)\n",
    "            total_loss = sum(self.vade.losses)\n",
    "\n",
    "            # Add a regularization term to the soft_counts, to prevent the embedding layer from\n",
    "            # collapsing into a few clusters.\n",
    "            if self.reg_cat_clusters:\n",
    "\n",
    "                soft_counts = self.grouper([x, a], training=True)\n",
    "                soft_counts_regulrization = (\n",
    "                    self.reg_cat_clusters\n",
    "                    * deepof.model_utils.cluster_frequencies_regularizer(\n",
    "                        soft_counts=soft_counts, k=self.n_components\n",
    "                    )\n",
    "                )\n",
    "                total_loss += soft_counts_regulrization\n",
    "\n",
    "            # Compute reconstruction loss\n",
    "            reconstruction_loss = -tf.reduce_mean(reconstructions.log_prob(seq_inputs))\n",
    "            total_loss += reconstruction_loss\n",
    "\n",
    "        # Backpropagation\n",
    "        grads = tape.gradient(total_loss, self.vade.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.vade.trainable_variables))\n",
    "\n",
    "        # Track losses\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "\n",
    "        # Log results (coupled with TensorBoard)\n",
    "        log_dict = {\n",
    "            \"total_loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "        if self.reg_cat_clusters:\n",
    "            self.cat_cluster_loss_tracker.update_state(soft_counts_regulrization)\n",
    "            log_dict[\"cat_cluster_loss\"] = self.cat_cluster_loss_tracker.result()\n",
    "\n",
    "        # Log to TensorBoard, both explicitly and implicitly (within model) tracked metrics\n",
    "        return {**log_dict, **{met.name: met.result() for met in self.vade.metrics}}\n",
    "\n",
    "    # noinspection PyUnboundLocalVariable\n",
    "    @tf.function\n",
    "    def test_step(self, data):  # pragma: no cover\n",
    "        \"\"\"Performs a test step.\"\"\"\n",
    "        # Unpack data, repacking labels into a generator\n",
    "        x, a, y = data\n",
    "        if not isinstance(y, tuple):\n",
    "            y = [y]\n",
    "        y = (labels for labels in y)\n",
    "\n",
    "        # Get outputs from the full model\n",
    "        outputs = self.vade([x, a], training=False)\n",
    "\n",
    "        # Get rid of the attention scores that the transformer decoder outputs\n",
    "        if self.encoder_type == \"transformer\":\n",
    "            outputs = outputs[0]\n",
    "\n",
    "        if isinstance(outputs, list):\n",
    "            reconstructions = outputs[0]\n",
    "        else:\n",
    "            reconstructions = outputs\n",
    "\n",
    "        # Compute losses\n",
    "        seq_inputs = next(y)\n",
    "        total_loss = sum(self.vade.losses)\n",
    "\n",
    "        # Add a regularization term to the soft_counts, to prevent the embedding layer from\n",
    "        # collapsing into a few clusters.\n",
    "        if self.reg_cat_clusters:\n",
    "            soft_counts = self.grouper([x, a], training=False)\n",
    "            soft_counts_regulrization = (\n",
    "                self.reg_cat_clusters\n",
    "                * deepof.model_utils.cluster_frequencies_regularizer(\n",
    "                    soft_counts=soft_counts, k=self.n_components\n",
    "                )\n",
    "            )\n",
    "            total_loss += soft_counts_regulrization\n",
    "\n",
    "        # Compute reconstruction loss\n",
    "        reconstruction_loss = -tf.reduce_mean(reconstructions.log_prob(seq_inputs))\n",
    "        total_loss += reconstruction_loss\n",
    "\n",
    "        # Track losses\n",
    "        self.val_total_loss_tracker.update_state(total_loss)\n",
    "        self.val_reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "\n",
    "        # Log results (coupled with TensorBoard)\n",
    "        log_dict = {\n",
    "            \"total_loss\": self.val_total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.val_reconstruction_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "        if self.reg_cat_clusters:\n",
    "            self.val_cat_cluster_loss_tracker.update_state(soft_counts_regulrization)\n",
    "            log_dict[\"cat_cluster_loss\"] = self.val_cat_cluster_loss_tracker.result()\n",
    "\n",
    "        return {**log_dict, **{met.name: met.result() for met in self.vade.metrics}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57b5b1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VaDEPT(nn.Module):\n",
    "    \"\"\"\n",
    "    A self-contained PyTorch implementation of the VaDE model.\n",
    "\n",
    "    This class encapsulates the entire VaDE architecture, including the encoder,\n",
    "    the Gaussian mixture latent space, and the decoder. It is instantiated with\n",
    "    all necessary configuration parameters, building its sub-modules internally.\n",
    "    This provides a clean, single-object interface for the model.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: tuple,\n",
    "        edge_feature_shape: tuple,\n",
    "        adjacency_matrix: np.ndarray,\n",
    "        latent_dim: int,\n",
    "        n_components: int,\n",
    "        use_gnn: bool = True,\n",
    "        kmeans_loss: float = 1.0,\n",
    "        interaction_regularization: float = 0.0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes and builds the VaDE model and its components.\n",
    "\n",
    "        Args:\n",
    "            input_shape (tuple): Shape of the input node features (Time, Nodes, Features_per_node).\n",
    "            edge_feature_shape (tuple): Shape of the edge features (Time, Edges, Features_per_edge).\n",
    "            adjacency_matrix (np.ndarray): Adjacency matrix of the connectivity graph.\n",
    "            latent_dim (int): Dimensionality of the latent space.\n",
    "            n_components (int): Number of components in the Gaussian mixture.\n",
    "            use_gnn (bool): If True, use the GNN-based encoder.\n",
    "            kmeans_loss (float): Weight of the k-means style loss in the latent space.\n",
    "            interaction_regularization (float): Regularization for GNN interaction features.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        # Store key dimensions for internal use (e.g., reshaping in forward pass)\n",
    "        time_steps, n_nodes, n_features_per_node = input_shape\n",
    "        self.input_n_nodes = n_nodes\n",
    "        self.input_n_features_per_node = n_features_per_node\n",
    "\n",
    "        # 1. Instantiate Encoder\n",
    "        self.encoder = RecurrentEncoderPT(\n",
    "            input_shape=input_shape,\n",
    "            edge_feature_shape=edge_feature_shape,\n",
    "            adjacency_matrix=adjacency_matrix,\n",
    "            latent_dim=latent_dim,\n",
    "            use_gnn=use_gnn,\n",
    "            interaction_regularization=interaction_regularization,\n",
    "        )\n",
    "\n",
    "        # 2. Instantiate Latent Space\n",
    "        self.latent_space = GaussianMixtureLatentPT(\n",
    "            input_dim=latent_dim,\n",
    "            n_components=n_components,\n",
    "            latent_dim=latent_dim,\n",
    "            kmeans=kmeans_loss,\n",
    "        )\n",
    "\n",
    "        # 3. Instantiate Decoder\n",
    "        decoder_output_features = n_nodes * n_features_per_node\n",
    "        self.decoder = RecurrentDecoderPT(\n",
    "            output_shape=(time_steps, decoder_output_features),\n",
    "            latent_dim=latent_dim,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, x: torch.Tensor, a: torch.Tensor\n",
    "    ) -> Tuple[torch.distributions.Distribution, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Defines the full forward pass for the VaDE model (training and evaluation).\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input node features tensor (B, T, N, F_node).\n",
    "            a (torch.Tensor): Input edge features tensor (B, T, E, F_edge).\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing:\n",
    "            - reconstruction_dist (torch.distributions.Distribution): The output distribution from the decoder.\n",
    "            - latent (torch.Tensor): The sampled latent representation from the GMM space.\n",
    "            - categorical (torch.Tensor): The cluster probabilities (soft assignments).\n",
    "            - kmeans_loss (torch.Tensor): The k-means regularization loss from the latent space.\n",
    "        \"\"\"\n",
    "        # 1. Encode the input to get the pre-latent representation\n",
    "        encoder_output = self.encoder(x, a)\n",
    "        \n",
    "        # 2. Pass through GMM latent space\n",
    "        latent, categorical, _, _, kmeans_loss, _ = self.latent_space(encoder_output)\n",
    "        \n",
    "        # 3. Decode the latent sample back to the original data space\n",
    "        # Reshape x to (B, T, N*F) for the decoder's masking logic\n",
    "        B, T, _, _ = x.shape\n",
    "        x_for_decoder = x.view(B, T, self.input_n_nodes * self.input_n_features_per_node)\n",
    "        \n",
    "        reconstruction_dist = self.decoder(latent, x_for_decoder)\n",
    "        \n",
    "        return reconstruction_dist, latent, categorical, kmeans_loss\n",
    "    \n",
    "\n",
    "    def get_gmm_params(self) -> dict:\n",
    "        \"\"\"Returns the GMM parameters from the latent space.\"\"\"\n",
    "        # This is the PyTorch equivalent of the TF property\n",
    "        with torch.no_grad():\n",
    "            means = self.latent_space.gmm_means\n",
    "            # The latent space stores log-variances, convert to std-dev\n",
    "            stds = torch.exp(0.5 * self.latent_space.gmm_log_vars)\n",
    "            # Prior is already softmaxed if needed, or just probabilities\n",
    "            weights = self.latent_space.prior\n",
    "        return {\"means\": means, \"stds\": stds, \"weights\": weights}\n",
    "\n",
    "\n",
    "    def set_pretrain_mode(self, pretrain_on: bool):\n",
    "        \"\"\"Sets the pretrain flag in the latent space.\"\"\"\n",
    "        # In TF it was a float (0.0/1.0), here a boolean is cleaner\n",
    "        self.latent_space.pretrain.fill_(1.0 if pretrain_on else 0.0)\n",
    "\n",
    "\n",
    "    def initialize_gmm_from_data(self, data_loader, n_samples=10000):\n",
    "        \"\"\"\n",
    "        Runs the autoencoder part of the model over the data to get embeddings,\n",
    "        then fits a scikit-learn GMM to initialize the latent space.\n",
    "        \"\"\"\n",
    "        print(\"Initializing GMM from data embeddings...\")\n",
    "        self.eval() # Set model to evaluation mode\n",
    "        \n",
    "        # 1. Gather embeddings from the autoencoder\n",
    "        all_embeddings = []\n",
    "        samples_gathered = 0\n",
    "        with torch.no_grad():\n",
    "            for x, a in data_loader:\n",
    "                # Assuming x,a are on the correct device\n",
    "                embeddings = self.encoder(x, a)\n",
    "                all_embeddings.append(embeddings.cpu())\n",
    "                samples_gathered += embeddings.size(0)\n",
    "                if samples_gathered >= n_samples:\n",
    "                    break\n",
    "        \n",
    "        all_embeddings = torch.cat(all_embeddings, dim=0).numpy()\n",
    "        if all_embeddings.shape[0] > n_samples:\n",
    "            all_embeddings = all_embeddings[:n_samples]\n",
    "\n",
    "        # 2. Fit a scikit-learn GMM\n",
    "        from sklearn.mixture import GaussianMixture\n",
    "        print(f\"Fitting scikit-learn GMM on {all_embeddings.shape[0]} samples...\")\n",
    "        gmm = GaussianMixture(\n",
    "            n_components=self.latent_space.n_components,\n",
    "            covariance_type=\"diag\",\n",
    "            reg_covar=1e-04,\n",
    "        ).fit(all_embeddings)\n",
    "\n",
    "        # 3. Assign the learned parameters to the model's latent space\n",
    "        print(\"Assigning learned GMM parameters to the model.\")\n",
    "        self.latent_space.gmm_means.data = torch.from_numpy(gmm.means_).float()\n",
    "        # Convert covariance (variance) to log-variance for the model\n",
    "        self.latent_space.gmm_log_vars.data = torch.from_numpy(np.log(gmm.covariances_)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc113fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_recurrent_block_weights(tf_model, pt_model):\n",
    "    \"\"\"Transfers weights for the full recurrent block with GRU gate permutation.\"\"\"\n",
    "    conv_td, _, gru1_td, norm1, gru2_td, norm2 = tf_model.layers[1:]\n",
    "\n",
    "\n",
    "    def permute_gru_weights(keras_weights):\n",
    "        W_ih, W_hh, B = keras_weights\n",
    "        W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "        W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "        W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "        W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "        B_ih, B_hh = B\n",
    "        B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "        B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "        B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "        B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "        return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_td.layer.get_weights()[0]).permute(2, 1, 0)\n",
    "    \n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(gru1_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1); pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    \n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(gru1_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1); pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm1.get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm1.get_weights()[1])\n",
    "\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(gru2_td.layer.forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2); pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    \n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(gru2_td.layer.backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2); pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    \n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm2.get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm2.get_weights()[1])\n",
    "\n",
    "    \n",
    "def transfer_censnet_weights(tf_layer, pt_layer):\n",
    "    \"\"\"\n",
    "    Transfers all six weights from a Spektral CensNetConv layer to the\n",
    "    corresponding CensNetConvPT layer.\n",
    "    \"\"\"\n",
    "    # Get all weights from the TensorFlow layer. The order is determined by\n",
    "    # the layer's build order in Spektral's source code.\n",
    "    tf_weights = tf_layer.get_weights()\n",
    "\n",
    "    # Unpack all six weights.\n",
    "    # Order: kernel_node, bias_node, kernel_edge, bias_edge, projector_node, projector_edge\n",
    "    kn_tf, bn_tf, ke_tf, be_tf, pn_tf, pe_tf = tf_weights\n",
    "\n",
    "    # Build weights on first pass\n",
    "    if pt_layer.node_kernel is None:\n",
    "        # Move parameters to the same device as input tensors\n",
    "        pt_layer._build(kn_tf.T.shape, bn_tf.T.shape)\n",
    "        #pt_layer.to(kn_tf.device)\n",
    "\n",
    "    # 1. & 2. Transfer Node Kernel and Bias\n",
    "    # Keras Dense kernel is (in_features, out_features)\n",
    "    pt_layer.node_kernel.data = torch.from_numpy(kn_tf)\n",
    "    pt_layer.edge_kernel.data = torch.from_numpy(bn_tf)\n",
    "\n",
    "    # 3. & 4. Transfer Edge Kernel and Bias\n",
    "    # Same transposition logic applies.\n",
    "    pt_layer.node_weights.data = torch.from_numpy(ke_tf)\n",
    "    pt_layer.edge_weights.data = torch.from_numpy(be_tf)\n",
    "\n",
    "    # 5. Transfer Node Projector Weights (P_n)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.node_bias.data = torch.from_numpy(pn_tf)\n",
    "\n",
    "    # 6. Transfer Edge Projector Weights (P_e)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.edge_bias.data = torch.from_numpy(pe_tf)\n",
    "    \n",
    "\n",
    "def transfer_recurrent_encoder_weights(tf_model, pt_model):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full recurrent encoder, finding layers\n",
    "    by their default names and types to avoid modifying original code.\n",
    "    \"\"\"\n",
    "    # The final dense layer is consistently the last one in the model's layer list.\n",
    "    final_dense_tf = tf_model.layers[-1]\n",
    "    final_dense_pt = pt_model.final_dense\n",
    "    w, b = final_dense_tf.get_weights()\n",
    "    final_dense_pt.weight.data = torch.from_numpy(w.T)\n",
    "    final_dense_pt.bias.data = torch.from_numpy(b)\n",
    "\n",
    "    if pt_model.use_gnn:\n",
    "        # Keras automatically names nested models 'model', 'model_1', etc., by order of creation.\n",
    "        # Node recurrent block is created first.\n",
    "        node_recurrent_model = tf_model.get_layer(\"model\")\n",
    "        # Edge recurrent block is created second.\n",
    "        edge_recurrent_model = tf_model.get_layer(\"model_1\")\n",
    "        # Find the CensNetConv layer by its class type.\n",
    "        gnn_layer = next(l for l in tf_model.layers if isinstance(l, CensNetConv))\n",
    "\n",
    "        transfer_recurrent_block_weights(node_recurrent_model, pt_model.node_recurrent_block)\n",
    "        transfer_recurrent_block_weights(edge_recurrent_model, pt_model.edge_recurrent_block)\n",
    "        transfer_censnet_weights(gnn_layer, pt_model.spatial_gnn_block)\n",
    "    else: # Not using GNN\n",
    "        # There is only one nested model, which Keras names 'model'.\n",
    "        recurrent_model = tf_model.get_layer(\"model\")\n",
    "        transfer_recurrent_block_weights(recurrent_model, pt_model.recurrent_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "822b9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_gmm_weights(tf_model, pt_model: GaussianMixtureLatentPT):\n",
    "    \"\"\"\n",
    "    Transfers weights from the final TF model to the refactored PT model,\n",
    "    using the updated attribute names.\n",
    "    \"\"\"\n",
    "    # --- Transfer GMM component parameters ---\n",
    "    # OLD: pt_model.c_mu\n",
    "    pt_model.gmm_means.data = torch.from_numpy(tf_model.c_mu.numpy())\n",
    "    # OLD: pt_model.log_c_sigma\n",
    "    pt_model.gmm_log_vars.data = torch.from_numpy(tf_model.log_c_sigma.numpy())\n",
    "\n",
    "    # --- Transfer Encoder layer parameters ---\n",
    "    tf_mean_weights = tf_model.z_gauss_mean.get_weights()\n",
    "    # OLD: pt_model.z_gauss_mean\n",
    "    pt_model.encoder_mean.weight.data = torch.from_numpy(tf_mean_weights[0].T)\n",
    "    pt_model.encoder_mean.bias.data = torch.from_numpy(tf_mean_weights[1])\n",
    "    \n",
    "    tf_var_weights = tf_model.z_gauss_var.get_weights()\n",
    "    # OLD: pt_model.z_gauss_var\n",
    "    pt_model.encoder_log_var.weight.data = torch.from_numpy(tf_var_weights[0].T)\n",
    "    pt_model.encoder_log_var.bias.data = torch.from_numpy(tf_var_weights[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0e8cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function from the provided example to handle gate order differences\n",
    "def permute_gru_weights(keras_weights):\n",
    "    \"\"\"Permutes GRU weights from Keras (z, r, n) to PyTorch (r, z, n) format.\"\"\"\n",
    "    W_ih, W_hh, B = keras_weights\n",
    "    # Keras gate order: z, r, n (update, reset, new/candidate)\n",
    "    W_ih_z, W_ih_r, W_ih_n = np.split(W_ih, 3, axis=1)\n",
    "    W_hh_z, W_hh_r, W_hh_n = np.split(W_hh, 3, axis=1)\n",
    "\n",
    "    # PyTorch gate order: r, z, n (reset, update, new/candidate)\n",
    "    W_ih_pt = np.concatenate([W_ih_r, W_ih_z, W_ih_n], axis=1)\n",
    "    W_hh_pt = np.concatenate([W_hh_r, W_hh_z, W_hh_n], axis=1)\n",
    "\n",
    "    # Keras has two bias vectors (input-hidden and recurrent), which are concatenated in B\n",
    "    B_ih, B_hh = B\n",
    "    B_ih_z, B_ih_r, B_ih_n = np.split(B_ih, 3)\n",
    "    B_hh_z, B_hh_r, B_hh_n = np.split(B_hh, 3)\n",
    "\n",
    "    B_ih_pt = np.concatenate([B_ih_r, B_ih_z, B_ih_n])\n",
    "    B_hh_pt = np.concatenate([B_hh_r, B_hh_z, B_hh_n])\n",
    "\n",
    "    return W_ih_pt.T, W_hh_pt.T, B_ih_pt, B_hh_pt\n",
    "    \n",
    "def transfer_recurrent_decoder_weights(tf_model, pt_model):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full recurrent decoder model.\n",
    "    \"\"\"\n",
    "    # Find layers by type to avoid index issues\n",
    "    bidi_layers = [l for l in tf_model.layers if isinstance(l, Bidirectional)]\n",
    "    norm_layers = [l for l in tf_model.layers if isinstance(l, LayerNormalization)]\n",
    "    conv_layers = [l for l in tf_model.layers if isinstance(l, tf.keras.layers.Conv1D)]\n",
    "    prob_dec_layer = next(l for l in tf_model.layers if isinstance(l, deepof.model_utils.ProbabilisticDecoder))\n",
    "\n",
    "    # --- GRU 1 and Norm 1 ---\n",
    "    W_ih_f1, W_hh_f1, B_ih_f1, B_hh_f1 = permute_gru_weights(bidi_layers[0].forward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0.data = torch.from_numpy(W_ih_f1); pt_model.gru1.weight_hh_l0.data = torch.from_numpy(W_hh_f1)\n",
    "    pt_model.gru1.bias_ih_l0.data = torch.from_numpy(B_ih_f1); pt_model.gru1.bias_hh_l0.data = torch.from_numpy(B_hh_f1)\n",
    "    W_ih_b1, W_hh_b1, B_ih_b1, B_hh_b1 = permute_gru_weights(bidi_layers[0].backward_layer.get_weights())\n",
    "    pt_model.gru1.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b1); pt_model.gru1.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b1)\n",
    "    pt_model.gru1.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b1); pt_model.gru1.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b1)\n",
    "    pt_model.norm1.weight.data = torch.from_numpy(norm_layers[0].get_weights()[0]); pt_model.norm1.bias.data = torch.from_numpy(norm_layers[0].get_weights()[1])\n",
    "\n",
    "    # --- GRU 2 and Norm 2 ---\n",
    "    W_ih_f2, W_hh_f2, B_ih_f2, B_hh_f2 = permute_gru_weights(bidi_layers[1].forward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0.data = torch.from_numpy(W_ih_f2); pt_model.gru2.weight_hh_l0.data = torch.from_numpy(W_hh_f2)\n",
    "    pt_model.gru2.bias_ih_l0.data = torch.from_numpy(B_ih_f2); pt_model.gru2.bias_hh_l0.data = torch.from_numpy(B_hh_f2)\n",
    "    W_ih_b2, W_hh_b2, B_ih_b2, B_hh_b2 = permute_gru_weights(bidi_layers[1].backward_layer.get_weights())\n",
    "    pt_model.gru2.weight_ih_l0_reverse.data = torch.from_numpy(W_ih_b2); pt_model.gru2.weight_hh_l0_reverse.data = torch.from_numpy(W_hh_b2)\n",
    "    pt_model.gru2.bias_ih_l0_reverse.data = torch.from_numpy(B_ih_b2); pt_model.gru2.bias_hh_l0_reverse.data = torch.from_numpy(B_hh_b2)\n",
    "    pt_model.norm2.weight.data = torch.from_numpy(norm_layers[1].get_weights()[0]); pt_model.norm2.bias.data = torch.from_numpy(norm_layers[1].get_weights()[1])\n",
    "\n",
    "    # --- Conv1D and Norm 3 ---\n",
    "    # TF Conv1D weights: (kernel_w, kernel_h, in_c, out_c) -> (5, 1, 4*ld, 2*ld)\n",
    "    # PT Conv1d weights: (out_c, in_c, kernel_w)\n",
    "    conv_weights_tf = conv_layers[0].get_weights()[0]\n",
    "    pt_model.conv1d.weight.data = torch.from_numpy(conv_weights_tf).squeeze(1).permute(2, 1, 0)\n",
    "    pt_model.norm3.weight.data = torch.from_numpy(norm_layers[2].get_weights()[0]); pt_model.norm3.bias.data = torch.from_numpy(norm_layers[2].get_weights()[1])\n",
    "\n",
    "    # --- Probabilistic Decoder ---\n",
    "    # TF Dense weights: (in_features, out_features)\n",
    "    # PT Linear weights: (out_features, in_features)\n",
    "    prob_dec_weights, prob_dec_bias = prob_dec_layer.time_distributer.get_weights()\n",
    "    pt_model.prob_decoder.loc_projection.weight.data = torch.from_numpy(prob_dec_weights.T)\n",
    "    pt_model.prob_decoder.loc_projection.bias.data = torch.from_numpy(prob_dec_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cf27b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_full_model_and_parts (__main__.TestVaDETranslation)\n",
      "Test the forward pass and helper methods of the VaDEPT class. ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferring weights for all VaDE components...\n",
      "  -> Transferring Encoder weights...\n",
      "  -> Transferring GMM Latent weights...\n",
      "  -> Transferring Decoder weights...\n",
      "Weight transfer complete.\n",
      "\n",
      "--- Testing Self-Contained VaDEPT Class Translation ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_full_model_and_parts (__main__.TestVaDETranslation)\n",
      "Test the forward pass and helper methods of the VaDEPT class.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Petron\\AppData\\Local\\Temp\\ipykernel_16880\\1105766262.py\", line 124, in test_full_model_and_parts\n",
      "    pt_rec_dist, _, _, _ = self.pt_vade(x_pt, a_pt)\n",
      "  File \"c:\\Users\\Petron\\Desktop\\Python_Projects\\Deepof\\dof\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1773, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"c:\\Users\\Petron\\Desktop\\Python_Projects\\Deepof\\dof\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1784, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"C:\\Users\\Petron\\AppData\\Local\\Temp\\ipykernel_16880\\2086274447.py\", line 87, in forward\n",
      "    latent, categorical, _, _, kmeans_loss, _ = self.latent_space(encoder_output)\n",
      "ValueError: too many values to unpack (expected 6)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 7.602s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=1 failures=0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transfer_vade_class_weights(tf_vade_model, tf_decoder_model, pt_vade_model: VaDEPT):\n",
    "    \"\"\"\n",
    "    Transfers weights from a full TensorFlow VaDE model to the self-contained PyTorch VaDEPT class.\n",
    "    \"\"\"\n",
    "    print(\"Transferring weights for all VaDE components...\")\n",
    "    \n",
    "    # 1. Get the inner Keras models/layers by name from the complete TF model\n",
    "    tf_encoder_inner = tf_vade_model.get_layer(\"recurrent_encoder\")\n",
    "    tf_latent_layer = tf_vade_model.get_layer(\"gaussian_mixture_latent\")\n",
    "    \n",
    "    # 2. Use the specialized weight transfer functions, passing the PT sub-modules\n",
    "    print(\"  -> Transferring Encoder weights...\")\n",
    "    transfer_recurrent_encoder_weights(tf_encoder_inner, pt_vade_model.encoder)\n",
    "    print(\"  -> Transferring GMM Latent weights...\")\n",
    "    transfer_gmm_weights(tf_latent_layer, pt_vade_model.latent_space)\n",
    "    print(\"  -> Transferring Decoder weights...\")\n",
    "    transfer_recurrent_decoder_weights(tf_decoder_model, pt_vade_model.decoder)\n",
    "    \n",
    "    print(\"Weight transfer complete.\")\n",
    "\n",
    "\n",
    "class TestVaDETranslation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        \"\"\"Set up parameters, models, and data for testing.\"\"\"\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf.keras.backend.set_epsilon(1e-3)\n",
    "\n",
    "        # --- 1. Define Fundamental Dimensions ---\n",
    "        self.batch_size = 128\n",
    "        self.window_length = 25\n",
    "        self.num_nodes = 11\n",
    "        # In your example, total features (n=33) / num_nodes (11) = 3\n",
    "        self.features_per_node = 3\n",
    "        self.num_edges = 11\n",
    "        self.features_per_edge = 1 # Assuming 1 feature per edge\n",
    "\n",
    "        # --- 2. Define Model Parameters ---\n",
    "        self.latent_dim = 6\n",
    "        self.n_components = 10\n",
    "        self.kmeans_loss = 1.0\n",
    "        self.use_gnn = False\n",
    "\n",
    "        # --- 3. Create Adjacency Matrix ---\n",
    "        m = np.zeros((self.num_nodes, self.num_nodes))\n",
    "        ui = np.triu_indices(self.num_nodes)\n",
    "        num_possible_edges = len(ui[0])\n",
    "        c = np.random.choice(num_possible_edges, min(self.num_edges, num_possible_edges), replace=False)\n",
    "        m[ui[0][c], ui[1][c]] = 1\n",
    "        m += m.T # Make symmetric\n",
    "        self.adj_matrix = m\n",
    "\n",
    "        # --- 4. Create Framework-Specific Shapes for Model Instantiation ---\n",
    "        \n",
    "        # TensorFlow expects (batch, time, total_features)\n",
    "        self.input_shape_tf = (self.batch_size, self.window_length, self.num_nodes * self.features_per_node)\n",
    "        self.edge_feature_shape_tf = (self.batch_size, self.window_length, self.num_edges * self.features_per_edge)\n",
    "        \n",
    "        # PyTorch VaDEPT expects (time, nodes, features_per_node) for a SINGLE sample\n",
    "        self.input_shape_pt = (self.window_length, self.num_nodes, self.features_per_node)\n",
    "        self.edge_feature_shape_pt = (self.window_length, self.num_edges, self.features_per_edge)\n",
    "\n",
    "        # --- 5. Instantiate Models ---\n",
    "        tf_model = VaDE(\n",
    "            input_shape=self.input_shape_tf,\n",
    "            edge_feature_shape=self.edge_feature_shape_tf,\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=self.use_gnn,\n",
    "            n_components=self.n_components,\n",
    "            batch_size=self.batch_size,\n",
    "            kmeans_loss=self.kmeans_loss\n",
    "        )\n",
    "        self.tf_decoder = tf_model.decoder\n",
    "        self.tf_vade = tf_model.vade\n",
    "        self.tf_embedding = tf_model.encoder\n",
    "        self.tf_grouper = tf_model.grouper\n",
    "        \n",
    "        self.pt_vade = VaDEPT(\n",
    "            input_shape=self.input_shape_pt,\n",
    "            edge_feature_shape=self.edge_feature_shape_pt,\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            n_components=self.n_components,\n",
    "            use_gnn=self.use_gnn,\n",
    "            kmeans_loss=self.kmeans_loss\n",
    "        )\n",
    "        self.pt_vade.eval()\n",
    "\n",
    "        # --- 6. Prepare Data Tensors for Each Framework ---\n",
    "        np.random.seed(42)\n",
    "        # The \"canonical\" data is 4D, as expected by the new PyTorch models\n",
    "        self.x_np_4d = np.random.rand(\n",
    "            self.batch_size, self.window_length, self.num_nodes, self.features_per_node\n",
    "        ).astype(np.float32)\n",
    "        self.a_np_4d = np.random.rand(\n",
    "            self.batch_size, self.window_length, self.num_edges, self.features_per_edge\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        # Create the 3D version for the legacy TensorFlow model by reshaping\n",
    "        self.x_np_tf = self.x_np_4d.reshape(self.input_shape_tf)\n",
    "        self.a_np_tf = self.a_np_4d.reshape(self.edge_feature_shape_tf)\n",
    "        \n",
    "        # --- 7. Transfer Weights ---\n",
    "        transfer_vade_class_weights(self.tf_vade, self.tf_decoder, self.pt_vade)\n",
    "\n",
    "    def test_full_model_and_parts(self):\n",
    "        \"\"\"Test the forward pass and helper methods of the VaDEPT class.\"\"\"\n",
    "        print(\"\\n--- Testing Self-Contained VaDEPT Class Translation ---\")\n",
    "        \n",
    "        # --- TensorFlow Execution (with its required 3D input) ---\n",
    "        tf_start = time.time()\n",
    "        tf_rec_dist = self.tf_vade([self.x_np_tf, self.a_np_tf], training=False)\n",
    "        tf_rec_mean = tf_rec_dist.mean().numpy()\n",
    "        tf_lat_out = self.tf_embedding([self.x_np_tf, self.a_np_tf], training=False).numpy()\n",
    "        tf_cat_out = self.tf_grouper([self.x_np_tf, self.a_np_tf], training=False).numpy()\n",
    "        tf_end = time.time()\n",
    "        \n",
    "        # --- PyTorch Execution (with its required 4D input) ---\n",
    "        x_pt = torch.from_numpy(self.x_np_4d)\n",
    "        a_pt = torch.from_numpy(self.a_np_4d)\n",
    "        \n",
    "        pt_start = time.time()\n",
    "        with torch.no_grad():\n",
    "            pt_rec_dist, _, _, _ = self.pt_vade(x_pt, a_pt)\n",
    "            pt_rec_mean = pt_rec_dist.mean.numpy() \n",
    "            pt_lat_out = self.pt_vade.embed(x_pt, a_pt).numpy()\n",
    "            pt_cat_out = self.pt_vade.group(x_pt, a_pt).numpy()\n",
    "        pt_end = time.time()\n",
    "\n",
    "        print(f\"TensorFlow execution time: {tf_end - tf_start:.6f}s\")\n",
    "        print(f\"PyTorch execution time: {pt_end - pt_start:.6f}s\")\n",
    "        \n",
    "        # --- Assertions ---\n",
    "        print(\"\\nComparing latent space embeddings (from .embed() vs 'embedding' model)...\")\n",
    "        # Both outputs should be (batch_size, latent_dim), so (128, 6)\n",
    "        np.testing.assert_allclose(tf_lat_out, pt_lat_out, rtol=1e-5, atol=1e-4)\n",
    "        print(\"✅ Latent embeddings match.\")\n",
    "\n",
    "        print(\"Comparing categorical probabilities (from .group() vs 'grouper' model)...\")\n",
    "        # Both outputs should be (batch_size, n_components), so (128, 10)\n",
    "        np.testing.assert_allclose(tf_cat_out, pt_cat_out, rtol=1e-5, atol=1e-5)\n",
    "        print(\"✅ Categorical probabilities match.\")\n",
    "        \n",
    "        print(\"Comparing final reconstruction means (from forward() vs 'vade' model)...\")\n",
    "        # Both outputs should be (batch_size, time_steps, total_features), so (128, 25, 33)\n",
    "        np.testing.assert_allclose(tf_rec_mean, pt_rec_mean, rtol=1e-5, atol=1e-4)\n",
    "        print(\"✅ Reconstructions match.\")\n",
    "\n",
    "        print(\"\\n✅ Self-contained VaDEPT class translation test PASSED!\")\n",
    "\n",
    "# To run the test\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestVaDETranslation)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c1c84",
   "metadata": {},
   "source": [
    "# TCN encoder test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "874077da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple, Optional\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from spektral.layers import CensNetConv\n",
    "from deepof.clustering.censNetConv_pt import CensNetConvPT\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Bidirectional, GRU, LayerNormalization, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    LayerNormalization,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    ")\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import tcn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c117294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TCN_encoder(\n",
    "    input_shape: tuple,\n",
    "    edge_feature_shape: tuple,\n",
    "    adjacency_matrix: np.ndarray,\n",
    "    latent_dim: int,\n",
    "    use_gnn: bool = True,\n",
    "    conv_filters: int = 32,\n",
    "    kernel_size: int = 4,\n",
    "    conv_stacks: int = 2,\n",
    "    conv_dilations: tuple = (1, 2, 4, 8),\n",
    "    padding: str = \"causal\",\n",
    "    use_skip_connections: bool = True,\n",
    "    dropout_rate: int = 0,\n",
    "    activation: str = \"relu\",\n",
    "    interaction_regularization: float = 0.0,\n",
    "):\n",
    "    \"\"\"Return a Temporal Convolutional Network (TCN) encoder.\n",
    "\n",
    "    Builds a neural network that can be used to encode motion tracking instances into a\n",
    "    vector. Each layer contains a residual block with a convolutional layer and a skip connection. See the following\n",
    "    paper for more details: https://arxiv.org/pdf/1803.01271.pdf\n",
    "\n",
    "    Args:\n",
    "        input_shape: shape of the input data\n",
    "        edge_feature_shape (tuple): shape of the adjacency matrix to use in the graph attention layers. Should be time x edges x features.\n",
    "        adjacency_matrix (np.ndarray): adjacency matrix for the mice connectivity graph. Shape should be nodes x nodes.\n",
    "        latent_dim: dimensionality of the latent space\n",
    "        use_gnn (bool): If True, the encoder uses a graph representation of the input, with coordinates and speeds as node attributes, and distances as edge attributes. If False, a regular 3D tensor is used as input.\n",
    "        conv_filters: number of filters in the TCN layers\n",
    "        kernel_size: size of the convolutional kernels\n",
    "        conv_stacks: number of TCN layers\n",
    "        conv_dilations: list of dilation factors for each TCN layer\n",
    "        padding: padding mode for the TCN layers\n",
    "        use_skip_connections: whether to use skip connections between TCN layers\n",
    "        dropout_rate: dropout rate for the TCN layers\n",
    "        activation: activation function for the TCN layers\n",
    "        interaction_regularization (float): Regularization parameter for the interaction features\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: a keras model that can be trained to encode a sequence of motion tracking instances into a latent\n",
    "        space using temporal convolutional networks.\n",
    "\n",
    "    \"\"\"\n",
    "    # Define feature and adjacency inputs\n",
    "    x = Input(shape=input_shape)\n",
    "    a = Input(shape=edge_feature_shape)\n",
    "\n",
    "    if use_gnn:\n",
    "        x_reshaped = tf.transpose(\n",
    "            tf.reshape(\n",
    "                tf.transpose(x),\n",
    "                [\n",
    "                    -1,\n",
    "                    adjacency_matrix.shape[-1],\n",
    "                    x.shape[1],\n",
    "                    input_shape[-1] // adjacency_matrix.shape[-1],\n",
    "                ][::-1],\n",
    "            )\n",
    "        )\n",
    "        a_reshaped = tf.transpose(\n",
    "            tf.reshape(\n",
    "                tf.transpose(a),\n",
    "                [\n",
    "                    -1,\n",
    "                    edge_feature_shape[-1],\n",
    "                    a.shape[1],\n",
    "                    1,\n",
    "                ][::-1],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        x_reshaped = tf.expand_dims(x, axis=1)\n",
    "\n",
    "    encoder = TimeDistributed(\n",
    "        tcn.TCN(\n",
    "            conv_filters,\n",
    "            kernel_size,\n",
    "            conv_stacks,\n",
    "            conv_dilations,\n",
    "            padding,\n",
    "            use_skip_connections,\n",
    "            dropout_rate,\n",
    "            return_sequences=False,\n",
    "            activation=activation,\n",
    "            kernel_initializer=\"random_normal\",\n",
    "            use_batch_norm=True,\n",
    "        )\n",
    "    )(x_reshaped)\n",
    "\n",
    "    # Instantiate spatial graph block\n",
    "    if use_gnn:\n",
    "\n",
    "        # Embed edge features too\n",
    "        a_encoder = TimeDistributed(\n",
    "            tcn.TCN(\n",
    "                conv_filters,\n",
    "                kernel_size,\n",
    "                conv_stacks,\n",
    "                conv_dilations,\n",
    "                padding,\n",
    "                use_skip_connections,\n",
    "                dropout_rate,\n",
    "                return_sequences=False,\n",
    "                activation=activation,\n",
    "                kernel_initializer=\"random_normal\",\n",
    "                use_batch_norm=True,\n",
    "            )\n",
    "        )(a_reshaped)\n",
    "\n",
    "        spatial_block = CensNetConv(\n",
    "            node_channels=latent_dim,\n",
    "            edge_channels=latent_dim,\n",
    "            activation=\"relu\",\n",
    "            node_regularizer=tf.keras.regularizers.l1(interaction_regularization),\n",
    "        )\n",
    "\n",
    "        # Process adjacency matrix\n",
    "        laplacian, edge_laplacian, incidence = spatial_block.preprocess(\n",
    "            adjacency_matrix\n",
    "        )\n",
    "\n",
    "        # Get and concatenate node and edge embeddings\n",
    "        x_nodes, x_edges = spatial_block(\n",
    "            [encoder, (laplacian, edge_laplacian, incidence), a_encoder], mask=None\n",
    "        )\n",
    "\n",
    "        x_nodes = tf.reshape(\n",
    "            x_nodes,\n",
    "            [-1, adjacency_matrix.shape[-1] * latent_dim],\n",
    "        )\n",
    "\n",
    "        x_edges = tf.reshape(\n",
    "            x_edges,\n",
    "            [-1, edge_feature_shape[-1] * latent_dim],\n",
    "        )\n",
    "\n",
    "        encoder = tf.concat([x_nodes, x_edges], axis=-1)\n",
    "\n",
    "    else:\n",
    "        encoder = tf.squeeze(encoder, axis=1)\n",
    "\n",
    "    encoder = tf.keras.layers.Dense(2 * latent_dim, activation=\"relu\")(encoder)\n",
    "    encoder = tf.keras.layers.BatchNormalization()(encoder)\n",
    "    encoder = Dense(latent_dim, activation=\"relu\")(encoder)\n",
    "    encoder = tf.keras.layers.BatchNormalization()(encoder)\n",
    "    encoder = tf.keras.layers.Dense(latent_dim)(encoder)\n",
    "\n",
    "    return Model([x, a], encoder, name=\"TCN_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc3b15f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from deepof.clustering.censNetConv_pt import CensNetConvPT\n",
    "\n",
    "\n",
    "def _act(name: str) -> nn.Module:\n",
    "    name = (name or \"relu\").lower()\n",
    "    if name == \"relu\":\n",
    "        return nn.ReLU()\n",
    "    if name == \"gelu\":\n",
    "        return nn.GELU()\n",
    "    if name == \"tanh\":\n",
    "        return nn.Tanh()\n",
    "    if name == \"leaky_relu\":\n",
    "        return nn.LeakyReLU(0.2)\n",
    "    if name in {\"linear\", \"identity\", \"none\"}:\n",
    "        return nn.Identity()\n",
    "    raise ValueError(f\"Unsupported activation: {name}\")\n",
    "\n",
    "\n",
    "class TemporalBlockPT(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual TCN block compatible with keras-tcn:\n",
    "      - Conv1d -> BN(eps=1e-3) -> Act -> Drop\n",
    "      - Conv1d -> BN(eps=1e-3) -> Act -> Drop\n",
    "      - Residual add (with 1x1 projection if channels differ) -> Act\n",
    "    Returns:\n",
    "      out: post-residual activation\n",
    "      skip: post-second-conv activation (summed across blocks when skip connections are used)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: int,\n",
    "        dilation: int,\n",
    "        padding: str = \"causal\",\n",
    "        dropout_rate: float = 0.0,\n",
    "        activation: str = \"relu\",\n",
    "        use_batch_norm: bool = True,\n",
    "        conv_init_std: float = 0.05,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert padding in {\"causal\", \"same\"}\n",
    "        self.dilation = int(dilation)\n",
    "        self.kernel_size = int(kernel_size)\n",
    "        self.padding_mode = padding\n",
    "        self.act = _act(activation)\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "\n",
    "        pad = lambda: ((self.kernel_size - 1) * self.dilation) // 2 if padding == \"same\" else 0\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, self.kernel_size, dilation=self.dilation, padding=pad(), bias=True)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels, eps=1e-3) if use_batch_norm else nn.Identity()\n",
    "        self.drop1 = nn.Dropout(float(dropout_rate)) if dropout_rate else nn.Identity()\n",
    "\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, self.kernel_size, dilation=self.dilation, padding=pad(), bias=True)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels, eps=1e-3) if use_batch_norm else nn.Identity()\n",
    "        self.drop2 = nn.Dropout(float(dropout_rate)) if dropout_rate else nn.Identity()\n",
    "\n",
    "        # 1x1 residual projection if channels differ\n",
    "        self.downsample = nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=True) if in_channels != out_channels else None\n",
    "\n",
    "        # Init similar to keras random_normal\n",
    "        nn.init.normal_(self.conv1.weight, mean=0.0, std=conv_init_std); nn.init.zeros_(self.conv1.bias)\n",
    "        nn.init.normal_(self.conv2.weight, mean=0.0, std=conv_init_std); nn.init.zeros_(self.conv2.bias)\n",
    "        if self.downsample is not None:\n",
    "            nn.init.normal_(self.downsample.weight, mean=0.0, std=conv_init_std); nn.init.zeros_(self.downsample.bias)\n",
    "\n",
    "    def _causal_pad(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        pad = (self.kernel_size - 1) * self.dilation\n",
    "        return F.pad(x, (pad, 0))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # x: (B, C_in, T)\n",
    "        y = self._causal_pad(x) if self.padding_mode == \"causal\" else x\n",
    "        y = self.drop1(self.act(self.bn1(self.conv1(y))))\n",
    "\n",
    "        y = self._causal_pad(y) if self.padding_mode == \"causal\" else y\n",
    "        y = self.drop2(self.act(self.bn2(self.conv2(y))))\n",
    "\n",
    "        skip = y  # per-block skip is the post-second-activation output\n",
    "\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        out = self.act(y + res)\n",
    "        return out, skip  # both (B, C_out, T)\n",
    "\n",
    "\n",
    "class TCN1DPT(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal Convolutional Network over sequences (B, T, C_in).\n",
    "    - When use_skip_connections=True: sum per-block skip outputs, then apply a final activation.\n",
    "    - Otherwise: use the last block’s residual output.\n",
    "    - return_sequences=False: returns last timestep features (B, C_out).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        conv_filters: int = 32,\n",
    "        kernel_size: int = 4,\n",
    "        conv_stacks: int = 2,\n",
    "        conv_dilations: Iterable[int] = (1, 2, 4, 8),\n",
    "        padding: str = \"causal\",\n",
    "        use_skip_connections: bool = True,\n",
    "        dropout_rate: float = 0.0,\n",
    "        activation: str = \"relu\",\n",
    "        use_batch_norm: bool = True,\n",
    "        return_sequences: bool = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_skip_connections = use_skip_connections\n",
    "        self.return_sequences = return_sequences\n",
    "        self.final_act = _act(activation)\n",
    "\n",
    "        blocks = []\n",
    "        c_in = in_channels\n",
    "        for _ in range(int(conv_stacks)):\n",
    "            for d in tuple(conv_dilations):\n",
    "                blocks.append(\n",
    "                    TemporalBlockPT(\n",
    "                        in_channels=c_in,\n",
    "                        out_channels=conv_filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        dilation=int(d),\n",
    "                        padding=padding,\n",
    "                        dropout_rate=dropout_rate,\n",
    "                        activation=activation,\n",
    "                        use_batch_norm=use_batch_norm,\n",
    "                    )\n",
    "                )\n",
    "                c_in = conv_filters\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (B, T, C_in) -> Conv1d expects (B, C_in, T)\n",
    "        y = x.transpose(1, 2)\n",
    "        skip_sum, last_out = None, None\n",
    "\n",
    "        for blk in self.blocks:\n",
    "            y, skip = blk(y)\n",
    "            last_out = y\n",
    "            if self.use_skip_connections:\n",
    "                skip_sum = skip if skip_sum is None else (skip_sum + skip)\n",
    "\n",
    "        out = skip_sum if self.use_skip_connections else last_out  # (B, C, T)\n",
    "        out = self.final_act(out)\n",
    "        return out.transpose(1, 2) if self.return_sequences else out[:, :, -1]\n",
    "\n",
    "\n",
    "class TCNEncoderPT(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch port of the TF get_TCN_encoder with matching behavior:\n",
    "      - Inputs:\n",
    "          x: (B, W, N, NF)   node features\n",
    "          a: (B, W, E, EF)   edge features\n",
    "      - use_gnn=True:\n",
    "          TimeDistributed(TCN) over nodes/edges -> (B, N, C) and (B, E, C)\n",
    "          CensNetConvPT([node, (lap, edge_lap, inc), edge]) -> (B, N, latent), (B, E, latent)\n",
    "          Flatten and MLP head\n",
    "      - use_gnn=False:\n",
    "          Flatten nodes+features -> TCN -> MLP head\n",
    "\n",
    "      Parity details:\n",
    "        - keras-tcn-compatible skip semantics and activation placement\n",
    "        - BN eps=1e-3 everywhere\n",
    "        - 'causal' and 'same' paddings supported\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: Tuple[int, int, int],        # (W, N, NF)\n",
    "        edge_feature_shape: Tuple[int, int, int], # (W, E, EF)\n",
    "        adjacency_matrix: np.ndarray,\n",
    "        latent_dim: int,\n",
    "        use_gnn: bool = True,\n",
    "        conv_filters: int = 32,\n",
    "        kernel_size: int = 4,\n",
    "        conv_stacks: int = 2,\n",
    "        conv_dilations: Iterable[int] = (1, 2, 4, 8),\n",
    "        padding: str = \"causal\",\n",
    "        use_skip_connections: bool = True,\n",
    "        dropout_rate: float = 0.0,\n",
    "        activation: str = \"relu\",\n",
    "        interaction_regularization: float = 0.0,  # not used explicitly in PT\n",
    "        use_batch_norm: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_gnn = use_gnn\n",
    "        self.latent_dim = int(latent_dim)\n",
    "        self.conv_filters = int(conv_filters)\n",
    "\n",
    "        W, N, F_node = input_shape\n",
    "        _, E, F_edge = edge_feature_shape\n",
    "        assert adjacency_matrix.shape[0] == N == adjacency_matrix.shape[1], \"Adjacency must be NxN and match input nodes.\"\n",
    "\n",
    "        tcn_cfg = dict(\n",
    "            conv_filters=conv_filters,\n",
    "            kernel_size=kernel_size,\n",
    "            conv_stacks=conv_stacks,\n",
    "            conv_dilations=tuple(conv_dilations),\n",
    "            padding=padding,\n",
    "            use_skip_connections=use_skip_connections,\n",
    "            dropout_rate=float(dropout_rate),\n",
    "            activation=activation,\n",
    "            use_batch_norm=use_batch_norm,\n",
    "            return_sequences=False,\n",
    "        )\n",
    "\n",
    "        if use_gnn:\n",
    "            # Per-node and per-edge TCNs\n",
    "            self.node_tcn = TCN1DPT(in_channels=F_node, **tcn_cfg)\n",
    "            self.edge_tcn = TCN1DPT(in_channels=F_edge, **tcn_cfg)\n",
    "\n",
    "            # Graph block and buffers\n",
    "            self.spatial_gnn_block = CensNetConvPT(node_channels=latent_dim, edge_channels=latent_dim, activation=\"relu\")\n",
    "            lap, edge_lap, inc = self.spatial_gnn_block.preprocess(torch.tensor(adjacency_matrix))\n",
    "            self.register_buffer(\"laplacian\", lap.float())\n",
    "            self.register_buffer(\"edge_laplacian\", edge_lap.float())\n",
    "            self.register_buffer(\"incidence\", inc.float())\n",
    "\n",
    "            final_in = (N * latent_dim) + (E * latent_dim)\n",
    "        else:\n",
    "            # Single TCN over flattened node features\n",
    "            self.flat_tcn = TCN1DPT(in_channels=N * F_node, **tcn_cfg)\n",
    "            final_in = conv_filters\n",
    "\n",
    "        # Head MLP: Dense(2*latent) -> BN -> Dense(latent) -> BN -> Dense(latent)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(final_in, 2 * latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(2 * latent_dim, eps=1e-3),\n",
    "            nn.Linear(2 * latent_dim, latent_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(latent_dim, eps=1e-3),\n",
    "            nn.Linear(latent_dim, latent_dim),\n",
    "        )\n",
    "        for m in self.head.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight); nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, a: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B, W, N, NF)  a: (B, W, E, EF)  -> returns (B, latent_dim)\n",
    "        \"\"\"\n",
    "        B, W, N, F_node = x.shape\n",
    "        _, _, E, F_edge = a.shape\n",
    "\n",
    "        if self.use_gnn:\n",
    "            # Nodes: TF-style reshape pipeline to match memory layout exactly\n",
    "            x_3d = x.view(B, W, N * F_node)          # (B, W, N*F)\n",
    "            x_t = x_3d.permute(2, 1, 0)              # (N*F, W, B)\n",
    "            x_reshaped_t = x_t.reshape(F_node, W, N, B)\n",
    "            x_nodes = x_reshaped_t.permute(3, 2, 1, 0)  # (B, N, W, F)\n",
    "\n",
    "            node_in = x_nodes.reshape(B * N, W, F_node)\n",
    "            node_out = self.node_tcn(node_in).view(B, N, self.conv_filters)  # (B, N, C)\n",
    "\n",
    "            # Edges: TF-style reshape pipeline to match memory layout exactly\n",
    "            a_3d = a.view(B, W, E * F_edge)          # (B, W, E*F_edge)\n",
    "            a_t = a_3d.permute(2, 1, 0)              # (E*F_edge, W, B)\n",
    "            a_reshaped_t = a_t.reshape(F_edge, W, E, B)\n",
    "            a_edges = a_reshaped_t.permute(3, 2, 1, 0)  # (B, E, W, F_edge)\n",
    "\n",
    "            edge_in = a_edges.reshape(B * E, W, F_edge)\n",
    "            edge_out = self.edge_tcn(edge_in).view(B, E, self.conv_filters)  # (B, E, C)\n",
    "\n",
    "            # Graph block\n",
    "            adj_tuple = (self.laplacian, self.edge_laplacian, self.incidence)\n",
    "            x_nodes_g, x_edges_g = self.spatial_gnn_block([node_out, adj_tuple, edge_out])\n",
    "            x_nodes_g = F.relu(x_nodes_g)\n",
    "            x_edges_g = F.relu(x_edges_g)\n",
    "\n",
    "            enc = torch.cat([x_nodes_g.reshape(B, -1), x_edges_g.reshape(B, -1)], dim=-1)\n",
    "        else:\n",
    "            # Non-GNN unchanged\n",
    "            x_flat = x.view(B, W, N * F_node)        # (B, W, N*NF)\n",
    "            enc = self.flat_tcn(x_flat)              # (B, C)\n",
    "\n",
    "        return self.head(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1005e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import tcn as tcn_pkg\n",
    "\n",
    "def _tf_conv1d_to_torch(w_keras: np.ndarray) -> torch.Tensor:\n",
    "    # TF Conv1D [K, Cin, Cout] -> PT Conv1d [Cout, Cin, K]\n",
    "    return torch.from_numpy(np.transpose(w_keras, (2, 1, 0)))\n",
    "\n",
    "def _load_bn_tf_to_pt(pt_bn: nn.BatchNorm1d, tf_bn: tf.keras.layers.BatchNormalization):\n",
    "    gamma, beta, moving_mean, moving_var = tf_bn.get_weights()\n",
    "    pt_bn.weight.data = torch.from_numpy(gamma)\n",
    "    pt_bn.bias.data = torch.from_numpy(beta)\n",
    "    pt_bn.running_mean.data = torch.from_numpy(moving_mean)\n",
    "    pt_bn.running_var.data = torch.from_numpy(moving_var)\n",
    "\n",
    "def _kernel_size_1(conv: tf.keras.layers.Conv1D) -> bool:\n",
    "    ks = conv.kernel_size\n",
    "    ks = ks[0] if isinstance(ks, tuple) else ks\n",
    "    return ks == 1\n",
    "\n",
    "def _collect_tcn_sublayers(tf_tcn_layer: tf.keras.layers.Layer):\n",
    "    # Use submodules as before; we’ll still verify counts and assign conservatively\n",
    "    convs = [m for m in tf_tcn_layer.submodules if isinstance(m, tf.keras.layers.Conv1D)]\n",
    "    bns = [m for m in tf_tcn_layer.submodules if isinstance(m, tf.keras.layers.BatchNormalization)]\n",
    "    return convs, bns\n",
    "\n",
    "def transfer_td_tcn_weights(tf_td_tcn: tf.keras.layers.TimeDistributed, pt_tcn) -> None:\n",
    "    \"\"\"\n",
    "    Transfer weights from TF TimeDistributed(tcn.TCN) into PT TCN1DPT:\n",
    "      - Map per-block [conv1, conv2] (in order) and their BN layers\n",
    "      - Map the single residual 1x1 projection (matching_conv1D), if present\n",
    "      - No skip 1x1 convs (your model has none)\n",
    "    \"\"\"\n",
    "    assert isinstance(tf_td_tcn, tf.keras.layers.TimeDistributed)\n",
    "    assert isinstance(tf_td_tcn.layer, tcn_pkg.TCN)\n",
    "    tf_tcn = tf_td_tcn.layer\n",
    "\n",
    "    convs, bns = _collect_tcn_sublayers(tf_tcn)\n",
    "    block_convs = [c for c in convs if not _kernel_size_1(c)]   # conv1D_0 / conv1D_1 pairs per block\n",
    "    proj_1x1 = [c for c in convs if _kernel_size_1(c)]          # matching_conv1D (0 or 1 in your build)\n",
    "\n",
    "    num_blocks = len(pt_tcn.blocks)\n",
    "    assert len(block_convs) == 2 * num_blocks, f\"Conv count mismatch: TF block convs={len(block_convs)}, PT blocks={num_blocks}\"\n",
    "\n",
    "    use_bn = isinstance(pt_tcn.blocks[0].bn1, nn.BatchNorm1d)\n",
    "    if use_bn:\n",
    "        assert len(bns) >= 2 * num_blocks, f\"BN count mismatch: TF BNs={len(bns)}, expected >= {2 * num_blocks}\"\n",
    "\n",
    "    # Load per-block convs and BN stats\n",
    "    for i, blk in enumerate(pt_tcn.blocks):\n",
    "        k1, b1 = block_convs[2 * i].get_weights()\n",
    "        blk.conv1.weight.data = _tf_conv1d_to_torch(k1)\n",
    "        blk.conv1.bias.data = torch.from_numpy(b1)\n",
    "\n",
    "        k2, b2 = block_convs[2 * i + 1].get_weights()\n",
    "        blk.conv2.weight.data = _tf_conv1d_to_torch(k2)\n",
    "        blk.conv2.bias.data = torch.from_numpy(b2)\n",
    "\n",
    "        if use_bn:\n",
    "            _load_bn_tf_to_pt(blk.bn1, bns[2 * i])\n",
    "            _load_bn_tf_to_pt(blk.bn2, bns[2 * i + 1])\n",
    "\n",
    "    # Residual projection for the first block if needed\n",
    "    proj_idx = 0\n",
    "    for blk in pt_tcn.blocks:\n",
    "        if isinstance(getattr(blk, \"downsample\", None), nn.Conv1d):\n",
    "            rk, rb = proj_1x1[proj_idx].get_weights()\n",
    "            blk.downsample.weight.data = _tf_conv1d_to_torch(rk)\n",
    "            blk.downsample.bias.data = torch.from_numpy(rb)\n",
    "            proj_idx += 1\n",
    "\n",
    "\n",
    "# ---------- MLP head transfer ----------\n",
    "\n",
    "def transfer_head_mlp(tf_model, pt_model_head: nn.Sequential):\n",
    "    \"\"\"\n",
    "    Transfer the final MLP head:\n",
    "      Dense(2*latent, relu) -> BN -> Dense(latent, relu) -> BN -> Dense(latent)\n",
    "    from TF model to PT head (Linear, BN, Linear, BN, Linear).\n",
    "    \"\"\"\n",
    "    # Extract the final [Dense, BN, Dense, BN, Dense] from TF model\n",
    "    tail = [l for l in tf_model.layers if isinstance(l, (tf.keras.layers.Dense, tf.keras.layers.BatchNormalization))]\n",
    "    d1, bn1, d2, bn2, d3 = tail[-5:]\n",
    "\n",
    "    # PT head layout: [Linear, ReLU, BN, Linear, ReLU, BN, Linear]\n",
    "    lin1: nn.Linear = pt_model_head[0]\n",
    "    bn1_pt: nn.BatchNorm1d = pt_model_head[2]\n",
    "    lin2: nn.Linear = pt_model_head[3]\n",
    "    bn2_pt: nn.BatchNorm1d = pt_model_head[5]\n",
    "    lin3: nn.Linear = pt_model_head[6]\n",
    "\n",
    "    # Dense 1\n",
    "    w, b = d1.get_weights()\n",
    "    lin1.weight.data = torch.from_numpy(w.T)\n",
    "    lin1.bias.data = torch.from_numpy(b)\n",
    "    # BN 1\n",
    "    _load_bn_tf_to_pt(bn1_pt, bn1)\n",
    "    # Dense 2\n",
    "    w, b = d2.get_weights()\n",
    "    lin2.weight.data = torch.from_numpy(w.T)\n",
    "    lin2.bias.data = torch.from_numpy(b)\n",
    "    # BN 2\n",
    "    _load_bn_tf_to_pt(bn2_pt, bn2)\n",
    "    # Dense 3\n",
    "    w, b = d3.get_weights()\n",
    "    lin3.weight.data = torch.from_numpy(w.T)\n",
    "    lin3.bias.data = torch.from_numpy(b)\n",
    "\n",
    "\n",
    "# ---------- High-level: TCN encoder transfer ----------\n",
    "\n",
    "def transfer_tcn_encoder_weights(tf_model, pt_model, use_gnn: bool):\n",
    "    \"\"\"\n",
    "    Transfers weights for the full TCN encoder.\n",
    "      - Node and edge TimeDistributed(TCN) blocks\n",
    "      - CensNetConv (if use_gnn)\n",
    "      - Final MLP head\n",
    "    \"\"\"\n",
    "    # 1) Final head\n",
    "    transfer_head_mlp(tf_model, pt_model.head)\n",
    "\n",
    "    # 2) TimeDistributed(TCN) blocks\n",
    "    td_layers = [l for l in tf_model.layers if isinstance(l, tf.keras.layers.TimeDistributed) and isinstance(l.layer, tcn.TCN)]\n",
    "    if use_gnn:\n",
    "        assert len(td_layers) >= 2, \"Expected two TimeDistributed(TCN) layers (node and edge) for use_gnn=True\"\n",
    "        # Heuristically: first TD is nodes, second is edges (matches build order)\n",
    "        node_td = td_layers[0]\n",
    "        edge_td = td_layers[1]\n",
    "        transfer_td_tcn_weights(node_td, pt_model.node_tcn)\n",
    "        transfer_td_tcn_weights(edge_td, pt_model.edge_tcn)\n",
    "\n",
    "        # 3) CensNetConv\n",
    "        gnn_layer = next(l for l in tf_model.layers if isinstance(l, CensNetConv))\n",
    "        transfer_censnet_weights(gnn_layer, pt_model.spatial_gnn_block)\n",
    "\n",
    "    else:\n",
    "        # Non-GNN: single TD(TCN); TF input_shape should be (T, N*F_node)\n",
    "        assert len(td_layers) >= 1, \"Expected one TimeDistributed(TCN) layer for use_gnn=False\"\n",
    "        transfer_td_tcn_weights(td_layers[0], pt_model.flat_tcn)\n",
    "\n",
    "def transfer_censnet_weights(tf_layer, pt_layer):\n",
    "    \"\"\"\n",
    "    Transfers all six weights from a Spektral CensNetConv layer to the\n",
    "    corresponding CensNetConvPT layer.\n",
    "    \"\"\"\n",
    "    # Get all weights from the TensorFlow layer. The order is determined by\n",
    "    # the layer's build order in Spektral's source code.\n",
    "    tf_weights = tf_layer.get_weights()\n",
    "\n",
    "    # Unpack all six weights.\n",
    "    # Order: kernel_node, bias_node, kernel_edge, bias_edge, projector_node, projector_edge\n",
    "    kn_tf, bn_tf, ke_tf, be_tf, pn_tf, pe_tf = tf_weights\n",
    "\n",
    "    # Build weights on first pass\n",
    "    if pt_layer.node_kernel is None:\n",
    "        # Move parameters to the same device as input tensors\n",
    "        pt_layer._build(kn_tf.T.shape, bn_tf.T.shape)\n",
    "        #pt_layer.to(kn_tf.device)\n",
    "\n",
    "    # 1. & 2. Transfer Node Kernel and Bias\n",
    "    # Keras Dense kernel is (in_features, out_features)\n",
    "    pt_layer.node_kernel.data = torch.from_numpy(kn_tf)\n",
    "    pt_layer.edge_kernel.data = torch.from_numpy(bn_tf)\n",
    "\n",
    "    # 3. & 4. Transfer Edge Kernel and Bias\n",
    "    # Same transposition logic applies.\n",
    "    pt_layer.node_weights.data = torch.from_numpy(ke_tf)\n",
    "    pt_layer.edge_weights.data = torch.from_numpy(be_tf)\n",
    "\n",
    "    # 5. Transfer Node Projector Weights (P_n)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.node_bias.data = torch.from_numpy(pn_tf)\n",
    "\n",
    "    # 6. Transfer Edge Projector Weights (P_e)\n",
    "    # These are [in_features, 1], which matches, so no transpose needed.\n",
    "    pt_layer.edge_bias.data = torch.from_numpy(pe_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2aa734e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_forward_pass_gnn (__main__.TestTCNEncoderTranslation) ... The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "ok\n",
      "test_forward_pass_no_gnn (__main__.TestTCNEncoderTranslation) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN TF time: 0.5147807598114014 PT time: 0.0169522762298584\n",
      "✅ TCNEncoderPT (GNN path) parity PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 1.261s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TCNEncoderPT (non-GNN path) parity PASSED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest, time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def count_undirected_edges(adj: np.ndarray) -> int:\n",
    "    # Count upper-triangular non-zero entries (undirected edges)\n",
    "    return int(np.count_nonzero(np.triu(adj, 1)))\n",
    "\n",
    "class TestTCNEncoderTranslation(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        # Fundamental dims (use your conventions)\n",
    "        self.R = 2048                 # number of rows (not used for model build)\n",
    "        self.W = 25                   # window length\n",
    "        self.N = 11                   # nodes\n",
    "        self.NF = 3                   # features per node\n",
    "        self.EF = 1                   # features per edge (TF expects 1 for the reshape quirk)\n",
    "        self.latent_dim = 6\n",
    "        self.use_gnn = True\n",
    "\n",
    "        # Batch used for parity test\n",
    "        self.B = 128\n",
    "\n",
    "        # Make an adjacency whose undirected edge count E matches the edge axis we'll use\n",
    "        # Example: pick a sparse symmetric adjacency with E edges\n",
    "        # If you already have an adjacency, just set self.adj_matrix = your_matrix and let E = count_undirected_edges(A)\n",
    "        rng = np.random.default_rng(0)\n",
    "        A = np.zeros((self.N, self.N), dtype=np.float32)\n",
    "        # randomly pick E edges; here we choose E = 11 (as in your typical config)\n",
    "        target_E = 11\n",
    "        iu = np.triu_indices(self.N, 1)\n",
    "        idx = rng.choice(len(iu[0]), size=target_E, replace=False)\n",
    "        A[iu[0][idx], iu[1][idx]] = 1.0\n",
    "        A = A + A.T\n",
    "        self.adj_matrix = A\n",
    "        self.E = count_undirected_edges(self.adj_matrix)  # should be target_E\n",
    "\n",
    "        # TF input shapes (flattened)\n",
    "        self.tf_input_shape_gnn = (self.W, self.N * self.NF)  # (W, NNF)\n",
    "        self.tf_edge_shape      = (self.W, self.E * self.EF)  # (W, EEF) -> with EF=1, equals (W, E)\n",
    "\n",
    "        # PT input shapes (split)\n",
    "        self.pt_input_shape = (self.W, self.N, self.NF)       # (W, N, NF)\n",
    "        self.pt_edge_shape  = (self.W, self.E, self.EF)       # (W, E, EF)\n",
    "\n",
    "        # Random inputs\n",
    "        self.x_pt = rng.normal(size=(self.B, self.W, self.N, self.NF)).astype(np.float32)\n",
    "        self.a_pt = rng.normal(size=(self.B, self.W, self.E, self.EF)).astype(np.float32)\n",
    "        # Flatten for TF model\n",
    "        self.x_tf = self.x_pt.reshape(self.B, self.W, self.N * self.NF)\n",
    "        self.a_tf = self.a_pt.reshape(self.B, self.W, self.E * self.EF)  # with EF=1, (B, W, E)\n",
    "\n",
    "        # Common TCN params\n",
    "        self.conv_filters = 32\n",
    "        self.kernel_size = 3\n",
    "        self.conv_stacks = 2\n",
    "        self.conv_dilations = (1, 2)\n",
    "        self.padding = \"causal\"\n",
    "        self.use_skip = True\n",
    "        self.dropout = 0.0\n",
    "        self.activation = \"relu\"\n",
    "\n",
    "    def test_forward_pass_gnn(self):\n",
    "        # Build TF and PT models\n",
    "        tf_model = get_TCN_encoder(\n",
    "            input_shape=self.tf_input_shape_gnn,   # (W, NNF)\n",
    "            edge_feature_shape=self.tf_edge_shape, # (W, EEF) -> E when EF=1\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=True,\n",
    "            conv_filters=self.conv_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            conv_stacks=self.conv_stacks,\n",
    "            conv_dilations=self.conv_dilations,\n",
    "            padding=self.padding,\n",
    "            use_skip_connections=self.use_skip,\n",
    "            dropout_rate=self.dropout,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "        pt_model = TCNEncoderPT(\n",
    "            input_shape=self.pt_input_shape,       # (W, N, NF)\n",
    "            edge_feature_shape=self.pt_edge_shape, # (W, E, EF)\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=True,\n",
    "            conv_filters=self.conv_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            conv_stacks=self.conv_stacks,\n",
    "            conv_dilations=self.conv_dilations,\n",
    "            padding=self.padding,\n",
    "            use_skip_connections=self.use_skip,\n",
    "            dropout_rate=self.dropout,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "        pt_model.eval()\n",
    "\n",
    "        # Warm-up PT graph (optional)\n",
    "        with torch.no_grad():\n",
    "            _ = pt_model(torch.from_numpy(self.x_pt), torch.from_numpy(self.a_pt))\n",
    "\n",
    "        # Transfer weights TF -> PT\n",
    "        transfer_tcn_encoder_weights(tf_model, pt_model, use_gnn=True)\n",
    "\n",
    "        # Compare outputs (TF expects flattened a)\n",
    "        t0 = time.time()\n",
    "        y_tf = tf_model([self.x_tf, self.a_tf], training=False).numpy()\n",
    "        t1 = time.time()\n",
    "        with torch.no_grad():\n",
    "            y_pt = pt_model(torch.from_numpy(self.x_pt), torch.from_numpy(self.a_pt)).cpu().numpy()\n",
    "        t2 = time.time()\n",
    "        print(\"GNN TF time:\", t1 - t0, \"PT time:\", t2 - t1)\n",
    "        np.testing.assert_allclose(y_tf, y_pt, rtol=1e-5, atol=2e-4)\n",
    "        print(\"✅ TCNEncoderPT (GNN path) parity PASSED\")\n",
    "\n",
    "    def test_forward_pass_no_gnn(self):\n",
    "        # Build TF and PT models (TF expects flattened x, a still provided but unused)\n",
    "        tf_model = get_TCN_encoder(\n",
    "            input_shape=self.tf_input_shape_gnn,   # (W, NNF) in your pipeline\n",
    "            edge_feature_shape=self.tf_edge_shape, # (W, EEF)\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=False,\n",
    "            conv_filters=self.conv_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            conv_stacks=self.conv_stacks,\n",
    "            conv_dilations=self.conv_dilations,\n",
    "            padding=self.padding,\n",
    "            use_skip_connections=self.use_skip,\n",
    "            dropout_rate=self.dropout,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "        pt_model = TCNEncoderPT(\n",
    "            input_shape=self.pt_input_shape,       # (W, N, NF)\n",
    "            edge_feature_shape=self.pt_edge_shape, # (W, E, EF)\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=False,\n",
    "            conv_filters=self.conv_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            conv_stacks=self.conv_stacks,\n",
    "            conv_dilations=self.conv_dilations,\n",
    "            padding=self.padding,\n",
    "            use_skip_connections=self.use_skip,\n",
    "            dropout_rate=self.dropout,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "        pt_model.eval()\n",
    "\n",
    "        # Transfer weights TF -> PT\n",
    "        transfer_tcn_encoder_weights(tf_model, pt_model, use_gnn=False)\n",
    "\n",
    "        # Compare outputs (TF expects flattened x, a flattened to EEF)\n",
    "        y_tf = tf_model([self.x_tf, self.a_tf], training=False).numpy()\n",
    "        with torch.no_grad():\n",
    "            y_pt = pt_model(torch.from_numpy(self.x_pt), torch.from_numpy(self.a_pt)).cpu().numpy()\n",
    "\n",
    "        np.testing.assert_allclose(y_tf, y_pt, rtol=1e-5, atol=2e-4)\n",
    "        print(\"✅ TCNEncoderPT (non-GNN path) parity PASSED\")\n",
    "\n",
    "# Run\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestTCNEncoderTranslation)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "386550a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TCN-only shapes -> TF: (128, 32) PT: (128, 32)\n",
      "TCN-only mean abs diff: 4.136673e-08\n",
      "TCN-only max abs diff: 2.9802322e-07\n"
     ]
    }
   ],
   "source": [
    "# TCN-only parity diagnostic (non-GNN), fully executable with your provided dims\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf\n",
    "import tcn as tcn_pkg\n",
    "\n",
    "# Assumes get_TCN_encoder and TCNEncoderPT are already defined/imported in your notebook.\n",
    "\n",
    "# -------------------------\n",
    "# 1) Your provided settings\n",
    "# -------------------------\n",
    "batch_size = 128\n",
    "window_length = 25\n",
    "num_nodes = 11\n",
    "features_per_node = 3\n",
    "num_edges = 11\n",
    "features_per_edge = 1\n",
    "\n",
    "latent_dim = 6\n",
    "use_gnn = False\n",
    "\n",
    "# Adjacency matrix\n",
    "m = np.zeros((num_nodes, num_nodes), dtype=np.float32)\n",
    "ui = np.triu_indices(num_nodes)\n",
    "num_possible_edges = len(ui[0])\n",
    "c = np.random.choice(num_possible_edges, min(num_edges, num_possible_edges), replace=False)\n",
    "m[ui[0][c], ui[1][c]] = 1\n",
    "m = (m + m.T).astype(np.float32)  # symmetric\n",
    "adj_matrix = m\n",
    "\n",
    "# Input shapes\n",
    "tf_input_shape = (window_length, num_nodes * features_per_node)     # TF non-GNN expects flattened features\n",
    "pt_input_shape = (window_length, num_nodes, features_per_node)      # PT expects (T, N, F_node)\n",
    "edge_shape = (window_length, num_edges, features_per_edge)\n",
    "\n",
    "# Random inputs\n",
    "rng = np.random.default_rng(0)\n",
    "x_np = rng.normal(size=(batch_size, window_length, num_nodes, features_per_node)).astype(np.float32)\n",
    "a_np = rng.normal(size=(batch_size, window_length, num_edges, features_per_edge)).astype(np.float32)\n",
    "\n",
    "# ------------------------------------\n",
    "# 2) Build TF and PT (non-GNN) models\n",
    "# ------------------------------------\n",
    "tf_model = get_TCN_encoder(\n",
    "    input_shape=tf_input_shape,\n",
    "    edge_feature_shape=edge_shape,\n",
    "    adjacency_matrix=adj_matrix,\n",
    "    latent_dim=latent_dim,\n",
    "    use_gnn=False,\n",
    "    conv_filters=32,\n",
    "    kernel_size=3,\n",
    "    conv_stacks=2,\n",
    "    conv_dilations=(1, 2),\n",
    "    padding=\"causal\",\n",
    "    use_skip_connections=True,\n",
    "    dropout_rate=0.0,\n",
    "    activation=\"relu\",\n",
    ")\n",
    "\n",
    "pt_model = TCNEncoderPT(\n",
    "    input_shape=pt_input_shape,\n",
    "    edge_feature_shape=edge_shape,\n",
    "    adjacency_matrix=adj_matrix,\n",
    "    latent_dim=latent_dim,\n",
    "    use_gnn=False,\n",
    "    conv_filters=32,\n",
    "    kernel_size=3,\n",
    "    conv_stacks=2,\n",
    "    conv_dilations=(1, 2),\n",
    "    padding=\"causal\",\n",
    "    use_skip_connections=True,\n",
    "    dropout_rate=0.0,\n",
    "    activation=\"relu\",\n",
    ")\n",
    "\n",
    "pt_model.eval()\n",
    "\n",
    "# Ensure PT BN eps=1e-3 inside TCN (BN eps mismatch is a common source of diffs)\n",
    "for blk in pt_model.flat_tcn.blocks:\n",
    "    if isinstance(blk.bn1, nn.BatchNorm1d):\n",
    "        blk.bn1.eps = 1e-3\n",
    "    if isinstance(blk.bn2, nn.BatchNorm1d):\n",
    "        blk.bn2.eps = 1e-3\n",
    "\n",
    "# ------------------------------------------------\n",
    "# 3) Helpers: extract TD(TCN) and transfer weights\n",
    "# ------------------------------------------------\n",
    "def get_first_td_tcn(tf_model):\n",
    "    for l in tf_model.layers:\n",
    "        if isinstance(l, tf.keras.layers.TimeDistributed) and isinstance(l.layer, tcn_pkg.TCN):\n",
    "            return l\n",
    "    raise RuntimeError(\"No TimeDistributed(TCN) found in TF model.\")\n",
    "\n",
    "def _tf_conv1d_to_torch(w_keras: np.ndarray) -> torch.Tensor:\n",
    "    # TF/Keras Conv1D: [kernel, in, out] -> PT Conv1d: [out, in, kernel]\n",
    "    return torch.from_numpy(np.transpose(w_keras, (2, 1, 0)))\n",
    "\n",
    "def _load_bn_tf_to_pt(pt_bn: nn.BatchNorm1d, tf_bn: tf.keras.layers.BatchNormalization):\n",
    "    gamma, beta, moving_mean, moving_var = tf_bn.get_weights()\n",
    "    pt_bn.weight.data = torch.from_numpy(gamma)\n",
    "    pt_bn.bias.data = torch.from_numpy(beta)\n",
    "    pt_bn.running_mean.data = torch.from_numpy(moving_mean)\n",
    "    pt_bn.running_var.data = torch.from_numpy(moving_var)\n",
    "\n",
    "def _kernel_size_1(conv: tf.keras.layers.Conv1D) -> bool:\n",
    "    ks = conv.kernel_size\n",
    "    ks = ks[0] if isinstance(ks, tuple) else ks\n",
    "    return ks == 1\n",
    "\n",
    "def _collect_tcn_sublayers(tf_tcn_layer: tf.keras.layers.Layer):\n",
    "    convs = [m for m in tf_tcn_layer.submodules if isinstance(m, tf.keras.layers.Conv1D)]\n",
    "    bns = [m for m in tf_tcn_layer.submodules if isinstance(m, tf.keras.layers.BatchNormalization)]\n",
    "    return convs, bns\n",
    "\n",
    "def transfer_td_tcn_weights(tf_td_tcn: tf.keras.layers.TimeDistributed, pt_tcn) -> None:\n",
    "    assert isinstance(tf_td_tcn, tf.keras.layers.TimeDistributed)\n",
    "    assert isinstance(tf_td_tcn.layer, tcn_pkg.TCN)\n",
    "    tf_tcn = tf_td_tcn.layer\n",
    "\n",
    "    convs, bns = _collect_tcn_sublayers(tf_tcn)\n",
    "    block_convs = [c for c in convs if not _kernel_size_1(c)]\n",
    "    resid_convs = [c for c in convs if _kernel_size_1(c)]  # includes residual 1x1 (and possibly skip 1x1s)\n",
    "\n",
    "    num_blocks = len(pt_tcn.blocks)\n",
    "    assert len(block_convs) == 2 * num_blocks, f\"Conv count mismatch: TF block convs={len(block_convs)}, PT blocks={num_blocks}\"\n",
    "\n",
    "    # Map conv1/conv2 + BN1/BN2\n",
    "    use_bn = isinstance(pt_tcn.blocks[0].bn1, nn.BatchNorm1d)\n",
    "    if use_bn:\n",
    "        assert len(bns) >= 2 * num_blocks, f\"BN count mismatch: TF BNs={len(bns)}, expected >= {2 * num_blocks}\"\n",
    "\n",
    "    for i, blk in enumerate(pt_tcn.blocks):\n",
    "        k1, b1 = block_convs[2 * i].get_weights()\n",
    "        blk.conv1.weight.data = _tf_conv1d_to_torch(k1)\n",
    "        blk.conv1.bias.data = torch.from_numpy(b1)\n",
    "\n",
    "        k2, b2 = block_convs[2 * i + 1].get_weights()\n",
    "        blk.conv2.weight.data = _tf_conv1d_to_torch(k2)\n",
    "        blk.conv2.bias.data = torch.from_numpy(b2)\n",
    "\n",
    "        if use_bn:\n",
    "            _load_bn_tf_to_pt(blk.bn1, bns[2 * i])\n",
    "            _load_bn_tf_to_pt(blk.bn2, bns[2 * i + 1])\n",
    "\n",
    "    # Residual 1x1 projection: only if PT block has it (assumes attribute name 'downsample' as you set)\n",
    "    resid_idx = 0\n",
    "    for blk in pt_tcn.blocks:\n",
    "        if isinstance(getattr(blk, \"downsample\", None), nn.Conv1d):\n",
    "            rk, rb = resid_convs[resid_idx].get_weights()\n",
    "            blk.downsample.weight.data = _tf_conv1d_to_torch(rk)\n",
    "            blk.downsample.bias.data = torch.from_numpy(rb)\n",
    "            resid_idx += 1\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# 4) Compare TCN-only outputs (TF TD(TCN) vs PT flat_tcn)\n",
    "# ------------------------------------------------------\n",
    "# Build a TF submodel that outputs the TimeDistributed(TCN) output only\n",
    "td = get_first_td_tcn(tf_model)\n",
    "tf_tcn_sub = tf.keras.Model(tf_model.inputs, td.output)  # -> (B, 1, conv_filters)\n",
    "\n",
    "# Transfer only the TCN weights TF -> PT (no head)\n",
    "transfer_td_tcn_weights(td, pt_model.flat_tcn)\n",
    "\n",
    "# Prepare inputs\n",
    "x_tf = x_np.reshape(batch_size, window_length, num_nodes * features_per_node)  # flattened for TF\n",
    "x_pt = torch.from_numpy(x_np)\n",
    "\n",
    "# Run\n",
    "tf_out = tf_tcn_sub([x_tf, a_np], training=False).numpy()   # (B, 1, C)\n",
    "tf_out = np.squeeze(tf_out, axis=1)                         # (B, C)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pt_out = pt_model.flat_tcn(x_pt.view(batch_size, window_length, num_nodes * features_per_node)).cpu().numpy()  # (B, C)\n",
    "\n",
    "# Report basic stats\n",
    "abs_diff = np.abs(tf_out - pt_out)\n",
    "print(\"TCN-only shapes -> TF:\", tf_out.shape, \"PT:\", pt_out.shape)\n",
    "print(\"TCN-only mean abs diff:\", abs_diff.mean())\n",
    "print(\"TCN-only max abs diff:\", abs_diff.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0754177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convs:\n",
      "   0: name=conv1D_0, kernel_size=3, filters=32\n",
      "   1: name=conv1D_1, kernel_size=3, filters=32\n",
      "   2: name=matching_conv1D, kernel_size=1, filters=32\n",
      "   3: name=conv1D_0, kernel_size=3, filters=32\n",
      "   4: name=conv1D_1, kernel_size=3, filters=32\n",
      "   5: name=conv1D_0, kernel_size=3, filters=32\n",
      "   6: name=conv1D_1, kernel_size=3, filters=32\n",
      "   7: name=conv1D_0, kernel_size=3, filters=32\n",
      "   8: name=conv1D_1, kernel_size=3, filters=32\n",
      "BNs:\n",
      "   0: name=batch_normalization, epsilon=0.001, momentum=0.99\n",
      "   1: name=batch_normalization_1, epsilon=0.001, momentum=0.99\n",
      "   2: name=batch_normalization_2, epsilon=0.001, momentum=0.99\n",
      "   3: name=batch_normalization_3, epsilon=0.001, momentum=0.99\n",
      "   4: name=batch_normalization_4, epsilon=0.001, momentum=0.99\n",
      "   5: name=batch_normalization_5, epsilon=0.001, momentum=0.99\n",
      "   6: name=batch_normalization_6, epsilon=0.001, momentum=0.99\n",
      "   7: name=batch_normalization_7, epsilon=0.001, momentum=0.99\n"
     ]
    }
   ],
   "source": [
    "def inspect_tf_tcn(tf_model):\n",
    "    import tcn as tcn_pkg\n",
    "    from tensorflow.keras.layers import TimeDistributed, Conv1D, BatchNormalization\n",
    "\n",
    "    td = None\n",
    "    for l in tf_model.layers:\n",
    "        if isinstance(l, TimeDistributed) and isinstance(l.layer, tcn_pkg.TCN):\n",
    "            td = l; break\n",
    "    assert td is not None, \"No TimeDistributed(TCN) found.\"\n",
    "\n",
    "    tf_tcn = td.layer\n",
    "    convs = [m for m in tf_tcn.submodules if isinstance(m, Conv1D)]\n",
    "    bns   = [m for m in tf_tcn.submodules if isinstance(m, BatchNormalization)]\n",
    "\n",
    "    print(\"Convs:\")\n",
    "    for i, c in enumerate(convs):\n",
    "        ks = c.kernel_size[0] if isinstance(c.kernel_size, tuple) else c.kernel_size\n",
    "        print(f\"  {i:2d}: name={c.name}, kernel_size={ks}, filters={c.filters}\")\n",
    "    print(\"BNs:\")\n",
    "    for i, b in enumerate(bns):\n",
    "        print(f\"  {i:2d}: name={b.name}, epsilon={b.epsilon}, momentum={b.momentum}\")\n",
    "\n",
    "inspect_tf_tcn(tf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f9f960",
   "metadata": {},
   "source": [
    "# TCN decoder test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07a9dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# TensorFlow + keras-tcn for building the reference TF decoder and grabbing weights\n",
    "import tensorflow as tf\n",
    "import tcn as tcn_pkg\n",
    "\n",
    "# The TF probabilistic decoder layer type (for weight transfer)\n",
    "# If your TF class lives elsewhere, adjust this import accordingly.\n",
    "import deepof\n",
    "from deepof.model_utils import ProbabilisticDecoder as ProbabilisticDecoderTF\n",
    "\n",
    "# The PT probabilistic decoder (you said this already exists)\n",
    "# Adjust import path if needed.\n",
    "from deepof.clustering.model_utils_new import ProbabilisticDecoderPT\n",
    "\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Bidirectional, GRU, LayerNormalization, Masking\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    GRU,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    LayerNormalization,\n",
    "    RepeatVector,\n",
    "    TimeDistributed,\n",
    ")\n",
    "import tensorflow as tf\n",
    "import tcn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75dc8894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TCN_decoder(\n",
    "    input_shape: tuple,\n",
    "    latent_dim: int,\n",
    "    conv_filters: int = 64,\n",
    "    kernel_size: int = 4,\n",
    "    conv_stacks: int = 1,\n",
    "    conv_dilations: tuple = (8, 4, 2, 1),\n",
    "    padding: str = \"causal\",\n",
    "    use_skip_connections: bool = True,\n",
    "    dropout_rate: int = 0,\n",
    "    activation: str = \"relu\",\n",
    "):\n",
    "    \"\"\"Return a Temporal Convolutional Network (TCN) decoder.\n",
    "\n",
    "    Builds a neural network that can be used to decode a latent space into a sequence of\n",
    "    motion tracking instances. Each layer contains a residual block with a convolutional layer and a skip connection. See\n",
    "    the following paper for more details: https://arxiv.org/pdf/1803.01271.pdf,\n",
    "\n",
    "    Args:\n",
    "        input_shape: shape of the input data\n",
    "        latent_dim: dimensionality of the latent space\n",
    "        conv_filters: number of filters in the TCN layers\n",
    "        kernel_size: size of the convolutional kernels\n",
    "        conv_stacks: number of TCN layers\n",
    "        conv_dilations: list of dilation factors for each TCN layer\n",
    "        padding: padding mode for the TCN layers\n",
    "        use_skip_connections: whether to use skip connections between TCN layers\n",
    "        dropout_rate: dropout rate for the TCN layers\n",
    "        activation: activation function for the TCN layers\n",
    "\n",
    "    Returns:\n",
    "        keras.Model: a keras model that can be trained to decode a latent space into a sequence of motion tracking\n",
    "        instances using temporal convolutional networks.\n",
    "\n",
    "    \"\"\"\n",
    "    # Define and instantiate generator\n",
    "    g = Input(shape=latent_dim)  # Decoder input, shaped as the latent space\n",
    "    x = Input(shape=input_shape)  # Encoder input, used to generate an output mask\n",
    "    validity_mask = tf.math.logical_not(tf.reduce_all(x == 0.0, axis=2))\n",
    "\n",
    "    generator = tf.keras.layers.Dense(latent_dim)(g)\n",
    "    generator = tf.keras.layers.BatchNormalization()(generator)\n",
    "    generator = tf.keras.layers.Dense(2 * latent_dim, activation=\"relu\")(generator)\n",
    "    generator = tf.keras.layers.BatchNormalization()(generator)\n",
    "    generator = tf.keras.layers.Dense(4 * latent_dim, activation=\"relu\")(generator)\n",
    "    generator = tf.keras.layers.BatchNormalization()(generator)\n",
    "    generator = tf.keras.layers.RepeatVector(input_shape[0])(generator)\n",
    "\n",
    "    generator = tcn.TCN(\n",
    "        conv_filters,\n",
    "        kernel_size,\n",
    "        conv_stacks,\n",
    "        conv_dilations,\n",
    "        padding,\n",
    "        use_skip_connections,\n",
    "        dropout_rate,\n",
    "        return_sequences=True,\n",
    "        activation=activation,\n",
    "        kernel_initializer=\"random_normal\",\n",
    "        use_batch_norm=True,\n",
    "    )(generator)\n",
    "\n",
    "    x_decoded = deepof.model_utils.ProbabilisticDecoder(input_shape)(\n",
    "        [generator, validity_mask]\n",
    "    )\n",
    "\n",
    "    return Model([g, x], x_decoded, name=\"TCN_decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52b11693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepof.clustering.models_new import TCN1DPT, TemporalBlockPT, _act\n",
    "\n",
    "\n",
    "\n",
    "class TCNDecoderPT(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch port of TF get_TCN_decoder:\n",
    "      - g: (B, latent_dim)\n",
    "      - x: (B, W, NNF) or (B, W, N, NF) for mask computation\n",
    "      Pipeline:\n",
    "        Dense(latent) -> BN ->\n",
    "        Dense(2*latent, relu) -> BN ->\n",
    "        Dense(4*latent, relu) -> BN ->\n",
    "        RepeatVector(W) ->\n",
    "        TCN(return_sequences=True) ->\n",
    "        ProbabilisticDecoderPT(hidden_dim=conv_filters, data_dim=NNF)\n",
    "      Returns: a distribution whose .mean is (B, W, NNF)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: Tuple[int, int],   # (W, NNF)\n",
    "        latent_dim: int,\n",
    "        conv_filters: int = 64,\n",
    "        kernel_size: int = 4,\n",
    "        conv_stacks: int = 1,\n",
    "        conv_dilations: Iterable[int] = (8, 4, 2, 1),\n",
    "        padding: str = \"causal\",\n",
    "        use_skip_connections: bool = True,\n",
    "        dropout_rate: float = 0.0,\n",
    "        activation: str = \"relu\",\n",
    "        use_batch_norm: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.W, self.data_dim = int(input_shape[0]), int(input_shape[1])\n",
    "        self.latent_dim = int(latent_dim)\n",
    "\n",
    "        # Front MLP: Dense -> BN -> Dense(relu) -> BN -> Dense(relu) -> BN\n",
    "        self.fc0 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.bn0 = nn.BatchNorm1d(latent_dim, eps=1e-3)\n",
    "\n",
    "        self.fc1 = nn.Linear(latent_dim, 2 * latent_dim)\n",
    "        self.act1 = _act(activation)\n",
    "        self.bn1 = nn.BatchNorm1d(2 * latent_dim, eps=1e-3)\n",
    "\n",
    "        self.fc2 = nn.Linear(2 * latent_dim, 4 * latent_dim)\n",
    "        self.act2 = _act(activation)\n",
    "        self.bn2 = nn.BatchNorm1d(4 * latent_dim, eps=1e-3)\n",
    "\n",
    "        # TCN over repeated latent sequence\n",
    "        self.tcn = TCN1DPT(\n",
    "            in_channels=4 * latent_dim,\n",
    "            conv_filters=conv_filters,\n",
    "            kernel_size=kernel_size,\n",
    "            conv_stacks=conv_stacks,\n",
    "            conv_dilations=conv_dilations,\n",
    "            padding=padding,\n",
    "            use_skip_connections=use_skip_connections,\n",
    "            dropout_rate=float(dropout_rate),\n",
    "            activation=activation,\n",
    "            use_batch_norm=use_batch_norm,\n",
    "            return_sequences=True,\n",
    "        )\n",
    "\n",
    "        # Probabilistic reconstruction head\n",
    "        self.prob_decoder = ProbabilisticDecoderPT(hidden_dim=conv_filters, data_dim=self.data_dim)\n",
    "\n",
    "        # Init linear layers (BN stats copied by transfer)\n",
    "        for m in [self.fc0, self.fc1, self.fc2]:\n",
    "            nn.init.xavier_uniform_(m.weight); nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, g: torch.Tensor, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        g: (B, latent_dim)\n",
    "        x: (B, W, NNF) or (B, W, N, NF)  -> used only to compute validity mask\n",
    "        returns: distribution with .mean of shape (B, W, NNF)\n",
    "        \"\"\"\n",
    "        B = g.shape[0]\n",
    "        # Build validity mask as in TF: logical_not(reduce_all(x == 0, axis=2))\n",
    "        if x.dim() == 4:\n",
    "            # (B, W, N, NF) -> (B, W, N*NF)\n",
    "            x_flat = x.view(x.size(0), x.size(1), -1)\n",
    "        else:\n",
    "            x_flat = x\n",
    "        validity_mask = ~torch.all(x_flat == 0.0, dim=-1)  # (B, W), bool\n",
    "\n",
    "        # Generator MLP\n",
    "        z = self.bn0(self.fc0(g))\n",
    "        z = self.bn1(self.act1(self.fc1(z)))\n",
    "        z = self.bn2(self.act2(self.fc2(z)))\n",
    "\n",
    "        # Repeat across time (RepeatVector)\n",
    "        z_rep = z.unsqueeze(1).repeat(1, self.W, 1)  # (B, W, 4*latent)\n",
    "\n",
    "        # Temporal block\n",
    "        hidden_seq = self.tcn(z_rep)  # (B, W, conv_filters)\n",
    "\n",
    "        # Probabilistic reconstruction\n",
    "        return self.prob_decoder(hidden_seq, validity_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73f2a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tf_conv1d_to_torch(w_keras: np.ndarray) -> torch.Tensor:\n",
    "    # TF Conv1D: [K, Cin, Cout] -> PT Conv1d: [Cout, Cin, K]\n",
    "    return torch.from_numpy(np.transpose(w_keras, (2, 1, 0)))\n",
    "\n",
    "\n",
    "def _load_bn_tf_to_pt(pt_bn: nn.BatchNorm1d, tf_bn: tf.keras.layers.BatchNormalization):\n",
    "    gamma, beta, moving_mean, moving_var = tf_bn.get_weights()\n",
    "    pt_bn.weight.data = torch.from_numpy(gamma)\n",
    "    pt_bn.bias.data = torch.from_numpy(beta)\n",
    "    pt_bn.running_mean.data = torch.from_numpy(moving_mean)\n",
    "    pt_bn.running_var.data = torch.from_numpy(moving_var)\n",
    "\n",
    "\n",
    "def _collect_tcn_sublayers(tf_tcn_layer: tf.keras.layers.Layer):\n",
    "    from tensorflow.keras.layers import Conv1D, BatchNormalization\n",
    "    convs = [m for m in tf_tcn_layer.submodules if isinstance(m, Conv1D)]\n",
    "    bns = [m for m in tf_tcn_layer.submodules if isinstance(m, BatchNormalization)]\n",
    "    return convs, bns\n",
    "\n",
    "\n",
    "def _is_1x1(conv: tf.keras.layers.Conv1D) -> bool:\n",
    "    ks = conv.kernel_size\n",
    "    ks = ks[0] if isinstance(ks, tuple) else ks\n",
    "    return ks == 1\n",
    "\n",
    "\n",
    "def transfer_decoder_front_mlp_weights(tf_model: tf.keras.Model, pt_model: TCNDecoderPT):\n",
    "    \"\"\"\n",
    "    Map the three Dense + three BN layers before RepeatVector in order.\n",
    "    TF sequence: Dense(latent) -> BN -> Dense(2*latent, relu) -> BN -> Dense(4*latent, relu) -> BN\n",
    "    PT: fc0/bn0, fc1/bn1, fc2/bn2 (with relu applied before BN for fc1,fc2).\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "    denses = [l for l in tf_model.layers if isinstance(l, Dense)]\n",
    "    bns = [l for l in tf_model.layers if isinstance(l, BatchNormalization)]\n",
    "\n",
    "    # Use the first three Dense and first three BN layers encountered (decoder-local)\n",
    "    d0, d1, d2 = denses[0], denses[1], denses[2]\n",
    "    bn0, bn1, bn2 = bns[0], bns[1], bns[2]\n",
    "\n",
    "    # Dense 0\n",
    "    w, b = d0.get_weights()\n",
    "    pt_model.fc0.weight.data = torch.from_numpy(w.T)\n",
    "    pt_model.fc0.bias.data = torch.from_numpy(b)\n",
    "    _load_bn_tf_to_pt(pt_model.bn0, bn0)\n",
    "\n",
    "    # Dense 1\n",
    "    w, b = d1.get_weights()\n",
    "    pt_model.fc1.weight.data = torch.from_numpy(w.T)\n",
    "    pt_model.fc1.bias.data = torch.from_numpy(b)\n",
    "    _load_bn_tf_to_pt(pt_model.bn1, bn1)\n",
    "\n",
    "    # Dense 2\n",
    "    w, b = d2.get_weights()\n",
    "    pt_model.fc2.weight.data = torch.from_numpy(w.T)\n",
    "    pt_model.fc2.bias.data = torch.from_numpy(b)\n",
    "    _load_bn_tf_to_pt(pt_model.bn2, bn2)\n",
    "\n",
    "\n",
    "def transfer_tcn_weights(tf_tcn_layer: tcn_pkg.TCN, pt_tcn: TCN1DPT):\n",
    "    \"\"\"\n",
    "    Transfer weights from a Keras tcn.TCN layer to our TCN1DPT (no TimeDistributed).\n",
    "    - Maps per-block conv1/conv2 + BN\n",
    "    - Maps residual 1x1 projection(s) if present\n",
    "    \"\"\"\n",
    "    convs, bns = _collect_tcn_sublayers(tf_tcn_layer)\n",
    "    block_convs = [c for c in convs if not _is_1x1(c)]\n",
    "    conv1x1 = [c for c in convs if _is_1x1(c)]\n",
    "    num_blocks = len(pt_tcn.blocks)\n",
    "\n",
    "    assert len(block_convs) == 2 * num_blocks, f\"Conv count mismatch: TF block convs={len(block_convs)}, PT blocks={num_blocks}\"\n",
    "\n",
    "    use_bn = isinstance(pt_tcn.blocks[0].bn1, nn.BatchNorm1d)\n",
    "    if use_bn:\n",
    "        assert len(bns) >= 2 * num_blocks, f\"BN count mismatch: TF BNs={len(bns)}, expected >= {2 * num_blocks}\"\n",
    "\n",
    "    # Load block convs and BN params\n",
    "    for i, blk in enumerate(pt_tcn.blocks):\n",
    "        k1, b1 = block_convs[2 * i].get_weights()\n",
    "        blk.conv1.weight.data = _tf_conv1d_to_torch(k1)\n",
    "        blk.conv1.bias.data = torch.from_numpy(b1)\n",
    "\n",
    "        k2, b2 = block_convs[2 * i + 1].get_weights()\n",
    "        blk.conv2.weight.data = _tf_conv1d_to_torch(k2)\n",
    "        blk.conv2.bias.data = torch.from_numpy(b2)\n",
    "\n",
    "        if use_bn:\n",
    "            _load_bn_tf_to_pt(blk.bn1, bns[2 * i])\n",
    "            _load_bn_tf_to_pt(blk.bn2, bns[2 * i + 1])\n",
    "\n",
    "    # Residual projections if any (first blocks typically)\n",
    "    proj_idx = 0\n",
    "    for blk in pt_tcn.blocks:\n",
    "        if isinstance(getattr(blk, \"downsample\", None), nn.Conv1d):\n",
    "            rk, rb = conv1x1[proj_idx].get_weights()\n",
    "            blk.downsample.weight.data = _tf_conv1d_to_torch(rk)\n",
    "            blk.downsample.bias.data = torch.from_numpy(rb)\n",
    "            proj_idx += 1\n",
    "\n",
    "\n",
    "def transfer_prob_decoder_weights(tf_prob_layer: ProbabilisticDecoderTF, pt_prob: ProbabilisticDecoderPT):\n",
    "    \"\"\"\n",
    "    Copy the final projection Dense from TF ProbabilisticDecoder to PT ProbabilisticDecoderPT.loc_projection.\n",
    "    Assumes TF layer exposes a single Dense with [hidden_dim, data_dim] kernel and bias at get_weights()[:2].\n",
    "    \"\"\"\n",
    "    w, b = tf_prob_layer.get_weights()[:2]\n",
    "    pt_prob.loc_projection.weight.data = torch.from_numpy(w.T)\n",
    "    pt_prob.loc_projection.bias.data = torch.from_numpy(b)\n",
    "\n",
    "\n",
    "def transfer_tcn_decoder_weights(tf_model: tf.keras.Model, pt_model: TCNDecoderPT):\n",
    "    \"\"\"\n",
    "    Orchestrates the full TF -> PT transfer for the decoder:\n",
    "      - Front MLP (3x Dense + 3x BN)\n",
    "      - TCN\n",
    "      - Probabilistic head projection\n",
    "    \"\"\"\n",
    "    # 1) Front MLP\n",
    "    transfer_decoder_front_mlp_weights(tf_model, pt_model)\n",
    "\n",
    "    # 2) TCN\n",
    "    tf_tcn_layer = next(l for l in tf_model.layers if isinstance(l, tcn_pkg.TCN))\n",
    "    transfer_tcn_weights(tf_tcn_layer, pt_model.tcn)\n",
    "\n",
    "    # 3) Probabilistic head\n",
    "    tf_prob_layer = next(l for l in tf_model.layers if isinstance(l, ProbabilisticDecoderTF))\n",
    "    transfer_prob_decoder_weights(tf_prob_layer, pt_model.prob_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac075ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_tcn_decoder_full_parity (__main__.TestTCNDecoderPT) ... ok\n",
      "test_tcn_only_parity (__main__.TestTCNDecoderPT)\n",
      "Optional: compare TCN outputs (before probabilistic head). ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder TF time: 0.09670162200927734 PT time: 0.011658430099487305\n",
      "✅ TCNDecoderPT end-to-end parity PASSED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.956s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TCN-only (pre-prob head) parity PASSED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "import time\n",
    "\n",
    "# Assume get_TCN_decoder is available in your environment (as per your note)\n",
    "\n",
    "\n",
    "class TestTCNDecoderPT(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        # Shapes (use your conventions)\n",
    "        self.B = 32\n",
    "        self.W = 25\n",
    "        self.N = 11\n",
    "        self.NF = 3\n",
    "        self.NNF = self.N * self.NF\n",
    "        self.latent_dim = 6\n",
    "\n",
    "        # Decoder params (keep small for speed; mirror TF defaults where relevant)\n",
    "        self.conv_filters = 32\n",
    "        self.kernel_size = 4\n",
    "        self.conv_stacks = 1\n",
    "        self.conv_dilations = (8, 4, 2, 1)\n",
    "        self.padding = \"causal\"\n",
    "        self.use_skip = True\n",
    "        self.dropout = 0.0\n",
    "        self.activation = \"relu\"\n",
    "\n",
    "        # Random inputs\n",
    "        rng = np.random.default_rng(0)\n",
    "        self.g_np = rng.normal(size=(self.B, self.latent_dim)).astype(np.float32)\n",
    "        self.x_np = rng.normal(size=(self.B, self.W, self.NNF)).astype(np.float32)\n",
    "\n",
    "        # Inject some zero windows to exercise the mask path\n",
    "        mask_rows = rng.integers(0, self.B, size=self.B // 8)\n",
    "        mask_ts = rng.integers(0, self.W, size=self.B // 8)\n",
    "        self.x_np[mask_rows, mask_ts, :] = 0.0\n",
    "\n",
    "    def test_tcn_decoder_full_parity(self):\n",
    "        # Build TF and PT models\n",
    "        tf_model = get_TCN_decoder(\n",
    "            input_shape=(self.W, self.NNF),\n",
    "            latent_dim=self.latent_dim,\n",
    "            conv_filters=self.conv_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            conv_stacks=self.conv_stacks,\n",
    "            conv_dilations=self.conv_dilations,\n",
    "            padding=self.padding,\n",
    "            use_skip_connections=self.use_skip,\n",
    "            dropout_rate=self.dropout,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "        pt_model = TCNDecoderPT(\n",
    "            input_shape=(self.W, self.NNF),\n",
    "            latent_dim=self.latent_dim,\n",
    "            conv_filters=self.conv_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            conv_stacks=self.conv_stacks,\n",
    "            conv_dilations=self.conv_dilations,\n",
    "            padding=self.padding,\n",
    "            use_skip_connections=self.use_skip,\n",
    "            dropout_rate=self.dropout,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "        pt_model.eval()\n",
    "\n",
    "        # Transfer weights\n",
    "        transfer_tcn_decoder_weights(tf_model, pt_model)\n",
    "\n",
    "        # Compare outputs\n",
    "        t0 = time.time()\n",
    "        y_tf = tf_model([self.g_np, self.x_np], training=False).mean().numpy() # (B, W, NNF)\n",
    "        t1 = time.time()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            dist_pt = pt_model(torch.from_numpy(self.g_np), torch.from_numpy(self.x_np))\n",
    "            y_pt = dist_pt.mean.detach().cpu().numpy()  # (B, W, NNF)\n",
    "        t2 = time.time()\n",
    "\n",
    "        print(\"Decoder TF time:\", t1 - t0, \"PT time:\", t2 - t1)\n",
    "        np.testing.assert_allclose(y_tf, y_pt, rtol=1e-5, atol=2e-4)\n",
    "        print(\"✅ TCNDecoderPT end-to-end parity PASSED\")\n",
    "\n",
    "    def test_tcn_only_parity(self):\n",
    "        \"\"\"\n",
    "        Optional: compare TCN outputs (before probabilistic head).\n",
    "        \"\"\"\n",
    "        # Build TF/PT decoders\n",
    "        tf_model = get_TCN_decoder(\n",
    "            input_shape=(self.W, self.NNF),\n",
    "            latent_dim=self.latent_dim,\n",
    "            conv_filters=self.conv_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            conv_stacks=self.conv_stacks,\n",
    "            conv_dilations=self.conv_dilations,\n",
    "            padding=self.padding,\n",
    "            use_skip_connections=self.use_skip,\n",
    "            dropout_rate=self.dropout,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "        pt_model = TCNDecoderPT(\n",
    "            input_shape=(self.W, self.NNF),\n",
    "            latent_dim=self.latent_dim,\n",
    "            conv_filters=self.conv_filters,\n",
    "            kernel_size=self.kernel_size,\n",
    "            conv_stacks=self.conv_stacks,\n",
    "            conv_dilations=self.conv_dilations,\n",
    "            padding=self.padding,\n",
    "            use_skip_connections=self.use_skip,\n",
    "            dropout_rate=self.dropout,\n",
    "            activation=self.activation,\n",
    "        )\n",
    "        pt_model.eval()\n",
    "\n",
    "        # Transfer weights (front MLP + TCN only; prob head not needed for this test)\n",
    "        transfer_decoder_front_mlp_weights(tf_model, pt_model)\n",
    "        tf_tcn_layer = next(l for l in tf_model.layers if isinstance(l, tcn_pkg.TCN))\n",
    "        transfer_tcn_weights(tf_tcn_layer, pt_model.tcn)\n",
    "\n",
    "        # Build TF submodel up to TCN output\n",
    "        g_in, x_in = tf_model.inputs\n",
    "        tf_tcn_sub = tf.keras.Model([g_in, x_in], tf_tcn_layer.output)  # (B, W, conv_filters)\n",
    "\n",
    "        # Compute TF TCN output\n",
    "        y_tf_tcn = tf_tcn_sub([self.g_np, self.x_np], training=False).numpy()\n",
    "\n",
    "        # Compute PT TCN output\n",
    "        with torch.no_grad():\n",
    "            g_pt = torch.from_numpy(self.g_np)\n",
    "            # Front MLP\n",
    "            z = pt_model.bn0(pt_model.fc0(g_pt))\n",
    "            z = pt_model.bn1(pt_model.act1(pt_model.fc1(z)))\n",
    "            z = pt_model.bn2(pt_model.act2(pt_model.fc2(z)))\n",
    "            # Repeat and TCN\n",
    "            z_rep = z.unsqueeze(1).repeat(1, self.W, 1)\n",
    "            y_pt_tcn = pt_model.tcn(z_rep).detach().cpu().numpy()\n",
    "\n",
    "        np.testing.assert_allclose(y_tf_tcn, y_pt_tcn, rtol=1e-5, atol=2e-4)\n",
    "        print(\"✅ TCN-only (pre-prob head) parity PASSED\")\n",
    "\n",
    "\n",
    "# Run tests\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestTCNDecoderPT)\n",
    "runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155bc540",
   "metadata": {},
   "source": [
    "# Transformer encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d050f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) IMPORTS\n",
    "\n",
    "from typing import Iterable, Tuple, List\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import deepof\n",
    "from spektral.layers import CensNetConv\n",
    "\n",
    "\n",
    "\n",
    "# TensorFlow + keras for the reference model and weights\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, TimeDistributed, Bidirectional, GRU, LayerNormalization, Masking\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Your TF entry-point we will test against (provided by you)\n",
    "# from your_module import get_transformer_encoder  # assumed available in the notebook\n",
    "\n",
    "# We will scan for these types inside the TF Transformer layer\n",
    "from tensorflow.keras.layers import (\n",
    "    TimeDistributed,\n",
    "    Conv1D,\n",
    "    Dense,\n",
    "    LayerNormalization,\n",
    "    MultiHeadAttention,\n",
    "    BatchNormalization,\n",
    ")\n",
    "\n",
    "# Your PT graph block (same API as used for TCN encoder)\n",
    "from deepof.clustering.censNetConv_pt import CensNetConvPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a53df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_transformer_encoder(\n",
    "    input_shape: tuple,\n",
    "    edge_feature_shape: tuple,\n",
    "    adjacency_matrix: np.ndarray,\n",
    "    latent_dim: int,\n",
    "    use_gnn: bool = True,\n",
    "    num_layers: int = 4,\n",
    "    num_heads: int = 64,\n",
    "    dff: int = 128,\n",
    "    dropout_rate: float = 0.1,\n",
    "    interaction_regularization: float = 0.0,\n",
    "):\n",
    "    \"\"\"Build a Transformer encoder.\n",
    "\n",
    "    Based on https://www.tensorflow.org/text/tutorials/transformer.\n",
    "    Adapted according to https://academic.oup.com/gigascience/article/8/11/giz134/5626377?login=true\n",
    "    and https://arxiv.org/abs/1711.03905.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): shape of the input data\n",
    "        edge_feature_shape (tuple): shape of the adjacency matrix to use in the graph attention layers. Should be time x edges x features.\n",
    "        adjacency_matrix (np.ndarray): adjacency matrix for the mice connectivity graph. Shape should be nodes x nodes.\n",
    "        latent_dim (int): dimensionality of the latent space\n",
    "        use_gnn (bool): If True, the encoder uses a graph representation of the input, with coordinates and speeds as node attributes, and distances as edge attributes. If False, a regular 3D tensor is used as input.\n",
    "        num_layers (int): number of transformer layers to include\n",
    "        num_heads (int): number of heads of the multi-head-attention layers used on the transformer encoder\n",
    "        dff (int): dimensionality of the token embeddings\n",
    "        dropout_rate (float): dropout rate\n",
    "        interaction_regularization (float): regularization parameter for the interaction features\n",
    "\n",
    "    \"\"\"\n",
    "    # Define feature and adjacency inputs\n",
    "    x = Input(shape=input_shape)\n",
    "    a = Input(shape=edge_feature_shape)\n",
    "\n",
    "    if use_gnn:\n",
    "        x_reshaped = tf.transpose(\n",
    "            tf.reshape(\n",
    "                tf.transpose(x),\n",
    "                [\n",
    "                    -1,\n",
    "                    adjacency_matrix.shape[-1],\n",
    "                    x.shape[1],\n",
    "                    input_shape[-1] // adjacency_matrix.shape[-1],\n",
    "                ][::-1],\n",
    "            )\n",
    "        )\n",
    "        a_reshaped = tf.transpose(\n",
    "            tf.reshape(\n",
    "                tf.transpose(a),\n",
    "                [\n",
    "                    -1,\n",
    "                    edge_feature_shape[-1],\n",
    "                    a.shape[1],\n",
    "                    1,\n",
    "                ][::-1],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        x_reshaped = tf.expand_dims(x, axis=1)\n",
    "\n",
    "    transformer_embedding = TimeDistributed(\n",
    "        deepof.clustering.model_utils_new.TransformerEncoder(\n",
    "            num_layers=num_layers,\n",
    "            seq_dim=input_shape[-1],\n",
    "            key_dim=input_shape[-1],\n",
    "            num_heads=num_heads,\n",
    "            dff=dff,\n",
    "            maximum_position_encoding=input_shape[0],\n",
    "            rate=dropout_rate,\n",
    "        )\n",
    "    )(x_reshaped, training=False)\n",
    "    transformer_embedding = tf.reshape(\n",
    "        transformer_embedding,\n",
    "        [\n",
    "            -1,\n",
    "            (adjacency_matrix.shape[0] if x_reshaped.shape[1] != 1 else 1),\n",
    "            input_shape[0] * input_shape[1],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    if use_gnn:\n",
    "\n",
    "        # Embed edge features too\n",
    "        transformer_a_embedding = TimeDistributed(\n",
    "            deepof.clustering.model_utils_new.TransformerEncoder(\n",
    "                num_layers=num_layers,\n",
    "                seq_dim=input_shape[-1],\n",
    "                key_dim=input_shape[-1],\n",
    "                num_heads=num_heads,\n",
    "                dff=dff,\n",
    "                maximum_position_encoding=input_shape[0],\n",
    "                rate=dropout_rate,\n",
    "            )\n",
    "        )(a_reshaped, training=False)\n",
    "\n",
    "        transformer_a_embedding = tf.reshape(\n",
    "            transformer_a_embedding,\n",
    "            [-1, adjacency_matrix.shape[0], input_shape[0] * input_shape[1]],\n",
    "        )\n",
    "\n",
    "        spatial_block = CensNetConv(\n",
    "            node_channels=latent_dim,\n",
    "            edge_channels=latent_dim,\n",
    "            activation=\"relu\",\n",
    "            node_regularizer=tf.keras.regularizers.l1(interaction_regularization),\n",
    "        )\n",
    "\n",
    "        # Process adjacency matrix\n",
    "        laplacian, edge_laplacian, incidence = spatial_block.preprocess(\n",
    "            adjacency_matrix\n",
    "        )\n",
    "\n",
    "        # Get and concatenate node and edge embeddings\n",
    "        x_nodes, x_edges = spatial_block(\n",
    "            [\n",
    "                transformer_embedding,\n",
    "                (laplacian, edge_laplacian, incidence),\n",
    "                transformer_a_embedding,\n",
    "            ],\n",
    "            mask=None,\n",
    "        )\n",
    "\n",
    "        x_nodes = tf.reshape(\n",
    "            x_nodes,\n",
    "            [-1, adjacency_matrix.shape[-1] * latent_dim],\n",
    "        )\n",
    "\n",
    "        x_edges = tf.reshape(\n",
    "            x_edges,\n",
    "            [-1, edge_feature_shape[-1] * latent_dim],\n",
    "        )\n",
    "\n",
    "        transformer_embedding = tf.concat([x_nodes, x_edges], axis=-1)\n",
    "\n",
    "    else:\n",
    "        transformer_embedding = tf.squeeze(transformer_embedding, axis=1)\n",
    "\n",
    "    encoder = tf.keras.layers.Dense(2 * latent_dim, activation=\"relu\")(\n",
    "        transformer_embedding\n",
    "    )\n",
    "    encoder = tf.keras.layers.BatchNormalization()(encoder)\n",
    "    encoder = tf.keras.layers.Dense(latent_dim, activation=\"relu\")(encoder)\n",
    "    encoder = tf.keras.layers.BatchNormalization()(encoder)\n",
    "    encoder = tf.keras.layers.Dense(latent_dim)(encoder)\n",
    "\n",
    "    return tf.keras.models.Model([x, a], encoder, name=\"transformer_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a970884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _act(name: str) -> nn.Module:\n",
    "    name = (name or \"relu\").lower()\n",
    "    if name == \"relu\": return nn.ReLU()\n",
    "    if name == \"gelu\": return nn.GELU()\n",
    "    if name == \"tanh\": return nn.Tanh()\n",
    "    if name == \"leaky_relu\": return nn.LeakyReLU(0.2)\n",
    "    if name in {\"linear\", \"identity\", \"none\"}: return nn.Identity()\n",
    "    raise ValueError(f\"Unsupported activation: {name}\")\n",
    "\n",
    "\n",
    "class BatchNorm1dKerasFP32(nn.BatchNorm1d):\n",
    "    \"\"\"Keras-like BatchNorm with eps=1e-3 and momentum=0.01 (Keras uses 0.99).\"\"\"\n",
    "    def __init__(self, num_features, eps=1e-3, momentum=0.01, affine=True, track_running_stats=True):\n",
    "        super().__init__(num_features, eps=eps, momentum=momentum, affine=affine, track_running_stats=track_running_stats)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        y = super().forward(x.float())\n",
    "        return y.to(dtype=x.dtype)\n",
    "\n",
    "\n",
    "def sinusoidal_positional_encoding(max_len: int, d_model: int, device=None, dtype=torch.float32) -> torch.Tensor:\n",
    "    \"\"\"Generate sinusoidal positional encodings.\"\"\"\n",
    "    pe = torch.zeros(max_len, d_model, dtype=dtype, device=device)\n",
    "    position = torch.arange(0, max_len, dtype=dtype, device=device).unsqueeze(1)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2, dtype=dtype, device=device) * (-np.log(10000.0) / d_model))\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "    n_odd = pe[:, 1::2].shape[1]\n",
    "    pe[:, 1::2] = torch.cos(position * div_term)[:, :n_odd]\n",
    "    return pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "\n",
    "\n",
    "class MultiHeadAttentionPT(nn.Module):\n",
    "    \"\"\"Multi-head attention layer compatible with Keras implementation.\"\"\"\n",
    "    def __init__(self, in_dim: int, num_heads: int, key_dim: int, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.in_dim = int(in_dim)\n",
    "        self.num_heads = int(num_heads)\n",
    "        self.key_dim = int(key_dim)\n",
    "        self.inner_dim = self.num_heads * self.key_dim\n",
    "\n",
    "        self.q_proj = nn.Linear(self.in_dim, self.inner_dim, bias=True)\n",
    "        self.k_proj = nn.Linear(self.in_dim, self.inner_dim, bias=True)\n",
    "        self.v_proj = nn.Linear(self.in_dim, self.inner_dim, bias=True)\n",
    "        self.out_proj = nn.Linear(self.inner_dim, self.in_dim, bias=True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        for m in [self.q_proj, self.k_proj, self.v_proj, self.out_proj]:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        B, T, _ = x.shape\n",
    "\n",
    "        def proj(linear: nn.Linear):\n",
    "            y = linear(x)\n",
    "            return y.reshape(B, T, self.num_heads, self.key_dim).permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        q = proj(self.q_proj)\n",
    "        k = proj(self.k_proj)\n",
    "        v = proj(self.v_proj)\n",
    "\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / (self.key_dim ** 0.5)\n",
    "        if attn_mask is not None:\n",
    "            scores = scores.masked_fill(attn_mask.unsqueeze(1).unsqueeze(2), float(\"-inf\"))\n",
    "\n",
    "        attn = torch.softmax(scores, dim=-1)\n",
    "        attn = self.dropout(attn)\n",
    "        ctx = torch.matmul(attn, v)\n",
    "        ctx = ctx.permute(0, 2, 1, 3).contiguous().reshape(B, T, self.inner_dim)\n",
    "        out = self.out_proj(ctx)\n",
    "\n",
    "        if attn_mask is not None:\n",
    "            out = out.masked_fill(attn_mask.unsqueeze(-1), 0.0)\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransformerEncoderLayerPT(nn.Module):\n",
    "    \"\"\"Transformer encoder layer with post-normalization.\"\"\"\n",
    "    def __init__(self, key_dim: int, num_heads: int, dff: int, rate: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttentionPT(in_dim=key_dim, num_heads=num_heads, key_dim=key_dim, dropout=rate)\n",
    "        self.dropout1 = nn.Dropout(rate)\n",
    "        self.norm1 = nn.LayerNorm(key_dim, eps=1e-6)\n",
    "\n",
    "        self.ffn1 = nn.Linear(key_dim, dff)\n",
    "        self.act = nn.ReLU()\n",
    "        self.ffn2 = nn.Linear(dff, key_dim)\n",
    "        self.dropout2 = nn.Dropout(rate)\n",
    "        self.norm2 = nn.LayerNorm(key_dim, eps=1e-6)\n",
    "\n",
    "        for m in [self.ffn1, self.ffn2]:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor = None) -> torch.Tensor:\n",
    "        attn_out = self.mha(x, attn_mask=attn_mask)\n",
    "        x = self.norm1(x + self.dropout1(attn_out))\n",
    "        ff = self.ffn2(self.act(self.ffn1(x)))\n",
    "        x = self.norm2(x + self.dropout2(ff))\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerCorePT(nn.Module):\n",
    "    \"\"\"Core transformer: Conv1D embedding -> positional encoding -> transformer layers.\"\"\"\n",
    "    def __init__(self, in_channels: int, key_dim: int, num_layers: int, num_heads: int, dff: int, max_pos: int, rate: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.key_dim = int(key_dim)\n",
    "        self.max_pos = int(max_pos)\n",
    "        self.dropout = nn.Dropout(rate)\n",
    "\n",
    "        self.embed = nn.Conv1d(in_channels, self.key_dim, kernel_size=1, bias=True)\n",
    "        nn.init.xavier_uniform_(self.embed.weight)\n",
    "        nn.init.zeros_(self.embed.bias)\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerEncoderLayerPT(key_dim=self.key_dim, num_heads=num_heads, dff=dff, rate=rate) \n",
    "            for _ in range(int(num_layers))\n",
    "        ])\n",
    "\n",
    "        pe = sinusoidal_positional_encoding(self.max_pos, self.key_dim)\n",
    "        self.register_buffer(\"pos_encoding\", pe, persistent=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, T, _ = x.shape\n",
    "        \n",
    "        # Compute mask for all-zero timesteps\n",
    "        with torch.no_grad():\n",
    "            mask = torch.all(x == 0.0, dim=-1)\n",
    "\n",
    "        # Embedding with Conv1D\n",
    "        y = self.embed(x.transpose(1, 2)).transpose(1, 2)\n",
    "        y = F.relu(y)\n",
    "        y = y * (self.key_dim ** 0.5)\n",
    "\n",
    "        # Add positional encoding\n",
    "        if T > self.pos_encoding.size(1):\n",
    "            self.pos_encoding = sinusoidal_positional_encoding(T, self.key_dim, device=x.device).to(self.pos_encoding.dtype)\n",
    "        y = y + self.pos_encoding[:, :T, :].to(y.dtype)\n",
    "        y = self.dropout(y)\n",
    "\n",
    "        # Apply transformer layers\n",
    "        for layer in self.layers:\n",
    "            y = layer(y, attn_mask=mask)\n",
    "        return y\n",
    "\n",
    "\n",
    "class TFMEncoderPT(nn.Module):\n",
    "    \"\"\"PyTorch implementation of TensorFlow Transformer Encoder with optional GNN.\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_shape: Tuple[int, int, int],        # (W, N, NF)\n",
    "        edge_feature_shape: Tuple[int, int, int], # (W, E, EF)\n",
    "        adjacency_matrix: np.ndarray,\n",
    "        latent_dim: int,\n",
    "        use_gnn: bool = True,\n",
    "        num_layers: int = 4,\n",
    "        num_heads: int = 8,\n",
    "        dff: int = 128,\n",
    "        dropout_rate: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.use_gnn = use_gnn\n",
    "        self.latent_dim = int(latent_dim)\n",
    "        self.W, self.N, self.NF = input_shape\n",
    "        _, self.E, self.EF = edge_feature_shape\n",
    "        assert adjacency_matrix.shape[0] == self.N == adjacency_matrix.shape[1], \"Adjacency must be NxN\"\n",
    "\n",
    "        key_dim = self.N * self.NF\n",
    "\n",
    "        if use_gnn:\n",
    "            # Node transformer\n",
    "            self.node_tf = TransformerCorePT(\n",
    "                in_channels=self.NF, key_dim=key_dim,\n",
    "                num_layers=num_layers, num_heads=num_heads, dff=dff, max_pos=self.W, rate=dropout_rate\n",
    "            )\n",
    "            # Edge transformer\n",
    "            self.edge_tf = TransformerCorePT(\n",
    "                in_channels=1, key_dim=key_dim,\n",
    "                num_layers=num_layers, num_heads=num_heads, dff=dff, max_pos=self.W, rate=dropout_rate\n",
    "            )\n",
    "\n",
    "            # Spatial GNN\n",
    "            self.spatial_gnn = CensNetConvPT(node_channels=self.latent_dim, edge_channels=self.latent_dim, activation=\"relu\")\n",
    "            lap, edge_lap, inc = self.spatial_gnn.preprocess(torch.tensor(adjacency_matrix))\n",
    "            self.register_buffer(\"laplacian\", lap.float())\n",
    "            self.register_buffer(\"edge_laplacian\", edge_lap.float())\n",
    "            self.register_buffer(\"incidence\", inc.float())\n",
    "\n",
    "            final_in = 2 * self.N * self.latent_dim\n",
    "        else:\n",
    "            # Single transformer for flattened input\n",
    "            self.flat_tf = TransformerCorePT(\n",
    "                in_channels=self.N * self.NF, key_dim=key_dim,\n",
    "                num_layers=num_layers, num_heads=num_heads, dff=dff, max_pos=self.W, rate=dropout_rate\n",
    "            )\n",
    "            final_in = self.W * self.N * self.NF\n",
    "\n",
    "        # MLP head\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(final_in, 2 * self.latent_dim),\n",
    "            nn.ReLU(),\n",
    "            BatchNorm1dKerasFP32(2 * self.latent_dim, eps=1e-3),\n",
    "            nn.Linear(2 * self.latent_dim, self.latent_dim),\n",
    "            nn.ReLU(),\n",
    "            BatchNorm1dKerasFP32(self.latent_dim, eps=1e-3),\n",
    "            nn.Linear(self.latent_dim, self.latent_dim),\n",
    "        )\n",
    "        \n",
    "        # Initialize head weights\n",
    "        for m in self.head.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, a: torch.Tensor) -> torch.Tensor:\n",
    "        B, W, N, NF = x.shape\n",
    "        B, W, E, EF = a.shape\n",
    "        assert (W, N, NF) == (self.W, self.N, self.NF)\n",
    "\n",
    "        if self.use_gnn:\n",
    "            # Process nodes using TF's transpose-reshape-transpose pattern\n",
    "            x_flat = x.view(B, W, N * NF)\n",
    "            x_transposed = x_flat.permute(2, 1, 0)  # (N*NF, W, B)\n",
    "            x_reshaped = x_transposed.reshape(NF, W, N, B)  # (NF, W, N, B)\n",
    "            x_nodes = x_reshaped.permute(3, 2, 1, 0)  # (B, N, W, NF)\n",
    "            \n",
    "            node_in = x_nodes.reshape(B * N, W, NF)\n",
    "            node_out = self.node_tf(node_in).view(B, N, W, -1)\n",
    "            nodes_flat = node_out.reshape(B, N, W * (self.N * self.NF))\n",
    "\n",
    "            # Process edges using TF's transpose-reshape-transpose pattern\n",
    "            EEF = E * EF\n",
    "            a_flat = a.view(B, W, EEF)\n",
    "            a_transposed = a_flat.permute(2, 1, 0)  # (EEF, W, B)\n",
    "            a_reshaped = a_transposed.reshape(1, W, EEF, B)  # (1, W, EEF, B)\n",
    "            a_edges = a_reshaped.permute(3, 2, 1, 0)  # (B, EEF, W, 1)\n",
    "            \n",
    "            edge_in = a_edges.reshape(B * EEF, W, 1)\n",
    "            edge_out = self.edge_tf(edge_in).view(B, EEF, W, -1)\n",
    "            edges_flat = edge_out.reshape(B, self.N, W * (self.N * self.NF))\n",
    "                    \n",
    "            # Apply spatial GNN\n",
    "            x_nodes_g, x_edges_g = self.spatial_gnn([\n",
    "                nodes_flat, (self.laplacian, self.edge_laplacian, self.incidence), edges_flat\n",
    "            ])\n",
    "\n",
    "            # Concatenate node and edge features\n",
    "            enc = torch.cat([x_nodes_g, x_edges_g], dim=1).reshape(B, -1)\n",
    "            \n",
    "        else:\n",
    "            # Non-GNN path: simple transformer on flattened input\n",
    "            x_flat = x.view(B, W, N * NF)\n",
    "            seq_out = self.flat_tf(x_flat)\n",
    "            enc = seq_out.reshape(B, -1)\n",
    "\n",
    "        # Apply MLP head\n",
    "        out = self.head(enc.float()).to(enc.dtype)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a867bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) WEIGHT TRANSFER UTILITIES (TF -> PT)\n",
    "\n",
    "def _tf_conv1d_to_torch(w_keras: np.ndarray) -> torch.Tensor:\n",
    "    # TF Conv1D [K, Cin, Cout] -> PT Conv1d [Cout, Cin, K]\n",
    "    return torch.from_numpy(np.transpose(w_keras, (2, 1, 0)))\n",
    "\n",
    "\n",
    "def _transfer_layernorm(tf_ln: LayerNormalization, pt_ln: nn.LayerNorm):\n",
    "    gamma, beta = tf_ln.get_weights()\n",
    "    pt_ln.weight.data = torch.from_numpy(gamma)\n",
    "    pt_ln.bias.data = torch.from_numpy(beta)\n",
    "\n",
    "\n",
    "def _flatten_qkv_kernel_bias(w: np.ndarray, b: np.ndarray, in_dim: int, num_heads: int, key_dim: int):\n",
    "    \"\"\"\n",
    "    Returns w2: (in_dim, H*K), b2: (H*K,)\n",
    "    Accepts Keras MHA kernels that may be 2D or 3D.\n",
    "    \"\"\"\n",
    "    # Kernel\n",
    "    if w.ndim == 2:\n",
    "        # (in_dim, H*K) already\n",
    "        w2 = w\n",
    "    elif w.ndim == 3:\n",
    "        # Common layouts:\n",
    "        # 1) (in_dim, num_heads, key_dim)\n",
    "        # 2) (num_heads, in_dim, key_dim)\n",
    "        # 3) (in_dim, key_dim, num_heads)\n",
    "        if w.shape == (in_dim, num_heads, key_dim):\n",
    "            w2 = w.reshape(in_dim, num_heads * key_dim)\n",
    "        elif w.shape == (num_heads, in_dim, key_dim):\n",
    "            w2 = np.transpose(w, (1, 0, 2)).reshape(in_dim, num_heads * key_dim)\n",
    "        elif w.shape == (in_dim, key_dim, num_heads):\n",
    "            w2 = np.transpose(w, (0, 2, 1)).reshape(in_dim, num_heads * key_dim)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected qkv kernel shape: {w.shape}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected qkv kernel rank: {w.ndim}\")\n",
    "\n",
    "    # Bias\n",
    "    if b is None:\n",
    "        b2 = None\n",
    "    elif b.ndim == 1:\n",
    "        # (H*K,)\n",
    "        b2 = b\n",
    "    elif b.ndim == 2:\n",
    "        # Common: (num_heads, key_dim)\n",
    "        if b.shape == (num_heads, key_dim):\n",
    "            b2 = b.reshape(num_heads * key_dim)\n",
    "        else:\n",
    "            b2 = b.reshape(-1)\n",
    "    else:\n",
    "        b2 = b.reshape(-1)\n",
    "\n",
    "    return w2, b2\n",
    "\n",
    "\n",
    "def _flatten_out_kernel_bias(w: np.ndarray, b: np.ndarray, out_dim: int, num_heads: int, key_dim: int):\n",
    "    \"\"\"\n",
    "    Returns w2: (H*K, out_dim), b2: (out_dim,)\n",
    "    Accepts Keras MHA output kernels that may be 2D or 3D.\n",
    "    \"\"\"\n",
    "    inner = num_heads * key_dim\n",
    "    if w.ndim == 2:\n",
    "        # (H*K, out_dim)\n",
    "        w2 = w\n",
    "    elif w.ndim == 3:\n",
    "        # Common layouts:\n",
    "        # 1) (num_heads, key_dim, out_dim)\n",
    "        # 2) (key_dim, num_heads, out_dim)\n",
    "        if w.shape == (num_heads, key_dim, out_dim):\n",
    "            w2 = w.reshape(inner, out_dim)\n",
    "        elif w.shape == (key_dim, num_heads, out_dim):\n",
    "            w2 = np.transpose(w, (1, 0, 2)).reshape(inner, out_dim)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected out kernel shape: {w.shape}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected out kernel rank: {w.ndim}\")\n",
    "\n",
    "    # Bias\n",
    "    if b is None:\n",
    "        b2 = None\n",
    "    elif b.ndim == 1:\n",
    "        # (out_dim,)\n",
    "        b2 = b\n",
    "    else:\n",
    "        b2 = b.reshape(-1)\n",
    "\n",
    "    return w2, b2\n",
    "\n",
    "\n",
    "def _transfer_mha_keras_to_pt(tf_mha: MultiHeadAttention, pt_mha: MultiHeadAttentionPT):\n",
    "    \"\"\"\n",
    "    Robustly map Keras MHA Dense kernels/biases to our PT MHA, flattening 3D tensors if needed.\n",
    "    \"\"\"\n",
    "    def get_dense(obj, primary, fallback):\n",
    "        d = getattr(obj, primary, None)\n",
    "        if d is None:\n",
    "            d = getattr(obj, fallback, None)\n",
    "        return d\n",
    "\n",
    "    qd = get_dense(tf_mha, \"query_dense\", \"_query_dense\")\n",
    "    kd = get_dense(tf_mha, \"key_dense\", \"_key_dense\")\n",
    "    vd = get_dense(tf_mha, \"value_dense\", \"_value_dense\")\n",
    "    od = get_dense(tf_mha, \"output_dense\", \"_output_dense\")\n",
    "    assert all([qd, kd, vd, od]), \"Could not find Keras MHA Dense sublayers (query/key/value/output).\"\n",
    "\n",
    "    in_dim = pt_mha.in_dim\n",
    "    H = pt_mha.num_heads\n",
    "    K = pt_mha.key_dim\n",
    "    inner = H * K\n",
    "\n",
    "    # q\n",
    "    Wq, bq = qd.get_weights()\n",
    "    Wq2, bq2 = _flatten_qkv_kernel_bias(Wq, bq, in_dim, H, K)\n",
    "    pt_mha.q_proj.weight.data = torch.from_numpy(Wq2.T)  # (inner, in_dim)\n",
    "    pt_mha.q_proj.bias.data = torch.from_numpy(bq2) if bq2 is not None else torch.zeros(inner)\n",
    "\n",
    "    # k\n",
    "    Wk, bk = kd.get_weights()\n",
    "    Wk2, bk2 = _flatten_qkv_kernel_bias(Wk, bk, in_dim, H, K)\n",
    "    pt_mha.k_proj.weight.data = torch.from_numpy(Wk2.T)\n",
    "    pt_mha.k_proj.bias.data = torch.from_numpy(bk2) if bk2 is not None else torch.zeros(inner)\n",
    "\n",
    "    # v\n",
    "    Wv, bv = vd.get_weights()\n",
    "    Wv2, bv2 = _flatten_qkv_kernel_bias(Wv, bv, in_dim, H, K)\n",
    "    pt_mha.v_proj.weight.data = torch.from_numpy(Wv2.T)\n",
    "    pt_mha.v_proj.bias.data = torch.from_numpy(bv2) if bv2 is not None else torch.zeros(inner)\n",
    "\n",
    "    # out\n",
    "    Wo, bo = od.get_weights()\n",
    "    Wo2, bo2 = _flatten_out_kernel_bias(Wo, bo, in_dim, H, K)  # (inner, in_dim_out==in_dim)\n",
    "    pt_mha.out_proj.weight.data = torch.from_numpy(Wo2.T)      # (in_dim, inner)\n",
    "    pt_mha.out_proj.bias.data = torch.from_numpy(bo2) if bo2 is not None else torch.zeros(in_dim)\n",
    "\n",
    "\n",
    "def _collect_tf_te(tf_te_layer):\n",
    "    \"\"\"Collect TF sublayers from TransformerEncoder (inner of TimeDistributed).\"\"\"\n",
    "    convs = [m for m in tf_te_layer.submodules if isinstance(m, Conv1D)]\n",
    "    enc_layers = list(getattr(tf_te_layer, \"enc_layers\"))\n",
    "    return convs, enc_layers\n",
    "\n",
    "\n",
    "def transfer_td_transformer_weights(tf_td: TimeDistributed, pt_core: TransformerCorePT):\n",
    "    assert isinstance(tf_td, TimeDistributed), \"Expected a TimeDistributed layer\"\n",
    "    tf_te = tf_td.layer  # inner TransformerEncoder\n",
    "\n",
    "    convs, enc_layers = _collect_tf_te(tf_te)\n",
    "    assert len(convs) >= 1, \"No Conv1D embedding found in TF transformer\"\n",
    "    k, b = convs[0].get_weights()\n",
    "    pt_core.embed.weight.data = _tf_conv1d_to_torch(k)\n",
    "    pt_core.embed.bias.data = torch.from_numpy(b)\n",
    "\n",
    "    assert len(enc_layers) == len(pt_core.layers), \"Transformer layer count mismatch\"\n",
    "    for i, (tf_el, pt_el) in enumerate(zip(enc_layers, pt_core.layers)):\n",
    "        _transfer_mha_keras_to_pt(tf_el.mha, pt_el.mha)\n",
    "        # FFN Dense\n",
    "        d1, d2 = tf_el.ffn.layers  # Dense(dff, relu), Dense(key_dim)\n",
    "        W1, B1 = d1.get_weights(); W2, B2 = d2.get_weights()\n",
    "        pt_el.ffn1.weight.data = torch.from_numpy(W1.T); pt_el.ffn1.bias.data = torch.from_numpy(B1)\n",
    "        pt_el.ffn2.weight.data = torch.from_numpy(W2.T); pt_el.ffn2.bias.data = torch.from_numpy(B2)\n",
    "        # LayerNorms\n",
    "        _transfer_layernorm(tf_el.layernorm1, pt_el.norm1)\n",
    "        _transfer_layernorm(tf_el.layernorm2, pt_el.norm2)\n",
    "\n",
    "\n",
    "def transfer_censnet_weights(tf_layer, pt_layer: CensNetConvPT):\n",
    "    \"\"\"\n",
    "    Transfer CensNetConv weights from TF to PyTorch.\n",
    "    The TF layer returns weights in this actual order (despite misleading names):\n",
    "    [node_kernel, edge_kernel, node_weights, edge_weights, node_bias, edge_bias]\n",
    "    \"\"\"\n",
    "    weights = tf_layer.get_weights()\n",
    "    \n",
    "    # Map based on actual shapes, not the misleading variable names\n",
    "    pt_layer.node_kernel.data = torch.from_numpy(weights[0])   # (825, 6)\n",
    "    pt_layer.edge_kernel.data = torch.from_numpy(weights[1])   # (825, 6) \n",
    "    pt_layer.node_weights.data = torch.from_numpy(weights[2])  # (825, 1)\n",
    "    pt_layer.edge_weights.data = torch.from_numpy(weights[3])  # (825, 1)\n",
    "    pt_layer.node_bias.data = torch.from_numpy(weights[4])     # (6,)\n",
    "    pt_layer.edge_bias.data = torch.from_numpy(weights[5])     # (6,)\n",
    "\n",
    "\n",
    "def transfer_head_mlp(tf_model: tf.keras.Model, pt_head: nn.Sequential):\n",
    "    # Dense(2*latent)->BN->Dense(latent)->BN->Dense(latent)\n",
    "    tail = [l for l in tf_model.layers if isinstance(l, (Dense, BatchNormalization))]\n",
    "    d1, bn1, d2, bn2, d3 = tail[-5:]\n",
    "\n",
    "    lin1: nn.Linear = pt_head[0]; bn1_pt: BatchNorm1dKerasFP32 = pt_head[2]\n",
    "    lin2: nn.Linear = pt_head[3]; bn2_pt: BatchNorm1dKerasFP32 = pt_head[5]\n",
    "    lin3: nn.Linear = pt_head[6]\n",
    "\n",
    "    # Dense 1\n",
    "    w, b = d1.get_weights(); lin1.weight.data = torch.from_numpy(w.T); lin1.bias.data = torch.from_numpy(b)\n",
    "    # BN 1\n",
    "    gamma, beta, mmean, mvar = bn1.get_weights()\n",
    "    bn1_pt.weight.data = torch.from_numpy(gamma); bn1_pt.bias.data = torch.from_numpy(beta)\n",
    "    bn1_pt.running_mean.data = torch.from_numpy(mmean); bn1_pt.running_var.data = torch.from_numpy(mvar)\n",
    "    # Dense 2\n",
    "    w, b = d2.get_weights(); lin2.weight.data = torch.from_numpy(w.T); lin2.bias.data = torch.from_numpy(b)\n",
    "    # BN 2\n",
    "    gamma, beta, mmean, mvar = bn2.get_weights()\n",
    "    bn2_pt.weight.data = torch.from_numpy(gamma); bn2_pt.bias.data = torch.from_numpy(beta)\n",
    "    bn2_pt.running_mean.data = torch.from_numpy(mmean); bn2_pt.running_var.data = torch.from_numpy(mvar)\n",
    "    # Dense 3\n",
    "    w, b = d3.get_weights(); lin3.weight.data = torch.from_numpy(w.T); lin3.bias.data = torch.from_numpy(b)\n",
    "\n",
    "\n",
    "def transfer_transformer_encoder_weights(tf_model: tf.keras.Model, pt_model: TFMEncoderPT, use_gnn: bool):\n",
    "    # Head first\n",
    "    transfer_head_mlp(tf_model, pt_model.head)\n",
    "\n",
    "    # Collect all TimeDistributed(TransformerEncoder) layers\n",
    "    td_layers = [\n",
    "        l for l in tf_model.layers\n",
    "        if isinstance(l, TimeDistributed) and hasattr(l.layer, \"embedding\") and hasattr(l.layer, \"enc_layers\")\n",
    "    ]\n",
    "\n",
    "    if use_gnn:\n",
    "        assert len(td_layers) >= 2, \"Expected node and edge TimeDistributed(TransformerEncoder) for GNN=True\"\n",
    "\n",
    "        # Identify which TD is nodes vs edges by inspecting the Conv1D embedding in_channels\n",
    "        def td_in_channels(td):\n",
    "            tf_te = td.layer\n",
    "            convs, enc_layers = _collect_tf_te(tf_te)  # reuse your helper\n",
    "            assert len(convs) >= 1, \"No Conv1D embedding found in TF transformer\"\n",
    "            k, _ = convs[0].get_weights()  # k shape: (kernel_size=1, in_channels, out_channels)\n",
    "            return int(k.shape[1])\n",
    "\n",
    "        # Keras TD order can vary; determine by in_channels\n",
    "        td_info = [(td, td_in_channels(td)) for td in td_layers]\n",
    "        # Nodes TD: in_channels == NF; Edges TD: in_channels == 1 (since TF reshapes edges to last dim 1)\n",
    "        nodes_td = next(td for td, in_ch in td_info if in_ch == pt_model.NF)\n",
    "        edges_td = next(td for td, in_ch in td_info if in_ch == 1)\n",
    "\n",
    "        # Transfer weights into the correct PT cores\n",
    "        transfer_td_transformer_weights(nodes_td, pt_model.node_tf)\n",
    "        transfer_td_transformer_weights(edges_td, pt_model.edge_tf)\n",
    "\n",
    "        # Ensure CensNetConvPT is built before weight copy (warm-up if needed)\n",
    "        needs_build = any(\n",
    "            getattr(pt_model.spatial_gnn, name, None) is None\n",
    "            for name in (\"node_kernel\", \"edge_kernel\", \"node_weights\", \"edge_weights\", \"node_bias\", \"edge_bias\")\n",
    "        )\n",
    "        if needs_build:\n",
    "            with torch.no_grad():\n",
    "                B = 2\n",
    "                W, N, NF = pt_model.W, pt_model.N, pt_model.NF\n",
    "                E, EF = pt_model.E, pt_model.EF\n",
    "                x_dummy = torch.zeros(B, W, N, NF)\n",
    "                a_dummy = torch.zeros(B, W, E, EF)\n",
    "                _ = pt_model(x_dummy, a_dummy)\n",
    "\n",
    "        # Copy CensNetConv weights\n",
    "        from deepof.clustering.model_utils_new import CensNetConv as CensNetConvTF\n",
    "        gnn_layer = next(l for l in tf_model.layers if isinstance(l, CensNetConvTF))\n",
    "        transfer_censnet_weights(gnn_layer, pt_model.spatial_gnn)\n",
    "\n",
    "    else:\n",
    "        assert len(td_layers) >= 1, \"Expected one TimeDistributed(TransformerEncoder) for non-GNN\"\n",
    "        transfer_td_transformer_weights(td_layers[0], pt_model.flat_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96405a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "try:\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    _HAS_SCIPY = True\n",
    "except Exception:\n",
    "    _HAS_SCIPY = False\n",
    "\n",
    "\n",
    "def _extract_tf_prehead(tf_model, x_np, a_np):\n",
    "    \"\"\"\n",
    "    Get the exact TF tensor fed into the first Dense of the head (d1.input).\n",
    "    x_np: (B, W, N*NF), a_np: (B, W, E*EF)\n",
    "    \"\"\"\n",
    "    denses = [l for l in tf_model.layers if isinstance(l, Dense)]\n",
    "    d1 = None\n",
    "    for l in denses:\n",
    "        if getattr(l, \"name\", \"\") == \"dense_4\":  # based on your model print\n",
    "            d1 = l\n",
    "            break\n",
    "    if d1 is None:\n",
    "        assert len(denses) >= 3, \"Could not find three Dense layers for the head\"\n",
    "        d1 = denses[-3]\n",
    "    sub = tf.keras.Model(tf_model.inputs, d1.input)\n",
    "    return sub([x_np, a_np], training=False).numpy()  # (B, D)\n",
    "\n",
    "\n",
    "def _capture_pt_prehead(pt_model, x_np, a_np):\n",
    "    \"\"\"\n",
    "    Run PT forward once and capture the tensor fed into self.head via a pre-hook.\n",
    "    Accepts either split dims (B,W,N,NF)/(B,W,E,EF) or flattened (B,W,N*NF)/(B,W,E*EF).\n",
    "    Returns: (B, D) numpy array\n",
    "    \"\"\"\n",
    "    # reshape flattened -> split if needed\n",
    "    if x_np.ndim == 3:\n",
    "        B, W, D = x_np.shape\n",
    "        N, NF = pt_model.N, pt_model.NF\n",
    "        assert D == N * NF, f\"x_np last dim {D} != N*NF {N*NF}\"\n",
    "        x_np = x_np.reshape(B, W, N, NF)\n",
    "    if a_np.ndim == 3:\n",
    "        B, W, D2 = a_np.shape\n",
    "        E, EF = pt_model.E, pt_model.EF\n",
    "        assert D2 == E * EF, f\"a_np last dim {D2} != E*EF {E*EF}\"\n",
    "        a_np = a_np.reshape(B, W, E, EF)\n",
    "\n",
    "    captured = {}\n",
    "    def hook(_mod, inputs):\n",
    "        captured[\"enc\"] = inputs[0].detach().cpu().numpy()\n",
    "\n",
    "    h = pt_model.head.register_forward_pre_hook(hook)\n",
    "    with torch.no_grad():\n",
    "        _ = pt_model(torch.from_numpy(x_np), torch.from_numpy(a_np))\n",
    "    h.remove()\n",
    "    return captured[\"enc\"]  # (B, D)\n",
    "\n",
    "\n",
    "def _standardize_columns(X):\n",
    "    \"\"\"Zero-mean, unit-variance per column.\"\"\"\n",
    "    mu = X.mean(axis=0, keepdims=True)\n",
    "    sd = X.std(axis=0, keepdims=True) + 1e-8\n",
    "    return (X - mu) / sd\n",
    "\n",
    "\n",
    "def _learn_perm_from_batch(tf_model, pt_model, x_tf_flat, a_tf_flat, use_cosine=True):\n",
    "    \"\"\"\n",
    "    Find perm such that PT_prehead[:, perm] ~= TF_prehead on one batch.\n",
    "    x_tf_flat: (B, W, N*NF), a_tf_flat: (B, W, E*EF)\n",
    "    Returns: torch.LongTensor of shape (D,)\n",
    "    \"\"\"\n",
    "    tf_pre = _extract_tf_prehead(tf_model, x_tf_flat, a_tf_flat)  # (B, D)\n",
    "    pt_pre = _capture_pt_prehead(pt_model, x_tf_flat, a_tf_flat)  # (B, D)\n",
    "    B, D = tf_pre.shape\n",
    "\n",
    "    tf_std = _standardize_columns(tf_pre)\n",
    "    pt_std = _standardize_columns(pt_pre)\n",
    "\n",
    "    if use_cosine:\n",
    "        tf_norm = tf_std / (np.linalg.norm(tf_std, axis=0, keepdims=True) + 1e-8)\n",
    "        pt_norm = pt_std / (np.linalg.norm(pt_std, axis=0, keepdims=True) + 1e-8)\n",
    "        sim = tf_norm.T @ pt_norm  # (D, D)\n",
    "        cost = 1.0 - sim\n",
    "    else:\n",
    "        diff = np.abs(tf_pre[:, :, None] - pt_pre[:, None, :])  # (B, D, D)\n",
    "        cost = diff.mean(axis=0)                                # (D, D)\n",
    "\n",
    "    if _HAS_SCIPY:\n",
    "        row_ind, col_ind = linear_sum_assignment(cost)\n",
    "        perm = np.full(D, -1, dtype=np.int64)\n",
    "        perm[row_ind] = col_ind\n",
    "    else:\n",
    "        # Greedy fallback\n",
    "        perm = np.full(D, -1, dtype=np.int64)\n",
    "        used_pt = np.zeros(D, dtype=bool)\n",
    "        pairs = [(cost[i, j], i, j) for i in range(D) for j in range(D)]\n",
    "        pairs.sort(key=lambda t: t[0])\n",
    "        assigned = 0\n",
    "        for _, i, j in pairs:\n",
    "            if perm[i] == -1 and not used_pt[j]:\n",
    "                perm[i] = j\n",
    "                used_pt[j] = True\n",
    "                assigned += 1\n",
    "                if assigned == D:\n",
    "                    break\n",
    "        assert (perm >= 0).all(), \"Failed to assign a unique PT column to each TF column\"\n",
    "\n",
    "    # Quality check\n",
    "    pt_matched = pt_pre[:, perm]\n",
    "    mean_abs = np.mean(np.abs(tf_pre - pt_matched))\n",
    "    max_abs = np.max(np.abs(tf_pre - pt_matched))\n",
    "    print(f\"Permutation quality -> mean abs diff: {mean_abs:.6g}, max abs diff: {max_abs:.6g}\")\n",
    "\n",
    "    return torch.from_numpy(perm)\n",
    "\n",
    "def apply_perm_into_head_first_linear(pt_model, perm_idx: torch.LongTensor):\n",
    "    \"\"\"\n",
    "    Compose the learned input permutation into the first Linear of the head:\n",
    "      new_weight = old_weight[:, perm]\n",
    "    Bias unchanged. Removes the need to permute activations at runtime.\n",
    "    \"\"\"\n",
    "    lin1 = pt_model.head[0]\n",
    "    with torch.no_grad():\n",
    "        lin1.weight.copy_(lin1.weight[:, perm_idx])\n",
    "    # If you had set prehead_perm for runtime, clear it:\n",
    "    if hasattr(pt_model, \"prehead_perm\"):\n",
    "        pt_model.prehead_perm = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff0fb026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_gnn_parity (__main__.TestTransformerEncoderPT) ... The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "ok\n",
      "test_non_gnn_parity (__main__.TestTransformerEncoderPT) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 1.724s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TransformerEncoderPT GNN parity PASSED\n",
      "✅ TransformerEncoderPT non-GNN parity PASSED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest, time\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import TimeDistributed, Conv1D, Dense, BatchNormalization\n",
    "from spektral.layers import CensNetConv as CensNetConvTF\n",
    "\n",
    "\n",
    "\n",
    "class TestTransformerEncoderPT(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        tf.keras.backend.clear_session()\n",
    "        # Your TCN-style init\n",
    "        self.batch_size = 128\n",
    "        self.W = 25\n",
    "        self.N = 11\n",
    "        self.NF = 3\n",
    "        self.E = 11\n",
    "        self.EF = 1\n",
    "        self.latent_dim = 6\n",
    "\n",
    "        # Adjacency\n",
    "        m = np.zeros((self.N, self.N), dtype=np.float32)\n",
    "        ui = np.triu_indices(self.N)\n",
    "        num_possible = len(ui[0])\n",
    "        c = np.random.choice(num_possible, min(self.E, num_possible), replace=False)\n",
    "        m[ui[0][c], ui[1][c]] = 1\n",
    "        self.adj_matrix = (m + m.T).astype(np.float32)\n",
    "\n",
    "        # Data\n",
    "        rng = np.random.default_rng(0)\n",
    "        self.x_np = rng.normal(size=(self.batch_size, self.W, self.N, self.NF)).astype(np.float32)\n",
    "        self.a_np = rng.normal(size=(self.batch_size, self.W, self.E, self.EF)).astype(np.float32)\n",
    "\n",
    "        # Transformer params (keep small to avoid OOM)\n",
    "        self.num_layers = 1\n",
    "        self.num_heads = 4\n",
    "        self.dff = 64\n",
    "        self.dropout = 0.0\n",
    "\n",
    "    def test_non_gnn_parity(self):\n",
    "        B, W, N, NF, E, EF = self.batch_size, self.W, self.N, self.NF, self.E, self.EF\n",
    "\n",
    "        # TF model: IMPORTANT — 2D shapes (W, N*NF) and (W, E*EF)\n",
    "        tf_model = get_transformer_encoder(\n",
    "            input_shape=(W, N * NF),\n",
    "            edge_feature_shape=(W, E * EF),\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=False,\n",
    "            num_layers=self.num_layers,\n",
    "            num_heads=self.num_heads,\n",
    "            dff=self.dff,\n",
    "            dropout_rate=self.dropout,\n",
    "        )\n",
    "\n",
    "        # PT model: split dims\n",
    "        pt_model = TFMEncoderPT(\n",
    "            input_shape=(W, N, NF),\n",
    "            edge_feature_shape=(W, E, EF),\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=False,\n",
    "            num_layers=self.num_layers,\n",
    "            num_heads=self.num_heads,\n",
    "            dff=self.dff,\n",
    "            dropout_rate=self.dropout,\n",
    "        )\n",
    "        pt_model.eval()\n",
    "\n",
    "        # Transfer weights\n",
    "        transfer_transformer_encoder_weights(tf_model, pt_model, use_gnn=False)\n",
    "\n",
    "        # Inputs to TF are flattened 2D per time step\n",
    "        x_tf = self.x_np.reshape(B, W, N * NF)\n",
    "        a_tf = self.a_np.reshape(B, W, E * EF)\n",
    "\n",
    "        y_tf = tf_model([x_tf, a_tf], training=False).numpy()\n",
    "        with torch.no_grad():\n",
    "            y_pt = pt_model(torch.from_numpy(self.x_np), torch.from_numpy(self.a_np)).cpu().numpy()\n",
    "\n",
    "        np.testing.assert_allclose(y_tf, y_pt, rtol=1e-5, atol=2e-4)\n",
    "        print(\"✅ TransformerEncoderPT non-GNN parity PASSED\")\n",
    "\n",
    "\n",
    "    def test_gnn_parity(self):\n",
    "        B, W, N, NF, E, EF = self.batch_size, self.W, self.N, self.NF, self.E, self.EF\n",
    "\n",
    "        # TF model: IMPORTANT — 2D shapes (W, N*NF) and (W, E*EF)\n",
    "        tf.keras.backend.clear_session()\n",
    "        tf_model = get_transformer_encoder(\n",
    "            input_shape=(self.W, self.N * self.NF),\n",
    "            edge_feature_shape=(self.W, self.E * self.EF),\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=True,\n",
    "            num_layers=self.num_layers,\n",
    "            num_heads=self.num_heads,\n",
    "            dff=self.dff,\n",
    "            dropout_rate=self.dropout,\n",
    "        )\n",
    "        pt_model = TFMEncoderPT(\n",
    "            input_shape=(self.W, self.N, self.NF),\n",
    "            edge_feature_shape=(self.W, self.E, self.EF),\n",
    "            adjacency_matrix=self.adj_matrix,\n",
    "            latent_dim=self.latent_dim,\n",
    "            use_gnn=True,\n",
    "            num_layers=self.num_layers,\n",
    "            num_heads=self.num_heads,\n",
    "            dff=self.dff,\n",
    "            dropout_rate=self.dropout,\n",
    "        )\n",
    "        pt_model.eval()\n",
    "\n",
    "        # Warm up PT model to build parameters\n",
    "        with torch.no_grad():\n",
    "            _ = pt_model(torch.from_numpy(self.x_np[:2]), torch.from_numpy(self.a_np[:2]))\n",
    "        transfer_transformer_encoder_weights(tf_model, pt_model, use_gnn=True)\n",
    "\n",
    "        # Inputs to TF are flattened 2D per time step\n",
    "        x_tf = self.x_np.reshape(B, W, N * NF)\n",
    "        a_tf = self.a_np.reshape(B, W, E * EF)\n",
    "\n",
    "        y_tf = tf_model([x_tf, a_tf], training=False).numpy()\n",
    "        with torch.no_grad():\n",
    "            y_pt = pt_model(torch.from_numpy(self.x_np), torch.from_numpy(self.a_np)).cpu().numpy()\n",
    "\n",
    "        np.testing.assert_allclose(y_tf, y_pt, rtol=1e-5, atol=2e-4)\n",
    "        print(\"✅ TransformerEncoderPT GNN parity PASSED\")\n",
    "\n",
    "\n",
    "# Run tests\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestTransformerEncoderPT)\n",
    "runner.run(suite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
